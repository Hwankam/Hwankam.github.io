[ { "title": "PRML-6", "url": "/posts/PRML6/", "categories": "", "tags": "PRML, Machine learning", "date": "2022-03-01 00:00:00 +0900", "snippet": "6. Kernel Methods[서론]there is a class of pattern recognition techniques==&amp;gt; training data points are kept, memory based methodex ) nearest neighborhood 방법은 training data와 가장 유사한 label을 test data에서 선택함. 즉 여기서 training data 가 storing 된다는 것은 모델 내부에서 파라미터를 정하는 학습이 아니라는 뜻. 즉, 모델을 달라고한다면 선형회귀모델 같은 경우에는 파라미터 계수를 주면 되겠지만, NN의 경우에는 데이터 자체를 줘야한다.kerenl function$\\ \\ $ : $k(x, x’) = \\phi(x)^T \\phi(x’)$특징 : symmetric종류 identity kernel(linear kernel) : $k(x, x’) = x^T x’$ stationary kernel : $k(x, x’) = k(x - x’) $ , 오직 차이에만 의존하므로 translation invarinace 를 갖는다. homogeneous kernel(radial basis kernel) :$k(x, x’) = k(||x - x’||) $ , 오직 거리의 크기에만 의존 large margin classifier로 머신러닝에서의 kernel function 중요성이 재조명됨“extenstion of kernels to handle symbolic objects” : 다양한 자료를 kernel을 통해 분석할 수 있게 됨6.1 Dual RepresentationsMany linear models can be reformulated in terms of a dual representation =&amp;gt; kernel function예측함수를 $w^t \\phi(x)$ 라고 할 때, regularized sum of squares error function을 고려하면 이를 최소화하는 벡터 w는 $\\phi(x)$ 의 linear combination으로 표현 가능하다.즉 dual formulation을 통해서 최소제곱의 문제를 kernel function을 통해 표현 가능하다.gram matrix $ K = \\boldsymbol{\\Phi} \\boldsymbol{\\Phi}^T $ 에 대해서 error function을 다음과 같이 적을 수 있다\\[\\begin{align} &amp;amp;J(a) = \\frac{1}{2} a ^T \\boldsymbol{K}^T\\boldsymbol{K}a - a^T \\boldsymbol{K} \\boldsymbol{t} + \\frac{1}{2} \\boldsymbol{t}^t\\boldsymbol{t} + \\frac{\\lambda}{2} a^T \\boldsymbol{K} a\\\\&amp;amp;\\textrm{where} \\ \\ \\ \\ w = \\boldsymbol{\\Phi}^T a \\ \\ \\ \\ \\&amp;amp; \\ \\ \\ \\ a_n = \\frac {-1}{\\lambda} \\{ w^T \\phi(x_n) - t_n \\}\\end{align}\\]error function의 gradient 를 0으로 하는 a를 구해 prediction을 구하면\\[y(x) = w^T \\boldsymbol{\\phi}(x) = a^T \\boldsymbol{\\Phi} \\ \\boldsymbol{\\phi}(x)\\]즉, w를 $\\phi$의 linear combination으로 구하게 되면, 최소제곱의 문제를 커널을 통해 해결할 수 있게 되는 것이다.파라미터 w 에서 이를 변환한 a 를 고려하게 되면 일반적으로 차원은 더 커지게 된다. 그러나 kernel function $k(x, x’)$을 통해서 온전히 식을 표시할 수 있으며 feature vector $\\phi(x)$가 무엇인지 명확하게 제시할 필요도 없어진다. =&amp;gt; high dimension을 다룰 수 있다.6.2 Constructing Kernelsconstruct valid kernel function이 중요하다첫번째 방법으로는 mapping $\\phi(x)$를 설정한 이후에 내적을 통해 kernel function을 찾는 것이 있고, 두번째 방법으로는 kernel fucntion을 directly 찾는 것이 있다. 두번째 방법에서는 내가 정한 kernel function이 정말 유효한 kernel function인지 찾는 것이 중요하다. 이때 gram matrix(각 원소가 kernel $\\phi(x)$의 내적) positive semi - definite이라는 조건만 있으면 kernel function이 되는 필요충분조건을 만족한다.따라서 기본 형태의 kernel fucntion을 찾은 뒤 building block의 형태로 kernel을 만들어나간다.gaussian kernel : $k(x, x’) = exp(-|| x - x’ || ^2 / 2\\sigma^2) = exp(-x^tx / 2\\sigma^2) exp(x^tx/\\sigma^2) exp(-(x’)^tx’ / 2\\sigma^2 )$gaussian kernel은 결국 linear kernel인 $k(x, x’) = x^t x’$를 block으로 해서 만든 것이므로 kernel function이 됨을 알 수 있다.kernel 종류 discriminant model과 generative model 섞기 : similarity measure use generative model to define a kernel and then use this kernel in a discriminative approach. ex ) Fisher kerenl (관련 논문 : http://www.vision.caltech.edu/publications/holubWellingPerona-FisherICCV05.pdf) $\\dot l(\\theta) \\sim \\mathcal{N}(0 , n I(\\theta)) $ 과 연관되어 있지 않을까 sigmoidal kernel실제로 많이 이용되는 커널. SVM을 neural network와 연결짓는 kernel “in the limit of an infinite number of basis functions, a Bayesian neural network with an appropriate prior reduces to a Gaussian process” 6.3 Radial Basis Function Networks앞 장에서부터 basis function 을 활용한 linear regression 과 classification 에 대해 이야기했다. 대표적인 basis function으로는 radial basis function이 있다. radial basis function은 Euclidean distance를 기반으로 한 basis function이다.[Interpolation - RBF 배경]본래 radial basis function은 exact function interpolation을 목적으로 만들어졌다. 일례로, input과 target을 정확하게 fitting 하는 smooth function을 만들기 위해서 radial basis function의 linear combination을 만드는 과정을 생각해볼 수 있다.\\[f(x) = \\sum_{n=1} w_n h(||x-x_n||)\\]여기서 $w_n$은 least square를 통해 얻을 수 있다.그러나 exact interpolation은 overfitting의 문제가 있다.input이 noisy 한 경우 interpolation을 고려하는 경우에도 Euclidean distance에 기반한 basis function을 고려할 수 있다.\\[E = \\frac{1}{2} \\sum_{n=1} \\int \\{y(x_n + \\xi) - t_n \\}^2 v(\\xi) d \\xi\\]이 때 optimization은\\[y(x_n) = \\sum t_n h(x-x_n) \\ \\ \\ \\ \\ \\ \\textrm{where} \\ \\ \\ h(x- x_n) = \\frac {v(x-x_n)}{\\sum v(x - x_n)}\\]이때 basis function h 는 normalized 되어있으므로, 이를 통해 모든 basis function이 작은 값을 갖게 되는 경우를 방지할 수 있다. 여기서 쓰인 basis function을 Nadaraya-Watson model이라고 한다.[Kernel density estimation - RBF 확장]normalized radial basis function의 확장으로, regression 문제에서의 kernel density estimation이 있다. 여기서는 computing cost를 절감하기 위한 방안으로써, data point 보다 더 작은 개수의 basis function을 setting 하는 법이 있음을 말하고 있다.일반적으로 basis function의 개수와 center에 대한 location $\\mu_i$ 는 data point에 의해 정해지며그 형태는 사전적이다. 또한 계수 $w_i$ 는 최소제곱을 통해 정해진다. 이 때에 basis function의 개수를 data point 개수보다 줄이기 위해서는 basis function의 center를 순차적으로 정하되, sum-of-square error를 최대한으로 줄이는 data point에 상응하는 center로 선택하는 sequential selection process가 있다. 이 방식은 통상적으로 orthogonal least square 라고 불린다.orthogonal least square참고논문 : orthogonal least square regression : a unifed apporoach for data modelingsparse kernel data modeling을 위해 kernel matrix(feature)를 QR 분해해서 orthogonoalize6.3.1 Nadaraya-Watson model(3.62)에서는 equivalent kernel $k(x, x’) = \\beta \\phi(x)^T S_N \\phi(x’)$ 를 제시하며 predictive distribution mean이 training data의 target$t_n$의 선형결합으로 나타내어짐을 보였다.이제 kernel density estimation의 관점에서 이를 살펴보자.joint distribution $p(x,t)$ 를 추정하기 위해 Parzen density estimator를 활용해보자.\\[p(x,t) = \\frac {1}{N} \\sum_{n=1} ^N f(x - x_n, t- t_n)\\]여기서 Paren density estimator는 kernel density estimation을 위한 방법 중 하나이다. 아래는 이에 대한 간단한 설명이다.(참고 링크)[https://jayhey.github.io/novelty%20detection/2017/11/08/Novelty_detection_Kernel/] 1장에서도 짧게 배웠듯이, $P(x) \\simeq \\frac {K}{N V}$ 로 적을 수 있고, V를 고정시키고 K를 구하는 것은 kernel density estimator와 같이 생각할 수 있다.(반대로 K를 고정시키고 V를 찾는 것은 K-nearest neighborhood 라고 할 수 있다) 이를 활용해 d-dimension에서$V = h^d$ 라고 할 때 x, t 를 기준으로 각 차원으로 h/2 안에 존재하는 데이터의 개수를 세어 밀도를 추정한다고 할 때 $$p(x, t) =\\frac {1}{N h^d} \\sum_{n=1} ^N f(\\frac{x - x_n}{h}, \\frac{t- t_n}{h})$$위의 식으로 밀도추정이 가능하다. 이제 target variable 에 대한 conditional expectation을 구하는 것에 대해 생각해보자.\\[\\begin{align}y(x) &amp;amp; = E[t|x] = \\int t p(t|x) dt \\\\&amp;amp; = \\frac{\\int t p(x,t) dt }{\\int p(x,t) dt} \\\\&amp;amp; = \\frac {\\sum_n \\int t f(x-x_n, t- t_n) dt }{\\sum _m\\int f(x-x_m, t-t_m) dt} \\ \\ \\ \\ \\cdots \\textrm{using Parzen density estimation }\\end{align}\\]component f에 대한 zero mean을 가정하고, $g(x) = \\int f(x,t) dt$ 라고 정의하면\\[\\begin{align}y(x) &amp;amp; = \\frac {\\sum_n g(x-x_n) t_n}{\\sum_m g(x-x_m)} \\\\&amp;amp; = \\sum k(x,x_n) t_n\\end{align}\\]위 식의 마지막 결과를 보면 앞에서 Bayesian regresssion에서 보았던 predictive distribution mean과 비슷한 형태를 가지고 있음을 알 수 있다.6.4 Gaussian Processkernel을 사용해 probablistic discriminative model로 확장해보자.(6.1은 non-probablistic model) 이 장에서는 kernel이 Bayesian setting과 어떻게 연관되는지 보여준다.6.4.1 Linear regression revisited[linear model에서 gaussian process가 어떻게 정의되는지]다시 linear regression 문제로 돌아가서, predictive distirbution을 도출해내는 것을 생각해보자. (predictive dist 는 다음 절에서 나오는 듯?)basis function의 선형결합으로 구성된 모델을 생각해보자.\\[y(x,w) = w^T \\phi(x)\\]이때 w 의 Gaussian prior를 다음과 같이 정의한다.\\[p(w) = \\mathcal{N}(w |0, \\alpha^{-1} I)\\]training data point x 에 대한 joint distribution은 다음과 같다.\\[\\boldsymbol{Y} = \\boldsymbol{\\Phi} w\\]$\\boldsymbol{Y}$ 는 w 에 대한 linear combination이므로, 그 자체로 이미 Gaussian 이다. 그리고 평균과 분산은 다음과 같다.\\[\\begin{align}&amp;amp; E[\\boldsymbol{Y}] = \\Phi E[w] = 0 \\\\&amp;amp; cov[\\boldsymbol{Y}] = E[\\boldsymbol{Y} \\boldsymbol{Y}^T] = \\Phi E[w w^T] \\Phi^T = \\frac{1}{\\alpha} \\Phi \\Phi^T \\\\ &amp;amp; \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ = K \\textrm{(gram matrix)}\\end{align}\\]이 모델(linear model)은 Gaussian process 의 특별한 모델로서 일반적으로 Gaussian process 는 joint distribution $\\boldsymbol{Y}(x)$ 로 정의된다.Gaussian 이므로 평균과 분산은 second order statistic (second moment) 가 중요하고, w에 대한 prior의 평균을 0으로 잡을 때는, covariance matrix 인 gram matrix가 중요하다. Gaussian process 에서도 kernel을 직접 정할 수 있으며 아래 그림은 GP에서 각각 Gaussian kernel과 exponential kernel을 설정해 densitiy estimation을 수행한 결과이다.6.4.2 Gaussian processes for regressionGaussian process 문제를 regression setting에 적용하기 위해서는 noise 개념을 도입해야 한다.\\[t_n = y(x_n) + \\epsilon_n\\]Gaussian 분포를 갖는 noise process를 생각하면\\[p(t_n | y_n ) = \\mathcal{N}(t_n | y(x_n), \\beta ^{-1} )\\]noise는 모두 독립이므로, $y(x_n)$의 값이 모두 조건으로 주어졌을 때 target value t에 대한 joint distribution은\\[p(\\boldsymbol{t} | \\boldsymbol{y} ) = \\mathcal{N}(\\boldsymbol{t} | \\boldsymbol{y}, \\beta ^{-1} \\boldsymbol{I}_N )\\]그리고 $\\boldsymbol{y}$가 Gaussian Process 를 따른다고하면 정의에 의해 marginal distribution 또한 Gaussian을 따른다.\\[p(\\boldsymbol{y}) = \\mathcal{N}(\\boldsymbol{y} | 0, \\boldsymbol{K})\\]여기서 K는 gram matrix이며 이는 각 원소가 kernel의 내적으로 정의된 함수이다.이때 t에 대한 marginal distribution을 구하면\\[p(\\boldsymbol{t}) = \\int p(\\boldsymbol{t}|\\boldsymbol{y}) p(\\boldsymbol{y}) d\\boldsymbol{y} = \\mathcal{N} ( \\boldsymbol{t} | 0, \\boldsymbol{C} )\\]Gaussian process regression에서 가장 자주 쓰이는 kernel function은 exponential of quadratic form으로 아래와 같다.\\[k(x_n, x_m) = \\theta_0 exp \\{ - \\frac{\\theta_1}{2} ||x_n - x_m || ^2\\} + \\theta_2 + \\theta_3 x_n^Tx_m\\]여기서 주목할 만한 점은 last term이 input variable x에 대한 linear function이라는 것이다.이제 regression에 초점을 맞춰보자. 결국 하고 싶은 것은 prediction이므로 new input $x_{N+1}$에 대한 target $t_{N+1}$ 을 예측하고 싶다. 즉 $p(t_{N+1} | \\boldsymbol{t}_N)$ 을 구하고 싶다.N+1개의 target에 대한 joint distribution은 위에서 구한 marginal distribution을 활용해서 아래 결과를 알 수 있다.\\[p(\\boldsymbol{t}_{N+1}) = \\mathcal{N} ( \\boldsymbol{t}_{N+1} | 0, \\boldsymbol{C}_{N+1} )\\]이때 $\\boldsymbol{C}_{N+1}$에 대한 partition matrix를 다음과 같이 정의한다고 하자.\\[C=(\\begin{array}{c c}\\boldsymbol{C}_N &amp;amp; k \\\\k^T &amp;amp; c\\end{array})\\]이 때의 predictive distribution의 평균과 분산은 아래와 같다.\\[\\begin{align}&amp;amp; m(x_{N+1}) = k^T \\boldsymbol{C}_N ^{-1} \\boldsymbol{t} \\\\&amp;amp; \\sigma^2(x_{N+1}) = c - k^T\\boldsymbol{C}_N ^{-1} k\\end{align}\\]식에서도 알 수 있듯, predictive distribution은 Gaussian이며 평균과 분산이 new input value $x_{N+1}$ 에 의존한다. (또한 kernel에 의존한다) 그래서 kernel$k(x,x’)$만 잘 정의된다면 3.3.2장에서 배운 linear regression의 predictive distribution에 대한 gaussian process 관점을 살펴볼 수 있게 되는 것이다.(3.3.2에서 배운 predictive distribution의 평균, 분산의 형태와 매우 비슷하다)정리하면 predictive distribution에 대한 두가지 관점이 존재한다. linear regression을 사용한 parameter space viewpoint $y = X \\beta + \\epsilon $ 에서 $\\beta$의 추정이 중요한 경우 Gaussian process를 활용한 function space viewpoint $y = f(x_n) + \\epsilon$ 에서 GP $f(x_n)$이 중요한 경우 이제 Gaussian process의 한계를 살펴보자. 우선 GP는 역행렬 계산이 들어가기 때문에 연산량이 매우 크다만약 kernel function을 바로 define해서 gram matrix를 구하면 복잡도는 $O(N^3)$일 것이다. 그러나 kernel function으로 바로 gram matrix를 define하는 방법 이외에도, mapping function을 통해$\\Phi$를 define한 뒤, gram matrix를 구하면 mapping function의 차원(차수) M에 의해 연산량은$O(M^3)$ 이다.이를 통해 알 수 있는 점은 무한차원의 mapping function을 사용한다고 할 때 이를 활용한 kernel f을 바로 define할 수 있다면 데이터의 개수에 의존하는 연산량만으로 GP를 계산할 수 있다. 그래서 이 책에서 제시되는 장점으로 “그럼에도 불구하고 GP를 사용하면 무한차원의 basis function을 covariance function(kernel function)을 통해 나타낼 수 있다는 장점이 있다.” 라는 말이 언급되는 것이다.6.4.3 Learning the hyperparametersGaussian process를 통한 예측은 결국 공분산함수에 영향을 받게 된다(공분산함수에 kernel이 들어가있기 때문). 특히, 공분산함수를 parametric하게 만들어 데이터에 따라 여러가지 변형을 줄 수 있다. 이러한 방법으로 책에서는 두 가지 방법을 소개한다. 가장 단순한 방법으로 Maximum Likelihood Estimator로 hyperparameter $\\theta$를 점추정하는 방법이 있다. 본래 커널은 연구자가 정하는 것이므로 kernel function $k(x,x’)$ 안에 들어있는 theta는 hyperparameter이다. 그러나 empirical Bayes 관점(prior마저도 data를 통해 ML방식으로 세팅하는 것)과 유사하게 ML방식으로 hyperparameter를 세팅할 수 있다. multivariate Gussian distribution의 standard form을 활용해서 로그가능도를 표현하면\\[ln \\ p(\\boldsymbol{t} | \\theta) = - \\frac{1}{2} ln \\ |C_N| - \\frac {1}{2} \\boldsymbol{t}^T C_N ^{-1} \\boldsymbol{t} - \\frac {N}{2} ln(2\\pi)\\] $ln \\ p(\\boldsymbol{t} | \\theta)$는 일반적으로 nonconvex function이므로 multiple maxima를 가진다. 두 번째 방법으로는 prior를 설정하고 log posterior를 극대화하는 방식으로 hyperparamter를 설정한다.(MAP) Gaussian process 로부터 predictive distribution을 구하면 평균과 분산이 모두 input x에 의존하게 됨을 위에서 보였다. 특히 분산은 noise에 의해서도 영향을 받는다는 것을 식을 통해 알 수 있는데, 몇몇 문제에서는 noise가 데이터에 의존하는 경우를 볼 수 있다. 이 경우 second Gaussian process $\\beta(x)$ 를 모델링 할 수 있다.6.4.4 Automatic relevnance determinationMaximum likelihood 방식을 이용해서 parameter를 최적화하는 것을 통해 다양한 input들의 상대적 중요도를 판정할 수 있다. Gaussian process 에서 이러한 automatic relevance determination 방법을 통해서 변수의 중요도를 판정할 수 있다. (7.2.2 참고)이차원의 input space $\\boldsymbol{x}= (x_1, x_2) $ 에 대해 kernel function을 아래와 같이 정의하자.\\[k(\\boldsymbol{x}, \\boldsymbol{x}&#39;) = \\theta_0 exp \\{ - \\frac{1}{2} \\sum _{i=1} ^2 \\eta_i (x_i - x_i &#39;) ^2 \\}\\]실제로 prior $\\theta$에 대한 그림을 그려보면parameter $\\eta_i$ 가 작을수록 함수가 input$x_i$에 덜 민감해짐을 알 수 있다.따라서, parameter $\\eta_i$를 optimize 했을 때, 만약 그 값이 작다면input $x_i$는 predictive distribution에서 중요도가 낮은 변수일 것이다.아래 그림은 $\\eta_i$ 값에 따라 prior가 input에 반응하는 민감도 차이를 나타낸 그림이다.특히, ARD(Automatic Relevance Determination)는 exponential quadratic kernel 에서 잘 이용된다.\\[k(\\boldsymbol{x}_n, \\boldsymbol{x}_m) = \\theta_0 exp \\{ - \\frac{1}{2} \\sum _{i=1} ^D \\eta_i (x_{ni} - x_{mi}) ^2 \\} + \\theta_2 + \\theta_3 \\sum _{i=1} ^D x_{ni}x_{mi}\\]" }, { "title": "PRML-5", "url": "/posts/PRML5/", "categories": "", "tags": "PRML, Machine learning", "date": "2022-02-09 00:00:00 +0900", "snippet": "5. Neural Networkschap 3과 4에서는 linear combination of fixed bases function에 대해 배웠다. 그러나 high dimension에서는 과적합의 문제가 발생하는 한계가 있었다. 이를 해결하기 위해 데이터에 맞게 basis function을 바꾸는 것은 어떠할까?SVM은 데이터에 맞게 hyperplane을 설정하는 것이므로 맥락에 부합한다. 이는 basis function의 후보 가운데 일부를 선택해서 데이터에 적합시키는 것이므로 ‘차원의 저주’로 부터 좀 더 자유로워질 수 있다. 또한 convex optimization 문제로 풀 수 있기 때문에 solution이 명확하다.좀 더 다른 방식으로, basis function 개수는 고정하지만 parameter를 통해 data에 맞는 basis function 자체를 바꾸는 것을 생각할 수 있다. 가장 대표적인 방식이, feed forward neural network(multilayer perceptron)이다. 이 모델은 SVM에 비해 compact하며 학습속도가 빠르다. 그러나 convex optimization 문제가 아니므로 해를 찾기 어려울 수 있다.multilayer perceptron에서 결정해야할 parameter는 Maximum likelihood를 사용해서 결정한다.(뒤에서 Jacobian 이나 Hessian을 통해서 error backpropagation의 작동원리를 배울 것임)5.1 Feed-forward Network Functionschap 3 과 4의 모델은 다음과 같다.\\[y(\\boldsymbol{x}, \\boldsymbol{w}) = f (\\sum_{i=1}^M w_j \\phi_j (\\boldsymbol{x}) )\\]multilayer perceptron 모델에서는 non-linear basis fucntion인 $\\phi_j (\\boldsymbol{x})$ 가 adjustable parameter에 의존하도록 하겠다.( how? layer를 거치면서 $\\phi$ 는 input과 weight $\\boldsymbol{w}$의 결합으로 만들어짐 )[modeling]input variable : D개 (i)linear combination of input variable : M개 (j)superscript : layeractivation : $a_j$differentiable nonlinear unit activation function(last layer) : h (data의 특성에 의해 / target의 분포적 특성에 의해 결정됨) (Regression : identity function // binary classification : sigmoid function // Multiclass classification : softmax)differentiable nonlinear activation function : sigmoid, tanh, relu …hidden unit : z\\[a_j = \\sum _{i=1} ^D w_{ji} ^{(1)} x_i + w_{j0} ^{(1)} \\\\z_j = h(a_j)\\]아래 그림은 two layer neural network를 나타내는데, node는 deterministic variable이므로, probabilistic graphical model(chap 8)은 아니다.식과 그림에서도 알 수 있듯, 각 layer는 perceptron 모델과 매우 유사하다. 결국 perceptron 모델 또한 에러를 줄이는 perceptron parameter w를 결정하고자 한다. 그러나 perceptron 모델은 class를 +1 과 -1 로 나누는 데에서 activation function이 step function인 반면, neural network에서는 differentiable 하다는 것이 차이라 할 수 있다.만약 hidden unit이 linear라면 결국 식 (5.7) 와 같이 중첩해서 식을 쓸 필요가 없고, input 과 output만이 있는 매우 simple한 모델을 만들 수 있을 것이다. 이러한 형태는 나중에 12장에서 배울 principal component analysis와 매우 유사하다고 할 수 있다.network architecture에서 자주 사용되는 skip-layer connection은 경사소실을 막아, sparse 모델이 특정 gredient에만 영향을 크게 받는 것을 방지한다.“모든 input 과 oupter이 hidden layer 에 의해 연결된다면 weight는 어떻게 정할 것인가 =&amp;gt; maximum likelihood and Bayesian apporach “아래 그림은 hidden unit과 network 학습 결과를 보여준다.5.1.1 Weight-space symmetriesfeed-forward network의 특징 중 하나는, weight vector에 대한 multiple distinct choice 가 결국 같은 mapping function을 만들어 낸다는 것이다.ex1 ) tanh function와 같은 기함수의 특징을 활용할 때 M개의 hidden unit에 대해 $2^M$ 개의 weight vector가 동일한 network를 만들어 낼 것이다.ex2 ) hidden unit의 순서를 바꾸면 된다.5.2 Network Trainingpolynomial curve fitting(chap 1) 에서는 sum of square error function을 minimize 하는 parameter 값을 추정하는 것을 배웠다. neural network에서도 마찬가지로 parameter를 추정하는 것이 중요하다.우선 network output에 대한 확률적 접근을 할 수 있다.target $\\boldsymbol{t}$ 가 Gaussian distribution을 따른다고 생각해보자. Regression setting에서 unit activation function을 생각하면 parameter에 대한 MLE를 찾을 수 있다. 또한 Gaussian 가정 하에서는 likelihood function을 최대화 하는 것은 sum of square error function을 최소화 하는 것과 같다.가우시안의 경우에는 convex 문제를 쉽게 풀 수 있지만, 실제로 많은 경우에는 network function이 non-linearity를 가지고 있고, error function 또한 마찬가지이다. =&amp;gt; analytic 하게 구해야 한다.binary classification의 경우는 maximum likelihood 방식으로 parameter를 추정하는 것이 cross entropy error function을 최소화 하는 것과 동일하다. (sum of square error는 학습의 속도 또한 느리며, ML 방식에서 도출할 수 없는 error 이므로 generalization이 어렵다) 또한 target이 특정 분포를 따르는 것이 아니라, 0 또는 1로 명확하게 labelling 되어 있기 때문에 분산을 정의할 필요가 없다.binary classification with multiple target의 경우, linear classification은 각 linear model이 output과 각각 linearly independent 하게 영향을 주지만, neural network에서는 각 input이 각 output에 non-linearly 영향을 준다는 것이다.5.2.1 Parameter optimizationgeometric apporachweight space에서 $\\delta \\boldsymbol{w}$ 만큼 움직였을 때, error function의 변화는 $\\delta E \\simeq \\delta \\boldsymbol{w}^T \\nabla E(\\boldsymbol{w}$) 이고 이때 gredient는 error를 가장 많이 줄이는 방향이다. 따라서 gredient가 0에 매우 근사할 때 error를 가장 작게 하는 값에 도달했다고 할 수 있다.“Points at which the gradient vanishes are called stationary points and may be further classified into minima, maxima, and saddle point”Network 안에는 수많은 inequivalent stationary point 와 inequivalent minima 가 존재한다. 그러나 반드시 global minima를 찾을 필요는 없으며 존재하지 않을 수도 있다. 실제로 할 수 있는 것은 local minima 후보지를 몇개 선정한 다음 이를 비교해서 최적의 값을 찾는 것이다.(Newton-Rhapson 방법과 같이 iterative하게 parameter 값을 추정해야할 경우도 있다.)5.5 Regularization in Neural Networkshidden unit의 개수는 모델을 설계할 때 정하는 free parameter이며 모델 자체의 성능을 결정하게 된다. 한 방법으로 maximum likelihood setting을 통해서 최적의 hidden unit 개수를 결정할 수도 있을 것이다. 아래 그림은 hidden unit의 개수에 따른 fitting 결과를 보여준다.overfitting을 방지하는 방법으로는 초기에 hidden unit의 개수를 매우 큰 모형을 만든 다음 데이터를 적합해가면서 sparse한 모형을 만들어 내는 방식이 있다. 이를 위해 regularized error를 설정하는 것을 생각해볼 수 있다.(weight decay) 또한, 이전에도 배웠지만 L2 regularization 하에서 최적의 계수를 찾는 것은 gaussian prior에서 MAP를 찾는 것과 동일하다.\\[\\tilde E(\\boldsymbol{w}) =E(\\boldsymbol{w}) + \\frac{\\lambda}{2}\\boldsymbol{w}^T\\boldsymbol{w}\\]또다른 방법으로는 validation set을 통해서도 적절한 hidden unit의 개수를 설정할 수 있을 것이다(또한 hidden unit을 만드는 weight를 결정할 수 있을 것이다)5.5.1 Consistent Gaussian Priorsweight decay의 한계는 neural network mapping에서 weight에 대한 transformation(scaling)과 일치하지 않는 부분이 있다는 것이다.기존 데이터를 transform한 데이터를 생각해보자. 두 데이터를 모델을 통해 train 했을 때, 일반적으로 weight 는 다르겠지만 두 모델의 동일한 layer의 weight는 linear transform으로 서로 표현될 수 있을 것이다. 이때에 regularization을 생각해보자. linear transform에 의해 변형된 데이터이므로, regularization 또한 동일한 데이터(변수)에 적용되어야 할 것이다.그러나 위에서 본 regularized error 는 이러한 점을 만족하지 못한다.(layer 별로 activation function이 다르기 때문에 regularization 또한 다르게 적용되어야 한다) 이를 위해 새로운 regularization term을 제시한다. $\\mathcal{w}_1$ 은 첫번째 layer, $\\mathcal{w}_2$ 는 두번째 layer를 의미한다.\\[\\frac{\\lambda_1}{2}\\sum_{w \\in \\mathcal{w}_1}w^2 + \\frac{\\lambda_2}{2}\\sum_{w \\in \\mathcal{w}_2}w^2\\]weight의 prior를 고려한다면 prior는 다음과 같다.(regularizer can be interpreted as the negative loarithm of prior)\\[p(\\boldsymbol{w}) \\propto exp(- \\frac{1}{2} \\sum_k \\alpha_k ||\\boldsymbol{w}||_k^2)\\]5.5.2 Early stopping모델의 복잡성을 control하는 방법으로 regularization의 대안으로 early stopping을 제시한다. network training에서는 error는 비증가(non-increasing) 함수이다. 그러나 validation set을 통해 모델 검증을 해보면 training의 횟수가 늘어날수록, 즉 데이터에 과적합이 되는 경우 오히려 error가 커지는 현상을 발견할 수 있다. 즉, 적절한 training 횟수를 위해 early stopping이 필요하다.또한 자유도에 대한 내용이 언급되고 있다. 저자는 모델 학습이 진행될수록 네트워크의 degree of freedom이 증가할 것이라 말하고 있다. 모델 초기에는 모든 weight들이 동일하게 가중치를 가지고 있는 상태이나 training 동안 모델이 데이터에 적합되면서 일부 weight은 커지고 또 일부 weight은 작아지기 때문에 df의 값은 상대적으로 training 을 반복하면서 커진다고 할 수 있다.5.5.3 Invariancespattern recognition에서 input의 tranforming에 대해서 결과가 바뀌어서는 안된다. 예를들어 input data의 position을 바꾼다거나, 혹은 사이즈를 바꾼다거나 하는 등의 transforming은 결과값을 다르게 만들어서는 안될 것이다.만약 데이터가 매우 많다면 모델의 invariance는 자연스럽게 학습될 것이다. 많은 데이터 안에서는 자연스럽게 여러가지 transforming에 대한 것을 학습할 수 있기 때문이다. 그러나 데이터가 많지 않다면?? 요구되는 invariant 가 매우 많다면??이에 대한 대안으로 책에서는 4가지를 제시한다 data augmentation(replication을 batch 각각에 넣어주면 더 좋을 것) regularization term(transforming을 제한, 뒤에 나오는 tangent propagation) tranformation과 관련없는 변수를 미리 추출 network 모델 자체에 invariance properties를 만들어 놓음. (local receptive fields, shared weights) 5.5.4 Tangent propagationcontinuous transformation에 대해서만 고려해보자.(rotation not reflection)특정 변환에 의해서 D 차원 input space 에서 M차원의 manifold로 변형될 수 있다. 아래 그림을 보자.$\\xi$에 의해 transformation이 되고 있고 이러한 변형을$s(x_n, \\xi)$ 라고 할 수 있다. 이때 point $x_n$에서 tangent 값은 아래와 같다.\\[\\tau_n = \\frac {\\partial s(x_n, \\xi)}{\\partial \\xi} |_{\\xi = 0}\\]output에 대한 derivative 는 아래와 같다.\\[\\frac{\\partial y_k}{\\partial \\xi} | _{\\xi=0} = \\sum_{i=1}^D \\frac{\\partial y_k}{\\partial x_i} \\frac{\\partial x_i}{\\partial \\xi} |_{\\xi=0} = \\sum_{i=1}^D J_{ki} \\tau_i\\]이를 활용해서 error function을 변형해보자.regularization coefficient $\\lambda$와 regularization function $\\Omega$ 에 대해서\\[\\Omega = \\frac{1}{2} \\sum_n \\sum_k ( \\frac{\\partial y_k}{\\partial \\xi} | _{\\xi=0} )^2\\]\\[\\tilde E = E + \\lambda \\Omega\\]라고 둘 수 있다. 만일 transformation에 대해서 network mapping function이 invariant 하다면 regularization function $\\Omega$는 zero가 될 것이다. 또한 $\\lambda$ 값은 데이터에 대한 fitting과 invariant property에 대한 학습을 조절해주는 역할을 한다.이를 통해 볼때, regularization function은 결국 Jacobian을 통해 weight 에 영향을 받는다. 그러므로 backpropagation 방식과 동일하게 regularizer의 derivative를 구해 적절한 weight을 업데이트한다. 즉 tangent propagation 방식은 앞에서 학습한 regularization과 그 방식이 거의 유사한 것이다.비슷한 테크닉으로, tangent distance는 nearest-neighbour classifier와 같은 distance 기반의 분석법에서 invariance property를 찾아낼 수 있다.5.5.6 Convolutional networks5.5.3에서 나오는 4가지 방법 중 마지막 방법을 설명해보도록 하겠다. 이 단락에서는 network 구조 자체에 invariance properties를 만들고자 한다. 이러한 시도는 이미지 데이터 처리에 사용되는 convolutional neural network의 기반이 되었다.미묘한 변화까지도 감지하기 위한 네트워크 구조를 만들기 위해 fully connected network를 만든다고 해도, ‘이미지’ 데이터는 주변 데이터들과 큰 상관관계를 갖는다는 특성이 있다. 그러므로 vision 분야에서는 local feature 를 찾아내려는 시도를 많이하고 있다.(cnn의 핵심 = feature extraction)convolutional neural network는 local feature를 찾기 위해 local receptive field // weight sharing // subsampling 이라는 3가지 개념을 제시한다.input image는 sharing weight을 통해서 학습이 되고, image의 subregion으로부터 weight와 bias를 통해 unit으로 이뤄진 feature map을 만든다. 여기서 각 unit들은 feature detector의 역할을 한다. 혹여나 이미지가 이동된다고 하더라도, feature map에서의 활성위치(unit) 만 바뀌면 되기 때문에 invariance가 유지된다.convolutional unit의 output은 subsampling layer의 input을 만든다. subsampling unit은 feature map의 정보를 보다 압축한다. 따라서 image shift 가 발생하는 경우 이를 보다 민감하게 찾게 된다.(pooling과 유사?)이를 정리하면 Convolutional neural network를 다음과 같은 구조로 표현할 수 있다.5.5.7 Soft weight sharing모델 복잡도를 통제하는 방법 중 하나로 그룹화를 한 뒤 동일한 weight을 주는 것을 들 수 있다. 이 방법은 translation invariance를 위한 방법 중 하나이기도 하다. 이 방법은 weight에 대한 제약이 선행(그룹 간 weight의 평균, 그룹내 weight의 분산)되어야 하며, soft한 제약을 통해 특정 그룹의 weight가 similar value를 갖도록 한다.따라서 이 방식은 결국 mixture model을 고려하는 것과 동일시된다. 확률밀도함수는 다음과 같다\\[\\begin{align}&amp;amp; p(w_i) = \\sum _{j=1} ^ M \\pi_j \\mathcal{N}(w_i | \\mu_j, \\sigma_j^2) \\\\&amp;amp; p(\\boldsymbol{w}) = \\prod _i p(w_i)\\end{align}\\]negative loagrithm(ML을 극대화하는 것과 동일)을 통해 regularization function을 다음과 같이 만들 수 있다.\\[\\Omega(\\boldsymbol{w}) = - \\sum_i ln (\\sum_{j=1} ^M \\pi_j \\mathcal{N}(w_i | \\mu_j, \\sigma_j^2))\\]total error function은 아래와 같다.\\[\\tilde E(\\boldsymbol{w}) = E(\\boldsymbol{w}) + \\lambda \\Omega(\\boldsymbol{w})\\]이와 같이 정의한 error는 weight w와 파라미터인 $\\pi, \\mu, \\sigma$ 에 의해 minimize된다. 그 방법으로는 conjugate-gradients 혹은 quasi-Newton method 같은 것으로 weight를 업데이트하면서 동시에 EM알고리즘을 통해 mixture distribution의 파라미터 값을 업데이트하는 방식이 있다.(공동 최적화를 통한 수치적 안정성)total error function에 대한 derivative 를 구하기 위해서 우선 coefficient 인 $\\pi$ 에 대한 prior를 $\\pi_j$로 먼저 설정한 뒤, posterior를 나타낸다.\\[\\textrm{posterior} \\ \\ \\gamma_j(w) = \\frac {\\pi_j \\mathcal{N}(w|\\mu_j, \\sigma_j ^2)}{\\sum_k \\pi_k \\mathcal{N}(w|\\mu_k, \\sigma_k ^2)}\\]이때 total error function에 대한 derivative를 살펴보자. weight에 대한 derivative 는 다음과 같다.\\[\\frac {\\partial \\tilde E}{\\partial w_i} = \\frac {\\partial E}{\\partial w_i} + \\lambda \\sum_j \\gamma_j(w_i) \\frac {(w_i - \\mu_j)}{\\sigma^2 _j}\\]식을 자세히 보면 regularization term은 weight을 $j^{th}$ Gaussian의 중심으로 모으는 역할을 하고 있음을 알 수 있다(표준화)비슷하게 $\\mu , \\sigma $ 에 대해서도 derivative 를 구할 수 있으며, 의미는 비슷하다.(sharing, grouping)만일 $\\sigma^2 _j = exp(\\eta_j)$ 라고 둔다면 분산의 값이 0이 되는 경우를 막을 수 있으므로 유용하다.(9장 mixture model에서 설명)mixing coefficient $\\pi$에 대한 제약을 위해(합 1) softmax function을 사용할 수 있으며 derivative 를 구하면\\[\\frac {\\partial \\tilde E}{\\partial \\eta_j} = \\sum _i \\{\\pi_j - \\gamma_j(w_i) \\}\\]이므로 $\\pi_j$ 는 사후분포의 평균으로 가까워짐을 알 수 있다.5.6 Mixture Density Networkssupervised learning의 목적은 조건부분포 $p(t | x)$를 구하고자 하는 것이다. 그러나 실제 문제들에서 Gaussian을 가정하는 것은 잘못된 결과를 이르게 할 수도 있다.causality를 기반으로 한 forward problem은 many to one의 문제로 인과관계에 의한 정확한 결과를 예측할 수 있다. 반면 inverse problem을 생각해보자. 즉 one to many 의 문제를 푸는 것으로, 어떤 현상들이 발생했을 때 이를 바탕으로 특정사건이 일어날 것이라 예측할 수 있을지 단정짓기 어렵다. (명확한 인과관계가 밝혀지지 않는 이상 어떠한 결과를 가져올지 단정짓기 어렵다)아래 그림은 forward problem과 inverse problem을 설명한다.그럼 조건부분포를 찾기위한 일반적인 framework는 없을까?이 책에서는 mixture density network를 제시한다. 즉 mixing coefficients 와 component density 모두를 input vector X에 대한 flexible function으로 생각하는 것이다.Gaussian components 를 가정한다면 아래와 같은 모델을 만들 수 있다\\[p(t|x) = \\sum _{k=1} ^K \\pi_k(x) \\ \\mathcal{N}(t|\\mu_k(x), \\sigma_k ^2 (x))\\]이 모델은 input vector에 의해 component의 분산이 영향을 받는 heteroscedastic model(이분산성 모델)이다.mixture 모델에서 $\\pi_k(x), \\mu_k (x), \\sigma_k ^2 (x)$ 는 neural network 모델의 output에 영향을 받는다. 즉 mixture model의 parameter를 찾는 데에 hidden unit이 모두 공유된다. 그래서 만약 L개의 mixture component와 output t가 K개의 component를 가진다면 network는 L 개의 output unit activation $a_k ^ {\\pi}$ 과K개의 output $a_k ^ {\\sigma}$, L x K 개의 output $a_{kj} ^ {\\mu}$ 를 갖게 될 것이다.즉 network의 output 수는 (K+2)L 이며 mixture를 고려하지 않을 때에는 K 개의 output 만을 가진다는 데에서 비교된다.이때 coefficeint의 조건과, 분산값이 양이 된다는 조건을 만족시키기 위해 softmax output form이나 exponential을 활용하면 error function은 다음과 같다.\\[E(w) = - \\sum _{n=1} ^N ln \\ \\{ \\sum_{k=1}^k \\pi_k(x_n,\\boldsymbol{w}) \\mathcal{N}(t_n | \\mu_k(x_n, \\boldsymbol{w}), \\sigma_k^2(x_n, \\boldsymbol{w}) \\}\\]derivative 를 구하는 방식은 5.5.7에서와 유사하게 생각할 수 있을 것이며, mixture model이므로 prior를 정의하고 posterior를 도입하도록 한다.교재에서 제시하는 toy example을 볼 때, 찾고싶은 조건부분포$p(t|x)$는 그림 (c)에서처럼 multimodal이다.mixture model을 통해$p(t|x)$를 구하게 되면 이를 활용한 대표값을 구할 수 있다«««&amp;lt; HEADmixture model을 통해 $p(t|x)$를 구하게 되면 이를 활용한 대표값을 구할 수 있다 =&amp;gt;========&amp;gt; 3d43dae3582fdaaa38969b0e32e7f9823bd71906$E(\\boldsymbol{t}|x) , E(||\\boldsymbol{t} - E(\\boldsymbol{t}|x)||^2|x) $ 그러나 평균값이 항상 데이터를 잘 나타낸다고 할 수는 없다. 로봇팔 문제를 생각해보면 inverse problem에서 두가지 가능한 해의 평균이 옳은 답이라 말하기는 힘들다. 이를 해결하기 위해서는 가능성이 높은 성분의 평균값을 각각의 x값에 대해 구하는 것이다. 이는 그림 (d)에서 잘 나타난다." }, { "title": "PRML-4", "url": "/posts/PRML4/", "categories": "", "tags": "PRML, Machine learning", "date": "2022-01-19 00:00:00 +0900", "snippet": "4. Linear Models for Classification이번 chapter는 “Input space를 K개의 Class로 나누는 것”이 핵심이다. 이때 나눠지는 영역은 decision region, 나누는 boundary를 decision boundary 혹은 decision surface라 한다. 특히 이번 chapter에서 중요한 것은 linear model이다. 즉 분류를 위한 decision surface가 linear function이며 D-dimensional input space를 (D-1)-dimensional hyperplane으로 나누는 것을 의미한다.linear model을 활용한 classification에서 주목하는 세 가지 접근방식은 다음과 같다. three different approaches to the classification Discriminant function ( X를 어떤 class에 할당할지 결정 )inference stage ( set conditional prob dist $p(C_k|\\mathcal{x})$ ) $\\&amp;amp;$ decision stage (use dist to make decision ) 이렇게 두 가지 step으로 나눠서 classification을 할 때 condition prob dist를 어떻게 정할 것인지에 따라 또 나뉜다. parametric model ( 최적 parameter 찾기 ) generative approach ( Bayes’ rule -&amp;gt; posterior) 그러나 classification에서는 linear model의 결과값이 discrete class label과 관련 있어야 하기 때문에 비선형함수인 activation function을 사용한다. (generalized linear model )더 나아가, input space $\\mathcal{X}$를 basis function $\\phi(\\mathcal{x})$을 활용해 확장하고 있는데 이를 통해 좀 더 유연한 모델을 만들어 낼 수 있을 것이다.4.1 Discriminant FunctionsDiscriminant 라는 것은 말 그대로 구분식! 즉, input $\\mathcal{X}$를 어떤 Class에 넣을 것인지 결정해준다! 여기서는 특별히 linear discriminants 에 한정해서 설명하도록 하겠다.“linear discriminants = decision surfaces are hyperplanes”4.1.1 Two Classes [Simplest representation of a linear discriminant]\\[y(\\boldsymbol{x}) = \\boldsymbol{w}^T\\boldsymbol{x} \\ + \\ w_0\\] $y(\\boldsymbol{x})=0$ 은 decision boundary. $\\boldsymbol{w}$ 는 weight vector, decision boundary에 직교하는 벡터, decision boundary 방향 결정 $\\ w_0$ 는 bias -&amp;gt; negative bias는 threshold. negative bias 가 threshold 인 이유* $y(\\boldsymbol{x}) &amp;gt;0 $ 이면 Class 1 으로 판정하기 때문 * $\\boldsymbol{x}$가 decision boundary에 위치할 때, 원점에서 decision boundary 까지 거리는$$\\frac {\\boldsymbol{w}^T\\boldsymbol{x}}{||\\boldsymbol{w}||} = \\frac{-w_0}{||\\boldsymbol{w}||}$$​ $\\because$ x&#39; 을 원점에서 가장 가까운 decision boundary 위의 점이라고 하면, boundary의 직교 벡터 $\\boldsymbol{w}$ 을 활용할 때, 다음이 성립한다$$\\begin{align}&amp;amp;\\mathcal{x}&#39; = \\alpha \\boldsymbol{w} \\ \\Rightarrow \\boldsymbol{w}^T \\cdot \\alpha \\boldsymbol{w} + w_0 = 0 \\ \\Rightarrow \\alpha = \\frac {-w_0}{||\\boldsymbol{w}||^2} \\\\&amp;amp; ||\\mathcal{x}&#39;|| = ||\\alpha \\boldsymbol{w}|| = \\frac{-w_0}{||\\boldsymbol{w}||}\\end{align}$$binary class 이므로 boundary decision 을 기준으로 $y(\\boldsymbol{x})$ 의 부호가 결정되고, 부호값을 통해 class를 판정하게 된다. 따라서 input X가 boundary를 기준으로 얼마나 떨어져 있는지에 대한 수직거리와 방향을 아는 것이 중요한데 이를 $\\gamma \\cdot \\frac {\\boldsymbol{w}}{||\\boldsymbol{w}||}$라고 하자. 그 결과 아래와 같은 그림을 얻을 수 있다.\\[\\boldsymbol{x} = \\boldsymbol{x}_{\\bot} + \\gamma \\cdot \\frac {\\boldsymbol{w}}{||\\boldsymbol{w}||}\\\\\\gamma = \\frac{y(\\boldsymbol{x})}{||\\boldsymbol{w}||}\\]특히 $\\gamma$의 부호 값이 중요하므로, 위와 같이 구하는 것 같다.추가적으로 식을 간편하게 적기 위해dummy input을 활용해 bias를 파라미터로 함께 표현할 수 있다. $\\boldsymbol{\\tilde w} = (w_0, \\boldsymbol{w})$ 에 대해, $y(\\boldsymbol{x}) = \\boldsymbol{\\tilde w}^T \\boldsymbol{\\tilde x}$ 로 표기하면 hyperplane( boundary)는 원점을 통과하는 D - dimensional hyperplane 이다.4.1.2 Multiple Classesbinary class에서 확장해서 multiple class 인 경우를 생각해보자.기존 binary class에서 하던 방식을 그대로 사용할 경우 올바른 분류가 어려울 수 있는데 이유는 아래 그림을 보면 잘 나타난다.이를 피하기 위해서는 아래와 같이 단순하게 K-class discriminant 를 설정할 수 있다.\\[\\begin{align}&amp;amp;y_k(\\boldsymbol{x}) = \\boldsymbol{w}_k^T\\boldsymbol{x} \\ + \\ w_{k0} \\\\&amp;amp;\\textrm{assign x to} \\ \\ C_k \\ \\ \\ \\ \\textrm{if} \\ \\ y_k(\\boldsymbol{x}) &amp;gt; y_j(\\boldsymbol{x}) \\ \\textrm{for all } j \\neq k\\end{align}\\]binary class 와 유사하게 생각한다면 class k 와 class j 사이의 boundary는 $y_k(\\boldsymbol{x}) = y_j(\\boldsymbol{x})$ 를 만족해야하므로 아래와 같다.\\[(\\boldsymbol{w}_k - \\boldsymbol{w_j})^T \\boldsymbol{x} + (w_{k0} - w_{j0}) = 0\\]또한 linear discriminant 에 의해 나눠진 region은 convex set 이다. (증명 생략)4.1.3 Least squares for classificationlinear discriminant의 parameter 값을 찾기 위한 세 가지 방법을 제시한다.첫번째 방법은 Least square 이다.정규성을 가정한 선형회귀분석에서 가장 많이 쓰이는 방법으로 quadratic error를 사용하므로 예측값은 $E(\\boldsymbol{t}|x)$이다그러나 선형모델 자체가 flexibility가 부족하기 때문에 binary class인 경우에도 $E(\\boldsymbol{t}|x)$ 값이 1을 초과할 수 있다.multiple class에서도 Least square를 사용하기 위해 행렬을 사용해 식을 확장해보자.개별 linear discriminant function $ y_k(\\boldsymbol{x}) = \\boldsymbol{w}k^T \\boldsymbol{x} \\ + \\ w{k0} $ 에 대해 다음과 같이 나타낸다.\\[y(\\boldsymbol{x}) = \\boldsymbol{\\tilde W}^T\\boldsymbol{\\tilde x}\\]이 때 $\\boldsymbol{\\tilde W}$ 는 k(class)개의 column을 가지고 있으며 열벡터가 $\\boldsymbol{\\tilde w}k = (w{k0}, \\boldsymbol{w}_k ^T)^T$ 인 행렬이다.Least square에 의해 $\\boldsymbol{\\hat {\\tilde W}} = (\\boldsymbol{\\tilde X}^T\\boldsymbol{\\tilde X} )^{-1}\\boldsymbol{\\tilde X}^T \\boldsymbol{T} = \\boldsymbol{\\tilde X}^{\\dagger} \\boldsymbol{T} \\Rightarrow y(\\boldsymbol{x}) = \\boldsymbol{\\hat {\\tilde W} }^T \\boldsymbol{\\tilde x}$이로부터 얻은 벡터 $y(\\boldsymbol{x})$ 에 대해서 그 원소들 중 가장 큰 값의 class로 예측하게 된다. (제약식을 통해 y(x)의 sum이 1이 되게 하고 벡터의 각 원소들이 0과 1 사이가 되도록 하면 model output을 probabilistic 하게 해석할 수 있다.)Least square는 closed form으로 해를 구할 수 있는 만큼 매우 간단하고 좋은 방법이지만 outlier에 민감하게 반응하며 가우시안을 가정한 경우에는 LS와 ML 방식의 결과가 동일한데, gaussian이 아닌 여러가지 분포들 대해서는 LS를 사용할 때 바람직한 결과를 얻지 못할 우려가 있다는 것도 알아둬야 한다.4.1.4 Fisher’s linear discriminantlinear discriminant의 parameter 값을 찾기 위한 두 번째 방법은 Fisher’s linear discriminant 이다. 이 방법의 핵심은 바로 차원 축소에 있다.X : D-dimension $\\Rightarrow $ one-dimension : $y = \\boldsymbol{w}^T \\boldsymbol{x}$차원 축소는 본질적으로 정보의 손실을 막을 수 없으며, 본래 D 차원의 공간이 1차원(line)으로 축소되며 overlapping이 발생할 수밖에 없다. 이를 보완하기 위해 집단 간 차이는 최대로 하되, 집단 내부의 분산은 최소화되도록 하는 projection을 선택해야 한다.* 집단 간 차이 최대적절한 weight vector $\\boldsymbol{w}$를 잘 선택해서 class separation을 최대로 하는 projection을 선택한다면 정보의 손실을 어느정도 보완할 수 있다. 즉, 볼드체의 m 이 분류된 집단의 평균값이 라 할 때$$m_2 - m_1 = \\boldsymbol{w}^T(\\boldsymbol{m}_2 - \\boldsymbol{m}_1) \\ \\ \\ \\ \\ \\ \\textrm{where} \\ m_k = \\boldsymbol{w}^T \\boldsymbol{m_k} \\ \\ \\ \\ \\textrm{(mean of projected data from class)}$$값을 최대화하는 길이 1의 벡터인 $\\boldsymbol{w}$ 를 찾으면 된다(길이를 1로 둠으로써 $m_2-m_1$이 무한정 커지진 않도록 제약을 준다) Lagrange multiplier를 사용하면 다음과 같은 결과를 얻는다$$\\boldsymbol{w} \\propto (\\boldsymbol{m}_2 - \\boldsymbol{m}_1)$$* 집단 내 분산 최소within class variance of transformed data from class $C_k$는 다음과 같이 정의한다.$$s_k^2 = \\sum_{n \\in C_k} (y_n - m_k)^2 \\ \\ \\ \\ \\textrm{where} \\ y_n = \\boldsymbol{w}^T\\boldsymbol{x_n}$$이 때 binary classification 의 경우 total within class variance는 $s_1^2 + s_2^2$이를 만족하는 projection vector w를 찾기 위해 Fisher는 다음과 같은 기준을 제시했다.\\[\\begin{align}&amp;amp;\\mathcal{J}(\\boldsymbol{w}) = \\frac{(m_2 - m_1)^2}{s_1^2 + s_2^2} = \\frac{\\boldsymbol{w}^T \\boldsymbol{S}_B \\boldsymbol{w}}{\\boldsymbol{w}^T \\boldsymbol{S}_W\\boldsymbol{w}} \\\\ \\\\&amp;amp;S_B = (\\boldsymbol{m}_2 - \\boldsymbol{m}_1)(\\boldsymbol{m}_2 - \\boldsymbol{m}_1)^T\\\\&amp;amp;S_W = \\sum (\\boldsymbol{x}_n - \\boldsymbol{m}_1)(\\boldsymbol{x}_n - \\boldsymbol{m}_1)^T + \\sum (\\boldsymbol{x}_n - \\boldsymbol{m}_2)(\\boldsymbol{x}_n - \\boldsymbol{m}_2)^T\\end{align}\\]이 때 J 를 w 로 미분하면 $\\mathcal{J}(\\boldsymbol{w})$는 $(\\boldsymbol{w}^T \\boldsymbol{S}_B \\boldsymbol{w})\\boldsymbol{S}_W\\boldsymbol{w} = (\\boldsymbol{w}^T \\boldsymbol{S}_W\\boldsymbol{w})\\boldsymbol{S}_B \\boldsymbol{w}$ 를 만족할 때 최대가 됨을 알 수 있다. $S_B$ 식으로부터 $S_B\\boldsymbol{w}$ 는 $\\boldsymbol{m}_2 - \\boldsymbol{m}_1$ 와 비례함을 알 수 있으므로 $\\boldsymbol{w} \\propto S_W^{-1}(\\boldsymbol{m}_2 - \\boldsymbol{m}_1)$ 이다. 이를 만족하는 $\\boldsymbol{w}$를 Fisher linear discriminant 라고 한다. (사실 discriminant 라기 보다는 projection direction을 의미한다고 말하는게 더욱 맞다)4.1.5 Relation to least squares Least -Square : target value를 최대한 정확하게 맞출 수 있을지(error를 최소화) Fisher-criterion : target의 class를 정확하게 분류할 수 있을지(maximum class separation) 그러나 1 - of -K coding (K class 중 가장 높은 확률값을 가지는 class 를 선택)이 아닌 다른 target coding scheme을 사용할 때, Least - square 와 Fisher solution은 동일하게 생각할 수 있다. 아래는 그 방법을 나타낸 것이다. [different target coding scheme for binary] target for class $C_1$ to be $N/N_1$, target for class $C_2$ to be $- N/N_2$라고 두면 sum of squares error function은 다음과 같다\\[E = \\frac{1}{2} \\sum_{n=1}^N (\\boldsymbol{w}^T \\boldsymbol{x}_n + w_0 - t_n ) ^2\\]이를 $\\boldsymbol{w}$ 와 $w_0$로 미분하면\\[w_0 = -\\boldsymbol{w}^T \\boldsymbol{m} \\\\(S_W + \\frac{N_1 N_2}{N}S_B)\\boldsymbol{w} = N(\\boldsymbol{m}_1 - \\boldsymbol{m}_2)\\]이므로 $S_B \\boldsymbol{w}$가 $\\boldsymbol{m}_2 - \\boldsymbol{m}_1$의 방향을 나타내는 것을 고려할 때, 결국 Least-square에서도 Fisher - criterion에서 얻은 $\\boldsymbol{w} \\propto S_W^{-1}(\\boldsymbol{m}_2 - \\boldsymbol{m}_1)$ 식을 얻게 됨을 알 수 있다.4.1.6 Fisher’s discriminant for multiple classes앞서 Fisher-criterion을 설명할 때는 binary class를 기반으로 input space 차원 축소를 1차원으로 했다면 multiple class 의 경우 inpute space 차원 축소를 D’ 차원으로 해 볼 것이다. multiple class 이므로 weight vector $\\boldsymbol{w}$ 를 column으로 하는 행렬 $\\boldsymbol{W}$를 생각하자. 즉 모델은 아래와 같다.\\[y =\\boldsymbol{W}^T \\boldsymbol{x}\\]within-class covariance matrix to the case of K classes\\[S_W = \\sum ^K S_k \\ \\ \\textrm{where} \\ \\ S_k = \\sum (\\boldsymbol{x}_n - \\boldsymbol{m}_k)(\\boldsymbol{x}_n - \\boldsymbol{m}_k)^T \\ \\ \\&amp;amp; \\ \\ \\boldsymbol{m}_k = \\frac{1}{N_k}\\sum_{n \\in C_k}\\boldsymbol{x_n}\\]Total covariance matrix\\[S_T = \\sum_{n=1}^N (\\boldsymbol{x}_n - \\boldsymbol{m})(\\boldsymbol{x}_n - \\boldsymbol{m})^T\\]Between class covariance\\[S_B = \\sum ^K N_k(\\boldsymbol{m}_k - \\boldsymbol{m})(\\boldsymbol{m}_k - \\boldsymbol{m})^T\\]세가지 공분산 행렬은 $S_T = S_B + S_W$ 관계를 만족한다.D’ 차원으로 projection한 데이터에 대해서도 유사한 공분산 행렬(소문자 s 사용)을 정의할 수 있다.binary class와 유사하게 Fisher-criterion $\\mathcal{J}(\\boldsymbol{W}) = Tr(s_W^{-1}s_B)$ 로 구할 수 있고 projection 이전의 데이터를 사용할 때 $\\mathcal{J}(\\boldsymbol{w}) = (\\boldsymbol{W}^T \\boldsymbol{S}_W \\boldsymbol{W})^{-1} \\boldsymbol{W}^T \\boldsymbol{S}_B\\boldsymbol{W}$ 이다.즉 weight vlaue ($\\boldsymbol{W}$)는 $S_W^{-1}S_B$ 의 eigenvector에 의해 결정되고 ??4.1.7 The perceptron algorithm…4.4 The Laplace ApproximationBayesian treatment of logistic regression 에서는 $p(C_k | \\boldsymbol{x})$가 더이상 Gaussian이 아니므로 적분이 어렵다. 따라서 Laplace apporximation을 통해서 확률밀도에 대한 Gaussian approximation을 하려고 한다.알고 싶은 확률밀도 $p(z)$ 에 대해$f(z)$를 활용해 근사한다고 하자.\\[p(z) = \\frac {1}{Z}f(z)\\]step 1 : $p(z)$ 의 mode 값 $z_0$을 찾는다step 2 : $ln f(z)$를 mode인 $z_0$에 대해 Talyor expansion 한다\\[ln f(z) \\ \\simeq \\ ln f(z_0) - \\frac{1}{2}(z - z_0)^TA(z - z_0) \\\\f(z) \\ \\simeq \\ f(z_0)exp\\{ - \\frac{1}{2}(z - z_0)^T A (z- z_0) \\} \\\\\\textrm{where} \\ \\ A = - \\nabla \\nabla ln f(z) |_{z=z_0}\\]step 3 : Gaussian 에 근거해서 normalized dist q(z) 로 근사한다\\[q(z) = (\\frac{|A|^{1/2}}{(2\\pi)^{M/2}}) exp\\{ - \\frac{1}{2}(z - z_0)^T A (z- z_0) \\}\\](단, precision matrix인 A는 positive definite 이어야 한다.)데이터가 많아지면 Gaussian으로의 근사가 더욱 효과적일 것이다(CLT)그러나 1. multimodal 인 경우 위의 Laplace apporximation은 한계가 있다. 2. 또한, Gaussian을 사용해서 근사를 하기 때문에 real variable로 정의된 함수에 대해서만 근사가 가능하다(즉 양수인 경우 로그변환이 필요). 3. 무엇보다 distribution에만 집중하여 global properties를 간과해선 안된다.(10장 variational inference and regression 부분에서 이를 자세히 배울 것)4.4.1 Model comparison and BIC$p(z)$를 근사하기 위해서는 normalization constant Z에 대해서도 알아야한다. Gaussian approximation $f(z)$에 대해서 다음이 성립한다.\\[\\begin{align}Z &amp;amp; = \\int f(z) dz \\\\&amp;amp; \\simeq f(z_0)\\int exp\\{ - \\frac{1}{2}(z - z_0)^T A (z- z_0) \\} dz \\\\&amp;amp; = f(z_0) \\frac{(2\\pi)^{M/2}}{|A|^{1/2}} \\textrm{----- * }\\end{align}\\]또한 모델의 집합 ${ \\mathcal{M}_i }$ 에 대해 각 모델의 parameter를 ${ \\theta_i }$ 라고 할 때 model evidence $p(\\mathcal{D} | \\mathcal{M}_i)$ 는 다음과 같이 쓸 수 있다.\\[p(\\mathcal{D}) = \\int p(\\mathcal{D}|\\theta) p(\\theta) d\\theta = \\int f(\\theta) d\\theta\\]normalization constant 근사식(*)을 활용할 때, 위 식을 다시 써보자.\\[p(\\mathcal{D}) = f(\\theta_{MAP})\\frac{(2\\pi)^{M/2}}{|A|^{1/2}} = p(\\mathcal{D}|\\theta_{MAP}) p(\\theta_{MAP}) \\frac{(2\\pi)^{M/2}}{|A|^{1/2}} \\\\ln \\ P(\\mathcal{D}) \\simeq ln \\ p(\\mathcal{D}|\\theta_{MAP}) + \\ln p(\\theta_{MAP}) + \\frac{M}{2} ln \\ 2\\pi - \\frac{1}{2} ln |A|\\]첫 번째 term은 log-likelihood 이고 두 번째 term 부터는 model complexity term이다. 그리고 matrix A는 posterior$p(C_k | \\boldsymbol{x})$에 대한 Hessian이다.이 때, Gaussian prior의 분산을 매우 크게 하면 상수처럼 취급될 수 있으므로 positive definte matrix A 에 대해 다음이 성립한다.\\[ln \\ P(\\mathcal{D}) \\simeq ln \\ p(\\mathcal{D}|\\theta_{MAP}) - \\frac{M}{2} ln \\ N + C\\]즉 이는 model selection에서 지표로 사용하는 BIC와 동일한 form임을 알 수 있다.(사실 $-2 ln \\ p(\\mathcal{D}$) 가 BIC 와 form이 완벽히 일치한다.)4.5 Bayesian Logisitic Regression앞서 설명한대로 sigmoid 함수에 대한 적분이 쉽지 않기 때문에, logistic regression 에 대한 Bayesian inference를 위해 새로운 접근법이 필요하다 $Rightarrow$ Laplace approximation4.5.1 Laplace approximationposterior에 대한 Gaussian representation을 행할 것이므로 prior를 Gaussain으로 생각해보자.\\[p(w) = \\mathcal{N}(w|m_0, S_0)\\]이때 posterior는 다음과 같다.\\[\\begin{align}&amp;amp;p(w|\\boldsymbol{t}) \\propto p(w)p(\\boldsymbol{t}|w) \\\\ &amp;amp;ln \\ p(w|\\boldsymbol{t}) = -\\frac{1}{2}(w-m_0)^T S_0 ^{-1}(w-m_0) + \\sum {t_n ln \\ y_n + (1-t_n) ln \\ (1-y_n)} + C \\\\&amp;amp;\\textrm{where} \\ \\ \\ \\ p(\\boldsymbol{t}|w) = \\prod y_n^{t_n} \\{1- y_n \\}^{1-t_n}\\end{align}\\]Laplace approximation의 논리와 동일하게 MAP 값으로 Taylor expansion 하면 posterior 에 대한 Gaussian 근사는 다음과 같다\\[q(w) = \\mathcal{N}(w|w_{MAP}, S_N) \\\\\\textrm{where} \\ \\ S_N = - \\nabla \\nabla ln \\ p(w| \\boldsymbol{t})\\]4.5.2 Predictive distribution이제 predictive distribution을 생각해보자. 새로운 feature vector $\\phi(x)$ 가 주어졌을 때 class $\\mathcal{C_1}$ 에 대한 predictive distribution은 다음과 같이 정의 및 근사 된다.\\[p(\\mathcal{C}_1|\\phi, \\boldsymbol{t}) = \\int p(\\mathcal{C}_1|\\phi, w) \\ p(w|\\boldsymbol{t}) dw \\simeq \\int \\sigma(w^T \\phi) \\ q(w) dw\\]이때 Gaussian의 marginal dist 또한 Gaussian이므로 $w$ 를 marginalized out 시킨 $p(a) = \\int \\delta(a - w^T\\phi) q(w) dw$ 를 활용해서 아래와 같이 적을 수 있다.\\[p(\\mathcal{C}_1|\\boldsymbol{t}) \\simeq \\int \\sigma(a) p(a) \\ da = \\int \\sigma(a) \\mathcal{N}(a|\\mu_a, \\sigma_a^2) \\ da\\]첫번째 근사는 미분방정식을 활용해서, 두번째 등식은 marginal dist$p(a)$가 Gaussian의 marginal임을 활용해서 전개한 것이다.위 식은 Gaussian과 sigmoid의 convolution을 나타낸 것이므로 계산하기가 까다로우나, sigomid function 대신 probit function을 사용하면 analytic한 결과를 얻을 수 있다.\\[p(\\mathcal{C}_1|\\boldsymbol{t}) \\simeq \\int \\Phi(\\lambda a) \\ \\mathcal{N}(a|\\mu_a, \\sigma_a^2) \\ da \\simeq \\sigma(\\kappa(\\sigma_a^2)\\mu_a)\\]“Marginalization of the logistic sigmoid model under a Gaussian approximation to the posterior dist will be illustrated in the context of variational inference in Fig 10.13”" }, { "title": "Computer Age Statistical Inference - chap 15", "url": "/posts/CASI15/", "categories": "", "tags": "datascience, statistical method, Efron", "date": "2021-11-21 00:00:00 +0900", "snippet": "Large-Scale Hypothesis Testing and False-Discovery Rateslarge-scale data analysis like microarrays -&amp;gt; thousands of simultaneous hypothesis test15.1 Large-Scale Testing앞선 여러 장에서 prostate cancer data를 활용한 여러가지 예제들을 살펴보았었다.이 데이터는 6033 by 102 Matrix 이며 columns은 cancer pateints 52, normal controls 50 으로 이뤄져있다.6033개의 gene에 대해 각각 Two-sample t-test를 실행하면 각각의 t-statistic 은 자유도가 100인 t 분포를 따른다 할 수 있다. 즉,\\[\\begin{align}&amp;amp; i=1,\\cdots , 6033 \\ \\ , \\ \\ j= 1, \\cdots , 52\\\\&amp;amp; x_{1ij} \\sim N(\\mu_{1i}, \\sigma^2) \\\\&amp;amp; x_{2ij} \\sim N(\\mu_{2i}, \\sigma^2) \\\\&amp;amp; \\textrm{under null,} \\ \\ t_i = \\frac {\\bar x_{1i}-\\bar x_{2i}}{\\hat {sd}_i} \\ \\ \\sim t_{100}(\\delta_i) \\ \\ \\textrm{where} \\ \\ \\delta_i = \\frac {\\mu_{1i} - \\mu_{2i}} {\\sigma} \\\\\\end{align}\\]이제 확률적분변환을 활용해서, 귀무가설하에서의 normal을 따르는 Z statistic을 만들자.\\[Z_i = \\Phi^{-1}(F_{100}(t_i)) \\approx N(\\mu_i, 1) \\ \\ \\textrm{where} \\ \\ F_{100} : \\textrm{cdf of} \\ \\ t_{100}\\]만약 비중심모수인 $\\delta_i$ 가 0이라면 Z 값은 normal을 따를 것이며 아래의 붉은색 그래프를 따르게 될 것이다.그러나 만들어진 Z staitstic의 분포가 이와 다르다면 귀무가설(treatment와 control이 동일한 분포를 갖는다)에 위배되는 case들이 몇몇 존재한다고 판단할 수 있을 것이다.그런데 i의 값은 1부터 6033이므로, treament와 control가 동일한 분포를 따른다고 결론짓기 위해서는 6033개의 모든 유전자가 동일해야만 한다. 이말인즉슨, 6033개의 가설을 동시에 검정하면서도 그 검정의 유의수준이 type - 1 error를 넘지않도록 하는 것이 중요하다. 만일 적절한 다중검정법을 사용하지 않고, 개별적인 가설검정을 유의수준 $\\alpha$에서 행한다면, 귀무가설을 따름에도 불구하고 가설이 기각되어 전체 검정의 type-1 error가 매우 커질 것이다.이제 다중검정에서 Type - 1 error를 control 하는 방법에 대해 알아보자.본 책에서는 크게 두가지 지표(1.Family - wise error rate , 2. False Discovery Rate)를 활용한 방법을 제시한다. FDR에 관한 이야기는 15.2에서 다루고, 여기서는 FWER을 사용해서 Type - 1 error 를 control하는 방법으로서 Bonferroni procedure와 Holm’s procedure을 소개하겠다.FWER(Family-Wise-Error Rate)우선 FWER의 정의는 아래와 같다.FWER = $P$ ( reject at least one $H_{oi}$ for $i \\in I_o$) where $I_o = \\textrm{the set of true null} \\subset {1,2,\\cdots, N }$즉, null에 속함에도 불구하고, 기각이 되는 case가 하나라도 존재할 확률을 의미한다.[Bonferroni procedure]n 개의 가설에 대해서 유의수준 $\\alpha$의 다중검정을 하기 위해서는 각 개별 가설에 대한 유의수준을 $\\frac {\\alpha}{N}$ 으로 잡는 검정법을 말한다. 이를 통해서 FWER을 수준 $\\alpha$ 로 통제할 수 있다.증명은 Boole’s inequality를 사용한다.\\[\\begin{align}\\textrm{FWER} &amp;amp; = P(\\cup_{i\\in I_o} \\{P_i \\leq \\frac {\\alpha}{N} \\}) \\\\ &amp;amp; \\leq \\sum_{i\\in I_o} \\{P_i \\leq \\frac {\\alpha}{N} \\}) \\\\ &amp;amp; = \\sum_{i\\in I_o} \\frac {\\alpha}{N} \\\\ &amp;amp; = \\frac {N_0 \\alpha} {N} \\\\ &amp;amp; \\leq \\alpha\\end{align}\\]Bonferroni procedure는 p-value들이 dependent 하더라도 FWER을 control할 수 있다. 다만, 이 방법은 매우 보수적인 방법이라 N이 커지게 되면 검정의 Power 가 매우 낮아진다.[Holm’s procedure]Bonferroni procedure의 장점을 가지고 있으며( dependent p-value 에 대해 control 가능) 단점을 보완한 방식이다. 즉 검정의 power가 더 크다. 그럼에도 불구하고 사람들이 Bonferroni procedure을 사용하는 이유는 단지 쉬워서….이 방식은 step-wise procedure라서, p-value를 순차적으로 나열한 뒤에 특정 기준 값 이하인 모든 해당 검정들을 기각하고, p-value가 특정 값을 넘어가면 그 이후의 p-value와 관련한 모든 검정들은 기각을 한다.(정확히는 가장 유의한 p-value 부터 검정하는 step-down 방식으로 뒤에 소개될 BH procedure와 반대된다)procedure를 자세히 소개해보면\\[\\begin{align}&amp;amp; \\textrm{Reject } H_{o(1)} \\textrm{ if } P_{(1)} \\leq \\frac {\\alpha}{N-1+1} = \\frac {\\alpha}{N} \\\\&amp;amp; \\textrm{Reject } H_{o(2)} \\textrm{ if } P_{(2)} \\leq \\frac {\\alpha}{N-2+1} = \\frac {\\alpha}{N-1} \\\\&amp;amp; \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\vdots \\\\&amp;amp; \\textrm{Repeat until } P_{(i_0)} \\geq \\frac {\\alpha}{N-i_o+1}\\\\&amp;amp; \\textrm{then stop. reject } H_{o(1)}, \\cdots, H_{o(i_0 -1)} \\textrm{ don&#39;t reject } H_{o(i_0)}, \\cdots\\end{align}\\]즉 $i_0 = min {i : P_{(i)} &amp;gt; \\frac {\\alpha} {N-i+1} }$ 이며 cut-off value는$\\frac {\\alpha} {N-i+1}$ 이다.procedure에서도 알 수 있듯, 한번 기각을 하게되면 그 이후로 나오는 가설들을 따로 검정 않고 모두 기각한다는 특징을 가지고 있다.증명은 아래와 같다.\\[\\begin{align}\\textrm{FWER} &amp;amp; = P(\\cup_{i\\in I_o} \\{P_i \\leq \\frac {\\alpha}{N} \\}) \\\\ &amp;amp; = P(H_{0(j)} \\textrm{ is rejected}) \\\\&amp;amp; = P(P_{(1)} \\leq \\frac {\\alpha}{N}, \\cdots , P_{(j)} \\leq \\frac {\\alpha}{N-j+1} )\\\\&amp;amp; \\leq P(P_{(j)} \\leq \\frac {\\alpha}{N-j+1}) \\\\&amp;amp; = P(min_{i\\in I_o} P_i \\leq \\frac {\\alpha}{N-j+1}) \\\\&amp;amp; \\leq P(min_{i\\in I_o} P_i \\leq \\frac {\\alpha}{N_o})\\\\&amp;amp; = P(\\cup_{i\\in I_o} \\{P_i \\leq \\frac {\\alpha}{N_o} \\}) \\\\&amp;amp; \\leq \\sum_{i\\in I_o} \\{P_i \\leq \\frac {\\alpha}{N_0} \\}) \\\\ &amp;amp; = \\sum_{i\\in I_o} \\frac {\\alpha}{N_0} \\\\ &amp;amp; = \\frac {N_0 \\alpha} {N_0} \\\\ &amp;amp; = \\alpha\\end{align}\\]Bonferroni procedure와 다르게 Holm’s procedure는 각 가설에 대한 유의수준이 달라진다. 즉 각 critical value에 대해\\[\\alpha^H(i) \\geq \\alpha^B(i)\\]15.2 False-Discovery Rates15.3 Empirical Bayes Large-Scale Testing" }, { "title": "Computer Age Statistical Inference - chap 11", "url": "/posts/CASI11/", "categories": "", "tags": "datascience, statistical method, Efron", "date": "2021-11-17 00:00:00 +0900", "snippet": "Bootstrap Condfidence Intervals일반적으로 CI를 구한다고 하면 다음과 같은 form을 떠올릴 것이다.\\[\\hat \\theta \\ \\pm \\ 1.96 \\hat{se}\\]그러나 만약 데이터들이 포아송분포를 따른다고 하면, 위와 같은 형태로 신뢰구간을 구할 때 asymmetric distribution의 특징을 제대로 잡아내지 못할 것이다. 11.1 Neyman’s Construction for One-Parameter Problems우선 pivot에 대해 간단히 언급하도록 하겠다.pivot이란, 분포가 파라미터 값에 의존하지 않는 확률변수를 의미힌다. 예를들어 $\\bar X \\sim N(\\mu,1)$ 인 경우 $\\bar X - \\mu \\sim N(0,1)$ 를 pivot이라 한다. 따라서 이를 활용해 표본평균에 대한 신뢰구간을 구하면\\[P_{\\mu} (-Z_{\\alpha/2} \\leq \\sqrt{n}(\\bar X - \\mu) \\leq Z_{\\alpha/2}) = 1-\\alpha\\]다음으로 Neyman’s construction에 대해 설명하겠다.간단하게 설명하자면 Neyman’s construction이란 통계량의 함수를 찾아내어 원하는 신뢰수준에 대한 신뢰구간을 적분을 통해 구하는 것이다.예를들어, 추정하고자 하는 파라미터가 ‘상관계수’라고 할 때, bivariate normality 가정하에 sample correlation에 대한 분포를 구할 수 있다.현재 가지고 있는 데이터에서 sample correlation이 0.498 이므로 위 식에서 $\\theta = 0.498 = \\hat \\theta_{sample}$ 일 것이다.alpha - quantile of $\\hat \\theta$ for $\\theta$ 를 $q_{\\alpha}(f_{\\theta})$ 라고 할 때 $P_{\\theta}(\\hat \\theta \\leq q_{\\alpha/2}(f_{\\theta})) = \\alpha /2$ 와 $P_{\\theta}(\\hat \\theta \\geq q_{1-\\alpha/2}(f_{\\theta})) = 1 - \\alpha /2$ 를 만족하는 quantile을 사용해서 신뢰구간에 대한 Neyman’s construction을 구하면\\[I_{\\theta}(\\hat \\theta) = I \\{g_{\\alpha/2}(f_{\\theta}) \\leq \\hat \\theta \\leq g_{1- \\alpha/2} (f_{\\theta}) \\}\\]이제 $\\hat \\theta$에 대한 분포를 활용해서 논의를 전개해보자. 위에서 Neyman’s construction으로 신뢰구간을 구했는데, 이때 $\\alpha/2, 1- \\alpha/2$ quantile 값을 각각 $\\hat \\theta_{lo} , \\hat \\theta_{up} $ 라고 하자.$\\hat \\theta$ 에 대한 분포의 $\\theta$ 값에 기존의 $\\hat \\theta_{sample}$ 을 plug-in 한 것 이외에도 $\\hat \\theta_{lo} , \\hat \\theta_{up} $ 을 plug-in 하면 아래와 같은 분포를 그릴 수 있다.빨간색은 $\\theta = 0.498$ 이며 점선으로 표시된 분포는 $\\theta$ 에 $\\hat \\theta_{lo} , \\hat \\theta_{up} $ 를 각각 대입한 것이다.이 그림이 나타내는 바는 $\\hat \\theta_{sample}$ 값이 점선으로 그려진 그래프의 $\\alpha/2, 1- \\alpha/2$ quantile 와 같아진다. 누적분포함수는 $\\theta$ 에 따라 감소하는 함수이고, 반대로 quantile 함수는 $\\theta$ 에 따라 증가하는 함수이다. 증명은 다음과 같다.(엄밀하진 않다. numerically)11.2 The Percentile Method(Neyman’s construction 과 연결되어 있음)이제 part 1 에서 설명한 두 내용(pivot, Neyman)을 활용해서 bootstrap CI를 만들어보자. bootstrap 의 목적은 기본적으로 se에 대한 추정이고 이를 활용해서 신뢰구간을 구할 수 있다. pivot은 $\\hat \\theta - \\theta \\approx N(0, \\hat {se}^2_{boot})$ 이고 분포를 알고 있기 때문에 신뢰구간은 quantile을 활용해서 쉽게 구할 수 있다.\\[P_{\\theta} (q_{\\alpha/2} \\leq \\hat \\theta - \\theta \\leq q_{1-\\alpha/2}) = 1-\\alpha\\] 만일 pivot의 분포를 모른다면, bootstrap distribution을 구해야 한다.$\\hat \\theta^{\\star} - \\hat \\theta \\sim g^{\\star}$ 일 때 bootstrap sample을 활용한 누적분포를 $\\hat G(t)$라고 하면 $\\hat G(t) = \\frac{ \\textrm{number} (\\ b \\ : \\ \\hat \\theta^{\\star b} \\leq t ) }{B}$ 이고 여기서 quantile을 뽑아내면 $q_{\\alpha}^{\\star} = \\hat G ^{-1} (\\alpha) $ 이므로 bootstrap CI는(Neyman’s construction)\\[\\theta \\in (q_{\\alpha/2}^{\\star} , q_{1-\\alpha/2}^{\\star})\\]아래 그림은 bootstrap CI를 나타낸 것인데, skewed to left임으로 bootstrap CI는 normal을 가정한 CI에 비해 왼쪽으으로 치우치게 된다.Transformation Invarianceestimator는 여러가지 변환을 통해 새로운 estimator를 만들어내는데, 이때에 변환에 의해 만들어진 새로운 추정량에 대한 bootstrap CI를 만들어 내고 싶을 수 있다. strictly monotone increasing function $\\phi = m(\\theta)$ 에 대해서 CI 또한 일대일 대응으로 변환 된다.\\[C^{\\phi}(\\hat \\phi) = \\{\\phi = m(\\theta) \\ \\ for \\ \\ \\theta \\in C(\\hat \\theta) \\}\\]이와 관련한 대표적인 예시로, Fisher’s Z-transformation을 들 수 있다. 상관계수 $\\theta$에 대해서 변환 $\\phi = m(\\theta) = \\frac {1}{2} log (\\frac {1+\\theta}{1-\\theta})$ 을 적용하면\\[\\hat \\phi \\approx N(\\phi, \\frac{1}{n-3})\\]이므로 $\\phi$ 에 대한 신뢰구간을 normal 분포에서 구한 뒤, $\\theta$에 대한 신뢰구간으로 변환해서 구할 수 있다.물론 $\\hat \\theta \\approx N(\\theta, (1-\\hat \\theta^2)^2$) 임을 활용해서 CI를 구해도 되겠지만, 이는 n이 충분히 클 때이고, normal 가정 없이 fisher transformation을 활용한 방법이 coverage prob이 더 좋으며 수렴 속도도 더 빠르다고 알려져있다.11.3 Bais-Corrected Condfidence IntervalsPart 2에서는 bootstrap을 통한 percentile method for CI를 소개했다. Part 3 에서는 Bias - Corrected method for CI 와 Bias - Corrected and Accelerated method for CI 에 대해 소개하겠다.우선 Bias - Corrected method 는 이론적으로 증명된 것이 아니지만, Bias - Corrected and Acclerated method 는 이론적으로 증명되었으며 수렴속도가 더 빠르다는 것을 밝힌다.Bias - Corrected method앞서 percentile method와 transformation을 통해 구한 신뢰구간은 unbiasness 를 가정하는 것이나, bias 의 가능성을 완전히 배제할 수 없다.예를 살펴보자.sample correlation이 0.498고, $\\hat \\theta$ 에 대한Fisher’s Z - transformation에 의해 $\\hat \\phi \\approx N(\\phi, \\frac{1}{n-3}) $ 임을 알고 있다.bootstrap sampling 이후 transformation을 적용하면\\[P \\{\\hat \\phi^{\\star} \\leq \\hat \\phi \\} = 0.5\\]이므로 transformation을 역으로 적용하면\\(P \\{\\hat \\theta^{\\star} \\leq \\hat \\theta \\} = 0.5\\)로 기대된다.그러나 이미 상관계수에 대한 분포를 알고 있으므로 이를 통해 계산해보았을 때\\[\\int_{-\\infty}^{0.498} f_{0.498}(\\hat \\theta^{\\star}) d \\hat \\theta^{\\star} = 0.478\\]임을 알 수 있다. 즉, $\\int_{-\\infty}^{\\hat \\theta_{sample}} f_{\\hat \\theta_{sample}}(\\hat \\theta) d \\hat \\theta = 0.5$ 이므로 $\\hat \\theta^{\\star}$ 가 upwardly biased 임을 알 수 있다. 따라서 boostrap CI는 downwardly 조정될 필요가 있다.일반적으로 볼 때, $P {\\hat \\theta^{\\star} \\leq \\hat \\theta } = 0.5$ 이면 bootstrap distribution에 bias 가 없다 $P {\\hat \\theta^{\\star} \\leq \\hat \\theta } &amp;gt; 0.5$ 이면 bootstrap distribution이 downward bias를 가지고 있다 $P {\\hat \\theta^{\\star} \\leq \\hat \\theta } &amp;lt; 0.5$ 이면 bootstrap distribution이 upward bias를 가지고 있다 bias가 있는 경우 이를 해결하기 위해 bias corrected quantile을 잡는 방법은 다음과 같다 $ p_0 $ = $ \\textrm{number} \\ (\\hat \\theta^{\\star b} \\leq \\hat \\theta) / B$ $z_0 = \\Phi^{-1}(p_0) $ $\\hat \\theta_{BC}[\\alpha] = \\hat G^{-1}[\\Phi(2z_0 + z^{(\\alpha)})]$여기서 $z_0$ 는 downward bias 인 경우 양수로, 반대의 경우 음수로 설정될 것.[증명은 따로 정리할 것]Remarks\\[\\begin{align}se(z_0) &amp;amp; = se(\\Phi^{-1}(p_0)) \\\\ &amp;amp; \\approx se(\\Phi^{-1}(p_{true} ) \\ \\ + \\ \\ \\frac{\\partial \\Phi^{-1}}{\\partial p}|_{p_0=p_{true}} (p_0 - p_{true})) \\\\ &amp;amp; = se(\\frac{1}{\\phi(\\Phi^{-1}(p_{true}))}(p_0 - p_{true})) \\\\ &amp;amp; = \\frac {1}{\\phi(z_{true})} \\sqrt{\\frac {p_{true}(1-p_{true})}{B}} \\end{align}\\]$\\because$ $p_0$가 binomial을 따르므로Bias - Corrected and Acclerated methodsampling distribution이 bias가 존재하며 분산이 일정하지 않는 경우이다. monotone increasing function $\\phi$에 대해 $\\hat \\phi = m(\\hat \\theta) \\sim N(\\phi - z_0 \\sigma_{\\phi}, \\sigma_{\\phi}^2)$ 와 같은 경우를 예로 생각해볼 수 있다. 여기서 $\\sigma_{\\phi} = 1 + a\\phi$ 이다. 이때 CI를 만드는 qunatile에 해당하는 값은$\\hat \\theta_{BCa}[\\alpha] = \\hat G^{-1} [\\Phi(z_0 + \\frac {z_0 + z^{\\alpha}} {1-a(z_0 + z^{\\alpha})} )]$remarkspercentile 방법과 BC 방법은 bootstrap sample 만 구하면 qunatile 을 구하는데 있어 매우 쉽다.(automatic) 그러나 BCa 방법은 a 의 값을 따로 정해줘야한다.아래 두 테이블은 제시된 방법들의 신뢰구간을 보여준다. BCa 방법이 Neyman’s construction 으로 구한 exact 값과 유사한 것을 알 수 있다.11.5 Bootstrap -t Intervalstwo sample t-test 방법을 차용한다. transformation invariant 하지 않고 추가적인 scaling 이 필요하다.각 집단에서 bootstrap sample을 각각 추출한 뒤, boostrap distribution\\[t^{\\star} = \\frac {\\hat \\theta^{\\star} - \\hat \\theta}{\\hat {se}}\\]을 만들어낸다. 이는 normality assumtion 하에서 만들어진 것이다.이 때 신뢰구간의 하한과 상한은 $\\hat \\theta_t^{\\star}[\\alpha /2] = \\hat \\theta - \\hat{se}^{\\star} \\ t_{df}(1-\\alpha/2)$ $\\hat \\theta_t^{\\star}[1-\\alpha /2] = \\hat \\theta - \\hat{se}^{\\star} \\ t_{df}(\\alpha/2)$만일 paried sample 인 경우 sampling 또한 pair로 해야한다." }, { "title": "MNIST ipynb 파일 업로드 수정중", "url": "/posts/mnist/", "categories": "", "tags": "datascience, statistical method", "date": "2021-11-12 00:00:00 +0900", "snippet": "import pandas as pdimport osimport numpy as npimport matplotlib.pyplot as pltos.getcwd()&#39;/Users/hwankam/ASC&#39;train = pd.read_csv(&quot;./mnist_train.csv&quot;)pd.read_csv(&quot;./mnist_test.csv&quot;) label 1x1 1x2 1x3 1x4 1x5 1x6 1x7 1x8 1x9 ... 28x19 28x20 28x21 28x22 28x23 28x24 28x25 28x26 28x27 28x28 0 7 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 4 4 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 9995 2 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9996 3 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9997 4 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9998 5 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9999 6 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 10000 rows × 785 columnstrain.shape(60000, 785)X_train = train.iloc[0:10000,1:]X_train 1x1 1x2 1x3 1x4 1x5 1x6 1x7 1x8 1x9 1x10 ... 28x19 28x20 28x21 28x22 28x23 28x24 28x25 28x26 28x27 28x28 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 9995 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9996 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9997 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9998 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 9999 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 10000 rows × 784 columns#이미지로 보이기 위해서는 배열로 바꾸어 줘야한다.A = X_train.iloc[3]A_array = np.array(A) A_data = A_array.reshape(28,28)plt.imshow(A_data)plt.show()from sklearn.preprocessing import StandardScalerscaler = StandardScaler()X_scaled = scaler.fit_transform(X_train)X_scaled_T = scaler.fit_transform(np.transpose(X_train))cov_mat = np.matmul(X_scaled.T, X_scaled)from scipy.linalg import eighvalues, vectors = eigh(cov_mat, eigvals = (774,783)) # 여기 eigvals에서 Eigenvector를 몇개 쓸지 정한다.valuesarray([101445.70057248, 112486.7190506 , 128273.94825691, 139044.86021375, 158766.14803775, 182041.79049293, 207745.99366805, 272280.73015253, 293848.17795963, 414834.99478416])vectorsarray([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]])SVD 이후에 고유백터의 일부를 뽑은 V’’ 를 사용해 (V’’)(V’’)^T 를 기존 Design 행렬에 곱해주면 Low rank approxX_train_trans = np.matmul(np.matmul(vectors,vectors.T),X_scaled.T) X_train_trans.shape(784, 10000)X_train_trans.T[1].shape(784,)plt.imshow(X_train_trans.T[3].reshape(28,28))plt.show()from scipy.linalg import eighvalues2, vectors2 = eigh(cov_mat, eigvals = (683,783)) # 여기 eigvals에서 Eigenvector를 몇개 쓸지 정한다.X_train_trans2 = np.matmul(np.matmul(vectors2,vectors2.T),X_scaled.T)plt.imshow(X_train_trans2.T[3].reshape(28,28))plt.show()from scipy.linalg import eighvalues3, vectors3 = eigh(cov_mat, eigvals = (583,783)) # 여기 eigvals에서 Eigenvector를 몇개 쓸지 정한다.X_train_trans3 = np.matmul(np.matmul(vectors3,vectors3.T),X_scaled.T)plt.imshow(X_train_trans2.T[3].reshape(28,28))plt.show()아래는 pc score의 분산값의 비율을 그림으로 표현한 것이다from sklearn.decomposition import PCApca=PCA(n_components=784)#pca=decomposition.PCA()#pca.n_components = 784pca_data = pca.fit_transform(X_scaled)per = pca.explained_variance_ / np.sum(pca.explained_variance_ )cum_var = np.cumsum(per)plt.plot(cum_var)plt.grid()plt.show()아래는 텐서플로우내에 존재하는 원본데이터 형식에서 그림을 추출해내는 코드이다.from keras.datasets import mnistUsing TensorFlow backend.import tensorflow as tfmnist = tf.keras.datasets.mnist.load_data()#mnist 데이터는 Minst[0] 이 train data 이고 mnist[1]이 test data이다. train_x = mnist[0][0]train_x.shape(60000, 28, 28)train_x[1]array([[ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 51, 159, 253, 159, 50, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 238, 252, 252, 252, 237, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 227, 253, 252, 239, 233, 252, 57, 6, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 60, 224, 252, 253, 252, 202, 84, 252, 253, 122, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 163, 252, 252, 252, 253, 252, 252, 96, 189, 253, 167, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 51, 238, 253, 253, 190, 114, 253, 228, 47, 79, 255, 168, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 238, 252, 252, 179, 12, 75, 121, 21, 0, 0, 253, 243, 50, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 38, 165, 253, 233, 208, 84, 0, 0, 0, 0, 0, 0, 253, 252, 165, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 7, 178, 252, 240, 71, 19, 28, 0, 0, 0, 0, 0, 0, 253, 252, 195, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 57, 252, 252, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 252, 195, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 198, 253, 190, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 253, 196, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 76, 246, 252, 112, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 252, 148, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 85, 252, 230, 25, 0, 0, 0, 0, 0, 0, 0, 0, 7, 135, 253, 186, 12, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 85, 252, 223, 0, 0, 0, 0, 0, 0, 0, 0, 7, 131, 252, 225, 71, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 85, 252, 145, 0, 0, 0, 0, 0, 0, 0, 48, 165, 252, 173, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 86, 253, 225, 0, 0, 0, 0, 0, 0, 114, 238, 253, 162, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 85, 252, 249, 146, 48, 29, 85, 178, 225, 253, 223, 167, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 85, 252, 252, 252, 229, 215, 252, 252, 252, 196, 130, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 28, 199, 252, 252, 253, 252, 252, 233, 145, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 25, 128, 252, 253, 252, 141, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)plt.imshow(train_x[1])plt.show()" }, { "title": "Computer Age Statistical Inference - chap 10", "url": "/posts/CASI10/", "categories": "", "tags": "datascience, statistical method, Efron", "date": "2021-11-09 00:00:00 +0900", "snippet": "The Jackknife and the Bootstrap목적은 SE의 계산!permuation test 는 without replacement $ calcuate p-valuebootstrap 은 with replacement % calculate Standard Errorstandard error란 무엇인가? 추정량이 얼마나 정확한지 알고싶을 때!컴퓨팅 기술이 발전하기 전까지는 plug-in 방식으로 binomial에서 p에 대한 se 추정값을 $\\sqrt{\\frac{\\hat p(1- \\hat p)}{n}}$ 로 구하는 것처럼 SE에 대한 추정을 하거나, Taylor expansion을 사용해서 구했다.그러나 잭나이프나 붓스트랩의 경우 nonformulaic computation based approach이다.10.1 The Jackknife Estimate of Standard Error\\[x_i \\sim \\mathbf F \\ \\ \\ \\ \\ \\ \\ for \\ \\ i=1,2,3,...n\\]일 때 $\\theta$의 추정량은 $\\hat \\theta = s(\\mathbf x) $ 이다. 가지고 있는 샘플이 $x_1,x_2,\\cdots, x_n$ 밖에 없을 때, 추정량에 대한 standard deviation을 어떻게 구할 수 있을까?특정 i 번째 데이터를 제거한 뒤 동일한 계산식을 통해 $\\theta$의 추정량을 구하고 이를 $\\hat \\theta_{(i)} = s(\\mathbf x_{(i)})$ 라고 하면 jackknife estimate of standard error for $\\hat \\theta$은 다음과 같이 구할 수 있다\\[\\hat {se}_{jack} = [\\frac {n-1}{n} \\sum_{i=1} ^n (\\hat \\theta_{(i)} - \\hat \\theta_{(\\cdot)} )^2]^{1/2}, \\ \\ \\ \\ \\ \\ with \\ \\ \\hat \\theta_{(\\cdot)} = \\sum \\hat \\theta_{(i)}/n\\]즉 $s(\\cdot)$만 알고 있으면 잭나이프 SE는 쉽게 구할 수 있다.jackknife formula의 특징은 다음과 같다 non-parametric $s(\\cdot)$만 알면 계산이 빠르다 n-1 개의 데이터를 사용한다. 여기서는 데이터를 하나 빼더라도 값이 smooth하게 바뀔 것이라는 가정이 깔려있다. 즉 not robust to sample 인 경우는 고려하지 않는 것 같다. jackknife SE는 true SE에 대해 upwardly biased 이다그림에서 age=25 일 때 jackkife SE가 크게 나타나는 것을 알 수 있다. 특히 이 그림은 교과서 Figure 1.2 의 lowess curve와 SE 를 나타낸 것인데, age=25 주변부분에서 그래프가 smooth한 성질을 지니지 못하기 때문에 SE 가 크게 변할 수밖에 없다.즉 여기서 jackkife SE는 $s(\\cdot)$ 의 derivative와 관련 있다는 것을 알 수 있다.10.2 The Nonparametric Bootstrap motivation\\[F \\longrightarrow x \\longrightarrow \\hat \\theta\\]모수에 대한 추정량을 얻는 방식은 위와 같다. 그러나 $F$ 를 모르기 때문에 empirical probability distribution $\\hat F$ 를 통해 bootstrap 샘플과 추정량을 얻는다. Empirical probability distribution은 샘플데이터의 추출 확률을 모두 균등하게 둔 누적분포로 $F$에 대한 nonparametric MLE 이다.\\[\\hat F \\longrightarrow x^{\\star} \\longrightarrow \\hat \\theta^{\\star}\\]Bootstrap SE를 얻는 공식은 다음과 같다. \\(\\hat {se}_{boot} = [\\frac {1}{B-1} \\sum_{b=1} ^B (\\hat \\theta^{*b} - \\hat \\theta^{\\star\\cdot} )^2]^{1/2}, \\ \\ \\ \\ \\ \\ with \\ \\ \\hat \\theta^{*\\cdot} = \\sum \\hat \\theta^{\\star b}/B\\)Bootstrap formula의 특징은 다음과 같다 여기서 묘사하는 것은 one-sample non-parametric bootstrap $s(\\cdot)$만 알면 계산이 빠르다 bootstrap은 모든 데이터를 shake(wit replacement)하기 때문에 local derivative에 의존하는 jackknife 보다 더욱 unsmoothness에 의존적이다. jackknife SE는 true SE에 대해 upwardly biased 이다 SE 뿐만 아니라, bootstrap sample을 사용해서 absolute error, fisher information 등등을 만들 수 있다. 특히 fisher information의 경우 bootstrap 추정량을 plug in 하는 형태로 구할텐데, bootstrap 과 fisherian 의 연관성이 뒷장 parametric bootstrap에 잘 드러난다.추가로, SE를 구하면 normality 가정하에 CI도 구할 수 있다. 그러나 bootstrap 샘플의 히스토그램을 그려보고 과연 normality 가정을 사용할 수 있을지 생각해봐야 한다.지금까지 나온 것으로 볼 때, jackknife는 SE와 bias 등을 살펴보는 frequentist device임을 알수있다. 반면 bootstrap은 frequentist, fisherian, Bayesian의 견해와 모두 연결되는 부분이 있는데 뒤에서 이를 자세히 살펴본다.10.3 Resampling Plans앞서서 jackknife와 bootstrap을 설명할 때에는 샘플이 뽑힐 확률을 모두 균등하게 둔 상태였다. 그러나 가지고 있는 sample data의 weight를 바꾸면 어떻게 될까?sample $x$와 resampling vector $P = (P_1, P_2, \\cdots, P_n)’$ 에 대해 (p는 확률값이므로 sum = 1)새로운 weight를 사용해서 뽑은 샘플이 있을텐데 이를 활용한 추정량을 $\\hat \\theta ^{\\star} = S(\\mathbf P)$ 라고 하자.예를들어, 분산에 대한 불편추청량은 $s(\\mathbf x) = \\sum(x_i - \\bar x)^2 / (n-1) = \\frac {n}{n-1} [\\frac{1}{n} \\sum x_i^2 - (\\frac{1}{n} \\sum x_i)^2 ]$ 이므로 reweight 추정량은 아래와 같다\\[S(\\mathbf P) = \\frac {n}{n-1} [\\sum \\mathbf P_i x_i^2 - (\\sum \\mathbf P_i x_i)^2 ]\\]이제 jackknife weight 와 bootstrap weight 중 기존의 균등 weight와 더 거리가 가까운 것은 어떤 것인지 살펴보자이 결과를 가지고 아래 그림을 보면 조금 이상한 점이 있다.\\[\\frac {(E||p^{\\star} - p_0||^2)^{1/2}} {||p_{(i)} - p_0||} \\sim \\sqrt n \\rightarrow \\infty \\ \\ as \\ \\ n \\rightarrow \\infty\\]인 것에 비해 $P_{(i)}$ 와$P^{\\star}$ 의 거리가 너무 가깝다는 점이다.remarks $\\hat {se}{jack}$는 $P_0$가 $P{(i)}$로 바뀔 때, $S(\\mathbf P_0)$ 가 $S(\\mathbf P_{(i)})$ 로 얼마만큼 바뀌는지에 관한 것을 보여준다.즉 “ directional derivative of $S(P)$ at $P_0$ along with the direction $P_{(i)} - P_0$ “ 를 다음과 같은 식으로 표현할 수 있다.\\[D_i = \\frac {S(p_{(i)}) - S(p_0)} {||p_{(i)} - p_0||} = \\frac {\\hat \\theta _{(i)} - \\hat \\theta} {1/ \\sqrt{n(n-1)}}\\]이를 활용할 때,\\[\\hat {se}_{jack} = [\\frac {\\sum D_i^2}{n^2}]^{1/2}\\] 동일한 논리로 $\\hat {se}_{boot}$는 $P_0$가 $P^{\\star}$로 바뀔 때, $S(\\mathbf P_0)$ 가 $S(\\mathbf P^{\\star})$ 로 얼마만큼 바뀌는지에 관한 것을 보여준다. linear approximation을 통해 jackknife와bootstrap 간의 관계를 살펴보자 10.4 The Parametric Bootstrap앞서 non-parametric bootstrap에서는 경험분포를 통해서 $\\hat F$를 추정하고 이를 통해 bootstrap sample을 뽑아내었다. 그러나 parametric 접근으로 가게 되면 모수에 대한 MLE를 구한 다음 추정하고 이를 plug-in 하면 parametric bootstrap sample을 얻게 되는 것이다. 즉,\\[F_{\\hat \\mu} \\longrightarrow x^{\\star} \\longrightarrow \\hat \\theta^{\\star}\\]여기서는 bootstrap을 활용한 모델의 fitting에 대해 살펴본다아래 그림은 polynomial poisson model(log linear model)의 fitting을 모델 복잡도에 따라 다르게 나타낸 것이다. 함수식은 df에 따라 다음과 같다\\[f(x) = exp(\\beta_0 + \\beta_1x + \\cdots + \\beta_df x^{df}) , \\ \\ \\ df = 2,3,4,5,6,7\\]설명을 명확히 하자면, 기존 가지고 있는 데이터로부터 MLE를 추정해서 이를 plug in 한 분포를 그려본 것인데 fitting의 과정은 아래와 같다.샘플을 k개의 구간으로 쪼갠 다음, 구간의 중위수를 $x_{(k)}$ 라고 하자. 그리고 각 구간에 속한 데이터의 개수를 $y_k$ 라고 하면($x_{(k)}$ , $y_k$) 를 포아송모형에 적합시킬 수 있다.\\[log(\\mu_k) = \\sum_{j=0} ^ {df} \\beta_j x_{(k)}^j\\]이 모형에서 회귀계수값의 MLE 값을 구하게 되면\\[log(\\hat \\mu_k) = \\sum_{j=0} ^ {df} \\hat \\beta_j x_{(k)}^j\\]일 것이므로 기존 bootstrap sample 을 얻는 프로세스와 동일하게,$\\hat \\mu$ 를 plug in 한 분포 $F_{\\hat \\mu}$ 로 부터 bootstrap sample을 얻고 이를 활용해 bootstrap MLE$s(x^{\\star}) = \\hat \\mu ^{\\star} $ 를 얻을 수 있을 것이다.즉 기존 데이터로부터 모수를 추정하고, 추정한 모수를 plug-in 한 분포로부터 다시 데이터를 추출해서(bootstrap) bootstrap data를 다시 구간으로 쪼개고 포아송모델에 적합해서 회귀계수와 $\\mu$를 bootstrap방식으로 다시 추정하는 과정을 시행하는 것이다.이를 B번 반복한다면, 각각의 gfr값 (x값)에 대한 적합값의 SE를 구할 수 있다. df 값의 변화에 따라 (모델의 변화에 따라) SE 값이 어떻게 변화하는지, 그리고 데이터는 잘 적합되는지 살펴봄으로서 최적의 모델을 구할 수 있을 것이다.단 parametric bootstrap의 경우에는 이미 모델 자체를 결정한 상태이므로, outlier들의 영향을 줄여버린다. 따라서 outlier들이 일부 존재해서 실제 분포가 분산이 큼에도 불구하고 이를 과소 추정해버릴 우려가 있다는 점을 염두해둬야 한다. (parametric familiies act as regularizers)" }, { "title": "PRML-3", "url": "/posts/PRML3/", "categories": "", "tags": "PRML, Machine learning", "date": "2021-11-07 00:00:00 +0900", "snippet": "3. Linear Models for Regressionlinear model : parameter에 대한 linear function ( input variables의 nonlinear function이 있다하더라도 이들의 결합이 파라미터 관점에서 선형결합이면 linear model이라 칭한다 )이 장에서는 선형모형과 이를 통한 학습 및 예측에 대해 설명하게 될 것이다.선형모델은 단순하며 모형의 해석적 측면에서 뛰어나지만, high dimension으로 넘어가게 되면 모델 사용의 한계가 있다는 점을 먼저 밝힌다.3.1 Linear Basis Function Modelsinput variables에 대해서도 선형함수라면 모형 자체가 너무 제한될 것이다. 따라서 basis function을 사용해서 조금 더 복잡한 선형모델을 만들어보자.Basis function $\\phi_j(x)$에 대해 다음과 같은 선형모델을 만들 수 있을 것이다.\\[y(\\mathbf x,\\mathbf w) = \\sum_{j=0}^{M-1} w_j \\phi_j(x) = \\mathbf w^T \\mathbf \\phi(x)\\]여기서 basis fuction의 종류는 여러가지가 있다. power를 사용한 $\\phi_j(x) = x^j$ 가우시안 basis $\\phi_j(x) = exp{ - \\frac{(x-\\mu_j)^2}{2s^2}}$ sigmoid basis $\\phi_j(x) =\\sigma (\\frac {x-\\mu_j} {s})$등이 있다.그러나 이 챕터에서는 특정 basis에 국한하지 않고, 일반적인 basis function에 적용되는 성질에 대해 말할 것이다.Waveletsbasis function으로 wavelets이 나오는데, wavelets transform을 한다면 함수를 특정 구간으로 localized 혹은 orthogonalized 할 수 있다. Input value들이 주변의 input value와 서로 연결되어있는 temporal sequnece나 image 상의 pixel 일 때 사용될 수 있을 것이다.3.1.1 Maximum likelihood and least squaresnotation이 지금까지 내가 공부하면서 쓰던 것과 조금 다르긴 하지만 내용은 동일함.Gaussian noise assumption 하에서 선형모델을 아래와 같이 적을 수 있다\\[p(t \\mid \\mathbf x, \\mathbf w, \\beta) = N(t \\mid y(\\mathbf x, \\mathbf w),\\beta^{-1})\\]gaussian assumption이므로 모델은 unimodal일 것이다.likelihood function은\\[p(\\mathbf t \\mid \\mathbf X, \\mathbf w, \\beta) = \\prod _{n=1} N(t_n \\mid y(\\mathbf x_n, \\mathbf w),\\beta^{-1}) = \\prod _{n=1} N(t_n \\mid \\mathbf w ^T \\phi(\\mathbf x_n),\\beta^{-1})\\]이를 극대화하는 파라미터 $\\mathbf w$ 추정값은 (ML)\\[\\mathbf w_{ML} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\mathbf t\\]이를 극대화하는 precision 파라미터 $\\beta$ 추정값은 (ML)\\[\\frac {1} {\\beta_{ML}} = \\frac {1}{N} \\sum \\{t_n - \\mathbf w_{ML} ^T \\phi(\\mathbf x_n) \\}^2\\]이를 극대화하는 bias term인 $w_0$의 추정값은 (ML)\\[\\sum _{n=1} \\{t_n - w_0 - \\sum _{j=1}w_j\\phi_j(\\mathbf x_n) \\}^2\\]을 $w_0$로 미분한 값을 0으로 만드는 값이므로\\[\\hat w_0 = \\frac{1} {N} \\sum _{n=1} t_n - \\sum _{j=1} w_j \\sum _{n=1} \\frac{1} {N} \\phi_j(\\mathbf x_n)\\]이다. 즉 bias term의 추정값은 target value의 평균값과 basis function의 평균값에 대한 weighted sum의 차이를 의미한다.3.1.2 Geometry of least squares아래 그림이 모든 것을 말해주고 있다.벡터 $ \\mathbf t $ 에 대해 M개의 basis function이 span하는 공간 $S$으로의 사영을 $\\mathbf y = \\hat {\\mathbf w ^T} \\phi(X) $ 라고 하자. 즉 $\\mathbf y$ 는 공간 $S$의 기저벡터의 선형결합으로 이뤄지며, $\\mathbf t$와의 squared Euclidean 거리가 가장 가까운 벡터이다.따라서, $\\mathbf t$의 추정값을 구할 때는 결국 $\\mathbf w_{ML} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\mathbf t $ 를 구해야하는데, 실제 데이터 분석에서는 $(\\Phi^T \\Phi)$ 가 singular 인 경우가 부지기수다(high dimension). 이 때에는 SVD를 사용하거나 Ridge, Lasso와 같이 regularization을 통해 해결할 수 있다.notation의 편의를 위해 $\\phi$ 대신에 $\\mathbf{X}$ 를 사용하겠다. (thin) Singular Value Decomposition의 경우만약 design matrix X 가 데이터의 개수가 변수에 비해 충분히 많은 (즉 n&amp;gt;p) 경우에는 thin SVD를 사용해서 아래와 같은 결과를 얻을 수 있을 것이다.\\[X^TX = (VDU^T)(UDV^T) \\Rightarrow \\hat \\beta = (X^TX)^{-1}X^Ty = VD^{-1}U^Ty\\]그러나 design matrix X 가 high dimension이거나 mulicollinear인 경우에는 $ \\mathbf X^T \\mathbf X$ 가 signular가 될 것이다. 이때는 SVD를 통해 Moore-Penrose pseudoinverse matrix를 구하는 방식으로 문제를 해결할 수 있다.$X=UDV^T$ 일 때 X의 무어 펜로즈 역행렬 $X^- = VD^-U^T$ , $D=diag(d_1^{-1},d_2^{-1},…)$ 을 사용해서\\[(X^TX)^- = V(D^2)^- V^T \\Rightarrow \\hat \\beta = (X^TX)^{-}X^Ty = X^-y\\]참고 : 무어 펜로즈 역행렬의 성질 무어펜로즈 역행렬은 SVD를 통해 만들어지므로 유일하다 무어펜로즈 역행렬은 $XX^-X = X$를 만족하는 $X^-$이다. $(X^TX)^{-1}X^T = \\mathbf K $ 는 $X$의 generalized inverse 이다. Ridge의 경우\\[\\hat \\beta^R = argmin_{\\beta} \\{ loss + \\lambda || \\beta||_2^2 \\} = (X^tX + \\lambda I)^{-1}X^Ty = (I + \\lambda(X^TX)^{-1})^{-1}\\hat\\beta\\]3.1.3 Sequential learningonline algorithm의 한 종류로, 실시간으로 파라미터의 추정량을 업데이트 할 수 있다. 데이터가 너무 큰 경우 인위적으로 데이터를 batch 별로 나눠 파라미터를 업데이트하는 방식을 사용할 수도 있을 것이다. sequential learning을 위해서는 Stochastic Gradient Descent를 사용한다. 즉\\[\\mathbf w^{(\\tau+1)} = \\mathbf w^{(\\tau)} - \\eta \\nabla E_n\\]여기서 $E_n$이란 특정 n번째 데이터에 대한 error를 구한 것으로, SGD에서는 이전의 반복에서 추정한 결과값을 따로 기억할 필요가 없고 한번의 적합으로 한번의 업데이트가 일어나기 때문에 계산비용과 메모리 비용이 적다는 장점이 있다. 그러나 업데이트 되는 값의 variability가 클 수 있다는 단점이 있다.(loss function의 형태에 따라 경사하강의 방향이 뒤죽박죽)교재 내용과는 별개로, 딥러닝에서 optimizer에 대한 설명을 담은 사진을 첨부한다.3.1.4 Regularized least squares딥러닝에서 weight decay라는 용어를 자주 볼 수 있다. weight란 통계학 관점에서의 parameter를 의미하는데, 단순히 loss 를 줄이는 것으로 파라미터값을 추정하다보면 특정 가중치(parameter)가 매우 커지면서 모델이 overfitting 하게 되므로 이를 막고자 weight값을 줄이자는 것이다. 통계학에서는 이를 shrinkage라고 하는데, regularization term을 사용해서 overfitting을 방지하고자 한다. 제약식 하에서 loss를 최소화 하는 것은 아래 식을 최소화 하는 것과 동일하다(Lagrange)\\[\\frac {1}{2} \\sum \\{t_n - \\mathbf w ^T \\phi(\\mathbf x_n) \\}^2 + \\frac {\\lambda} {2} \\sum |w_j|^q\\]regularization term을 통해서 파라미터 추정값을 구하면 주어진 제약 하에서의 squared loss를 최소로하는 추정값을 closed form으로 구할 수 있다는 장점이 있다. $\\lambda$값을 크게할수록 변수에 대한 규제가 커지고 그 값을 0에 가깝게 만들기 때문에 이 값을 적절히 설정하는 것이 계수를 추정하는 것 만큼이나 중요하다.특히 q=1 인 경우를 Lasso라고 하는데 이는 sparse model을 만들어 낼 수 있다. 아래그림에서와 같이 L1 제약하에서 파라미터 추정값이 0이 되는 것을 알 수 있다.3.1.5 Multiple outputstarget variable이 multiple 인 경우에는 어떻게 해야할까?각 target에 대한 모델을 만들 수도 있겠지만, 동일한 basis function을 사용해서 multiple response와 한번에 적합하는 모델을 생각할 수 있다. (후자가 더 일반적인 접근 방식이다)target의 dimemsion이 K라고 하자.기존 모델과의 차이는 basis function에 대한 set $\\phi(\\mathbf x)$는 기존과 동일하나, 회귀계수 벡터였던 $\\mathbf w$ 대신 response variable의 개수(dimension K)를 열 개수로 하는 행렬 $\\mathbf W$을 사용한다는 것이다. 가우시안 가정하에서 single obs $\\mathbf t_1, \\mathbf t_2, \\cdots \\mathbf t_n$에 대한 모델은 다음과 같다.K 차원 벡터 $\\mathbf y$에 대해\\[\\mathbf y(\\mathbf x, \\mathbf w) = \\mathbf W^T \\phi(\\mathbf x)\\]이며 target vector $\\mathbf t$ 에 대해\\[p(\\mathbf t \\mid \\mathbf x, \\mathbf W, \\beta) = N(\\mathbf t \\mid \\mathbf y(\\mathbf x, \\mathbf w),\\beta^{-1})\\]이다. 모델의 구성을 행렬과 벡터의 size를 통해 살펴보면 다음과 같다.\\[\\mathbf T = \\begin{bmatrix} t_{1} \\ \\ t_{2} \\ \\ t_{3} \\ \\ \\cdots \\ \\ t_{K} \\end{bmatrix} = \\begin{bmatrix} w_1 \\ w_{2} \\ w_{3} \\ \\cdots w_{K} \\end{bmatrix} \\begin{bmatrix} \\ 1 \\ \\ \\ \\ \\ \\ 1 \\ \\ \\ \\ \\ 1 \\ \\ \\ \\ \\cdots \\ \\ \\ \\ 1 \\\\ \\phi_{n1} \\ \\ \\ \\phi_{n1} \\ \\ \\ \\phi_{n1} \\ \\cdots \\ \\ \\phi_{n1} \\\\ \\vdots \\\\ \\phi_{nK} \\ \\ \\phi_{nK} \\ \\ \\phi_{nK} \\ \\cdots \\phi_{nK}\\end{bmatrix} + \\begin{bmatrix} \\epsilon_{1} \\ \\ \\epsilon_{2} \\ \\ \\epsilon_{3} \\ \\ \\cdots \\ \\ \\epsilon_{K} \\end{bmatrix} = \\mathbf W^T \\phi(\\mathbf x) + \\mathbf \\epsilon\\]로그가능도함수는\\[\\text{ln} \\ p(\\mathbf T \\mid \\mathbf X, \\mathbf W, \\beta) = \\sum_{k=1} \\sum _{n=1} \\text{ln} \\ N(\\mathbf t_{nk} \\mid y(\\mathbf x_n, \\mathbf w),\\beta^{-1}) = \\frac{NK}{2} \\text{ln} \\ (\\frac {\\beta}{2\\pi}) - \\frac{\\beta}{2} \\sum _{n=1} ||\\mathbf t_n - \\mathbf W ^T \\phi(\\mathbf x_n)||^2\\]이렇게 보면 multiple response에서의 계수추정값은 기존의 single response variable에 대한 계수추정값과 같은 form으로 나오게 될 것임이 예상가능하며 각 target variable에 대해 각각의 회귀식을 적합시킨 것에 다를 바 없다.\\[\\mathbf W_{ML} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\mathbf T\\]회귀계수 $\\mathbf w$는 분산에 관계없이 오직 가우시안의 mean 과 연관되어 있으므로 $\\mathbf w$에 대한 추정을 할 때 각 target 변수들을 독립적으로 생각할 수 있다는 뜻.3.2 The Bias Variance DecompositionML or LS 추정은 복잡한 모델에서 데이터셋의 개수가 한계가 있는 경우 overfitting의 문제를 야기할 수 있다. 그러나 무턱대고 모델의 복잡성(complexity / flexibility) 를 줄여 정말한 피팅을 포기할 수 있을까? Regularization term을 사용한다한들, $\\lambda$ 값은 또 어떻게 정할 것인가?3장의 목적은 over-fitting을 줄이기 위한 Bayesian 관점의 해결전략을 알아보는 데에 있다. 뒤에서도 설명하겠지만, posterior를 극대화하는 추정량(MAP)는 sum of squared error와 regularization을 동시에 고려해서 error를 최소화 하는 추정량이 된다.그러나 이 part에서는 좀 더 일반적으로 알려진, frequentist 관점에서 모델 복잡성 문제 이슈를 살피는 bias-variance trade-off 에 관해 설명하도록 하겠다.Expected squared loss decompostion을 통해 bias와 variance 간의 관계를 살펴보자.For Your Information어떤 loss 를 사용하는지에 따라, opitmal prediction이 달라짐을 1장에서 확인했다. 예를들어 squared loss f에서는 조건부 기댓값이, absolute loss f에서는 조건부분포의 median이 optimal prediction이 될 것이다. 핵심은 조건부 분포를 찾는 데에 있으므로, regularization 혹은 Baysian approach(Bayes theorem)를 통해 조건부 분포를 구할 수 있을 것이다.step 1$t=X\\beta + \\epsilon $는 response variable, $y(x)$는 추정회귀선, $h(x) = X\\beta $이라고 할 때 (figure 3.2 참조)\\[E[L] = \\int \\{ y(x)-h(x) \\}^2 p(x) dx + \\int \\{ h(x) - t \\}^2 p(x,t)dxdt\\]와 같이 분해가 가능하다.첫번째 term 은 어떤 추정회귀식 $y(x)$ 를 선택했는가에 따라 달라지는 값이며 이를 최소화하는 y(x)를 찾고자 할 것이다. 이상적으로 데이터가 무수히 많다면 정확히 h(x) 와 일치하는 y(x)를 찾아낼 수 있을 것이므로 첫번째 term은 0이 될 것이다.반면, 두번째 term 은 $h(x) - t = \\epsilon$ 이므로 intrinsic noise를 의미하며 expected loss 의 minimum이다. 즉 두번째 term은 결코 0이 될 수 없다.이로부터 필연적으로 존재할 수밖에 없는 noise는 차치하고, 줄일 수 있는 첫번째 term을 어떻게 다뤄야할지 생각해볼 필요가 있다.step 2frequentist는 데이터셋을 통해 파라미터를 추정하며, 데이터셋이 바뀌면 당연히 추정값이 바뀌게 된다. 전체 데이터셋을 batch 형태로 나누었다고 할 때, 각 batch 마다의 적합 회귀추정식을 $y(x; D)$,batch 마다 만들어진 추정회귀식의 평균을 $E_D[y(x;D)]$ 라고 하면 다음과 같은 분해가 가능하다.\\[\\begin{align} \\int \\{ y(x)-h(x) \\}^2 p(x) dx &amp;amp; = \\int \\{ y_D(x)-E_D[y(x;D)] \\}^2 p(x) dx + \\int \\{ E_D[y(x;D)] - h(x) \\}^2 p(x) dx \\\\ &amp;amp; =\\ \\ \\ \\ \\ \\textrm{Variance of } \\ y_D(x) \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\ \\ \\ \\ \\ \\ (bias)^2 \\end{align}\\]여기서 분산이란 특정 데이터셋이 얼마나 민감한지를 나타내며 bias 란 추정한 회귀식의 평균값이 실제 참값이라고 여겨지는 h(x)와 어느정도 멀리 떨어져있는지를 알려준다.이제 모든 과정을 종합해보면\\[\\textrm{Expected loss = squared bias + variance + noise}\\]임을 알 수 있다.bias-variance trade-off결국 expected loss 가 위와 같이 분해되기 때문에 bias 와 variacne 간의 trade - off 는 필연적이다.위 그림은 regularization term $\\lambda$ 값에 따라 bias와 variance가 어떻게 바뀌는지 simulation 한 결과이다. 제약이 강하게 들어갈 때, 분산이 줄어들고 상대적으로 bias 가 커진다.decompostion을 통한 관계를 qunatitative하게 나타내면\\[\\begin{align}&amp;amp; (bias)^2 = \\frac {1} {N} \\sum_{n=1}^N \\{\\bar y(x_n) - h(x_n) \\}^2 \\\\&amp;amp; Variance = \\frac {1} {N} \\sum_{n=1}^N \\frac{1}{L} \\sum_{l=1}^L \\{y_{(l)}(x_n) - \\bar y(x_n) \\}^2\\end{align}\\]limitation식을 통해서도 알 수 있지만, 위의 decompostion은 data set의 평균에 관한 것이다. 그러나 현실에서는 오직 single data set만을 가진 경우가 허다하다. 이런 이유로 모델 complexity와 over-fitting 문제를 동시에 다룰 수 있는 Baysian approach를 공부해볼 필요가 있다.3.4 Bayesian Model Comparison (brief) intro Model selection from Bayesian perspective 을 살펴보자. 3.4장에서는 간단한 개념만 살핀 뒤, 3.5장에서는 regularization parameter를 어떻게 결정할지에 대한 아이디어를 제시할 것이다.베이지안 관점의 가장 큰 특징은 불확실성을 control할 수 있다는 것이다. 통상적으로 모델을 만들어 검증을 하는 방식으로 모델의 성능, 즉 over-fitting 여부를 확인한다. 반면 베이지안 관점에서는 training에 모든 데이터를 사용하므로 데이터 손실이 없으며, 동시에 모델의 복잡도를 fitting 과정에서 동시에 판단 가능하다. (이러한 내용은 Chap 7. relevance vector machine에 잘 나온다고 한다.) body $\\mathcal{M}_i$는 모델의 종류를 의미한다고 하자.[notation]prior ; $p(\\mathcal{M}_i)$ ; uncertainty model evidence ; $p(\\mathcal{D} \\mathcal{M}_i)$ ; marginal likelihood $\\quad \\because p(\\mathcal{D}|\\mathcal{M}_i) = \\int p(\\mathcal{D}|\\mathcal{M}_i, \\boldsymbol{w})p(\\boldsymbol{w}|\\mathcal{M}_i) d\\boldsymbol{w}$이므로 $\\boldsymbol{w}$ 가 marginalized out 된다고 보는 것. posterior ; $p(\\mathcal{M}_i \\mathcal{D})$ predictive distribution ; $p(t|x, \\mathcal{D}) = \\sum_{i=1} ^L p(t|x,\\mathcal{M}_i, \\mathcal{D})p(\\mathcal{M}_i|\\mathcal{D})$ ; mixture distribution[main]위에서 기술한 것처럼 predictive dist는 model evidence를 posterior weight로 가중평균낸 것으로 model selection의 관점에서는 가장 그럴듯한 모델을 말하는 model evidence를 찾아야 한다. 즉, flat prior와 shaply peaked posterior를 가정할 때,\\[\\begin{align}&amp;amp;p(\\mathcal{D}) = \\int p(\\mathcal{D}|w)p(w)\\ dw \\simeq p(\\mathcal{D}|w_{MAP}) \\frac {\\Delta W_{posterior}}{\\Delta W_{prior}} \\\\&amp;amp;ln \\ P(\\mathcal{D}) \\simeq ln \\ p(\\mathcal{D}|w_{MAP}) + ln \\ (\\frac {\\Delta W_{posterior}}{\\Delta W_{prior}})\\end{align}\\]여기서 첫 번째 term은 각 모델에 데이터가 얼마나 잘 fitting 하는지를 나타내고(complexity가 높을수록 모델이 모든 데이터에 fitting 될 것), 두 번째 term은 모델 복잡도에 대한 penalty term을 나타낸다.(즉 모델이 복잡할수록 posterior는 간격이 좁아진다 =&amp;gt; second term의 값을 줄여버린다) 따라서 최적의 모델 복잡도는 두가지 term의 trade off 를 통해 선택될 것이다.3.5 The Evidence Appproximation intro Evidence function에 대해 좀 더 설명하기 앞서, 데이터를 활용해서 predictive distribution을 form 하는 경우를 생각해보자.predictive distribution $p(t|\\boldsymbol{t})$은hyperparameter $\\alpha, \\beta, w$를 marginalizing 한 것이라 생각할 수 있다. 즉,\\[p(t|\\boldsymbol{t}) = \\int \\int \\int p(t|\\boldsymbol{w}, \\beta)p(\\boldsymbol{w}|\\boldsymbol{t}, \\alpha, \\beta)p(\\alpha, \\beta|\\boldsymbol{t}) \\ d\\boldsymbol{w} \\ d\\alpha \\ d\\beta\\]이때, hyperparameter $\\alpha, \\beta$를 marginal likellihood function을 극대화하는 추정량 $\\hat \\alpha , \\hat \\beta$ 로 정했을 때 predictive distribution을 approximation하는 경우를 생각해보자.posterior $p(\\alpha, \\beta | \\boldsymbol{t})$ 에 대해 $p(\\alpha, \\beta|\\boldsymbol{t}) \\propto p(\\boldsymbol{t}|\\alpha, \\beta)p(\\alpha, \\beta)$ 이므로 flat prior를 생각하면 likelihood를 극대화하는 것이 곧 $\\alpha, \\beta$를 극대화 하는 것임을 알 수 있다.이와 같이 온전히 데이터에 의존해서(likelihood) hyperparmeter를 결정하게 되면 predictive distribution을 아래와 같은 방식으로 구해낼 수 있다.\\[p( t | \\boldsymbol{t}) \\simeq p( t | \\boldsymbol{t}, \\hat \\alpha , \\hat \\beta) = \\int p(t|\\boldsymbol{w}, \\hat \\beta) p(\\boldsymbol{w}|\\boldsymbol{t}, \\hat \\alpha \\hat \\beta) d \\beta\\]즉 alpha 와 beta 값을 적절하게 추정하면 predicitve distribution을 보다 쉽게 만들 수 있음을 보였다.3.5.1 Evaluation of the evidence functionlikelihood function을 다시 한번 정의한 뒤, 이를 극대화하는 hyperparameter를 찾아보자.marginal likelihood function $p(\\boldsymbol{t}|\\alpha, \\beta)$는 weight parameter $\\boldsymbol{w}$ 에 대한 적분을 통해 얻어진다. 즉,\\[p(\\boldsymbol{t}|\\alpha, \\beta) = \\int p(\\boldsymbol{t}|\\boldsymbol{w},\\beta)p(\\boldsymbol{w}|\\alpha) d\\boldsymbol{w}\\]이에 대한 적분 과정은 뒤에 연습문제로 잘 나타나있다. 특히 적분 결과가 Error function의 형태로 나타남에 주목할 만하다.이를 전개한뒤, 로그를 씌우면\\[ln\\ p(\\boldsymbol{t}|\\alpha, \\beta) = \\frac{M}{2}ln\\ \\alpha + \\frac{N}{2}ln\\ \\beta - E(\\boldsymbol{m}_N) -\\frac{1}{2}ln\\ |\\boldsymbol{A}| - \\frac{N}{2}ln\\ (2\\pi)\\]여기서 M은 parameter 차원을, N은 데이터의 개수를 의미한다.3.4에서 likelihood를 data fitting 부분과 penalty 부분으로 나누어 보았는데 이러한 관점에서 볼 때, Figure 3.14는 M=3 이후로는 data fitting 보다 penalty 부분이 더 커지는 상황임을 알 수 있다.또한, Figure 1.5를 보면 베이지안 관점의 장점이 잘 드러난다. M=3,…,8 일 때 error 가 모두 동일해 어떠한 complexity에서 모델 fitting이 가장 잘 되었을지 수치적으로 확인하기 힘들지만 베이지안적 접근을 통해 이를 극복할 수 있다.3.5.2 Maximizing the evidence function앞서 구한 $p(\\boldsymbol{t}|\\alpha, \\beta)$ 를 maximizing하는 $\\alpha$ 값을 찾아보자. 일차 미분한 뒤 그 식을 0으로 만들어주는 $\\alpha$ 값을 구하면 아래와 같다.\\[\\alpha = \\frac{\\gamma}{\\boldsymbol{m}_n^T\\boldsymbol{m}_n} \\ \\ \\textrm{where} \\ \\ \\gamma = \\sum \\frac{\\lambda_i}{a+\\lambda_i}\\]여기서 $\\lambda$는 design matrix로 만든 행렬 $\\Phi^T \\Phi$의 고유값이고 $\\boldsymbol{m}_n$ 또한 design matrix를 활용한 변환값이다. 즉 $\\alpha$는 오로지 데이터에만 의존한다.$\\gamma$와 $\\boldsymbol{m}_n$은 모두 $\\alpha$에 의존하기 때문에 $\\alpha$에 대한 초기값을 설정한 뒤 $\\alpha$ 에 대한 iterative estimation 이 가능해진다.$\\beta$에 관해서도 동일한 방식으로 보일 수 있으며, hyperparameter인 $\\alpha, \\beta$를 업데이트 하는데 오로지 데이터에만 의존하는 것에 주목해야 한다.3.5.3 Effective number of parameters위의 그림을 볼 때, eigenvalue는 curvature를 나타내고, $\\lambda_1$ &amp;lt; $\\lambda_2$ 이다.$\\alpha$ = 0이면 prior인 $p(\\boldsymbol{w}|\\alpha)$의 분산이 무한에 가깝다는 말이 되므로 flat prior를 의미하게 된다.따라서 posterior $p(\\boldsymbol{w}|\\alpha, \\boldsymbol{t})$의 mode는 $\\boldsymbol{w}_{ML}$로 표현될 수 있다. (flat prior이므로 likelihood를 극대화하는 것이 사후분포를 극대화 하는 것이다)반면 $\\alpha$ &amp;gt;0 이면 posterior인 $p(\\boldsymbol{w} | \\boldsymbol{t}) = \\mathcal{N}(\\boldsymbol{w} | \\boldsymbol{m}_N, \\boldsymbol{S}_N)$의 mode는 posterior의 평균 $\\boldsymbol{m}_N$이다." }, { "title": "Computer Age Statistical Inference - chap 9", "url": "/posts/CASI9/", "categories": "", "tags": "datascience, statistical method, Efron", "date": "2021-11-05 00:00:00 +0900", "snippet": "Survival Analysis and the EM Algorithm이 글에서는 survival analysis에 집중해서 글을 쓰도록 하겠습니다.생존분석에서 사용되는 3가지 방법 : 1. Kaplan-Meier estimate ==&amp;gt; 2. the log-rank test ==&amp;gt; 3. Cox’s proportional hazards model1,2,3 으로 갈수록 복잡한 계산과 추론이 필요하고, 실제 현업에서는 Kaplan-Meier를 통한 분석이 주로 이뤄지고 있다( 간편성 때문에 )9.1 Life Tables and Hazard Rates우선 생존함수에 대한 의미와 notation을 자세히 살펴본다.확률변수 $X$는 수명에 관한 확률변수이다. 즉, $f_i = Pr { X=i } $ 이다. 이때 생존함수(survival function)을 아래와 같이 정의하면 이는 i-1 번째까지는 살아있을 확률을 의미한다.(책마다 생존함수를 정의하는 방식에서 등호를 포함하는지 여부에 대해 차이가 있지만, 그에 맞춰 해석을 하면 되겠다)\\[S_i = \\sum _{j \\geq i} f_j = Pr \\{ X \\geq i\\}\\]그리고 생존함수를 이용해서 위험률함수(hazard function)을 정의할 수 있다. 위험률함수는 i-1번째까지는 살아있을 때, 수명이 i 번째에서는 끝남을 말한다.\\[h_i = \\frac {f_i} {S_i} = Pr \\{ X = i | X \\geq i\\}\\]이제 아래첨자를 두개 사용해서 새로운 survival function $S_{ij}$을 정의할 수 있는데\\[S_{i,j} = \\prod_{k=i} ^j (1-h_k) = Pr \\{ X &amp;gt; j | X \\geq i\\}\\]이는 i번째부터 j번째 타임까지는 살아있을 확률(i부터 j까지는 수명이 다하지 않는다)을 의미한다.(조건부확률에 대한 계산으로 쉽게 우변을 도출해낼 수 있다.) 결국 기존에 정의했던 생존함수와 관계를 생각해보면 $S_j$가 j-1번째까지는 수명이 다하지 않을 확률을 의미하기 때문에 $S_j = S_{1,j-1}$ 가 성립한다.( 만약 각 함수에 대한 해석이 어렵다면; 생존함수는 i-1 번째까지는 수명이 다하지 않을 확률, 위험률함수는 조건부확률로서 i번째에는 수명이 다할 확률, 생존함수 ij 는 i 부터 j 번째 까지는 수명이 다하지 않을 확률을 의미한다. )이제 위에서 정의한 함수(확률변수)들을 추정해보자책에서 제시한 표는 아래와 같다$\\hat S$는 $S_{ij}$에 대한 추청값으로 여기서는 i=30의 상황을 의미한다. 즉 30살부터 j살까지 살아있을 확률을 의미한다.$\\hat h_i = y_i / n_i$ 로서 위험률함수에 대한 추정값이다.section의 처음에서 정의한대로 두 추정량의 관계를 다시 살펴보면 아래값이 성립할 것이다\\[\\hat S_{30,j} = \\prod_{k=30} ^j (1-\\hat h_k) = Pr \\{ X &amp;gt; j | X \\geq 30\\}\\]그래서 만약 위험률함수가 변하지 않는다면? i부터 j까지 생존할 확률 (생존함수 ij)를 찾기 위해 (j-i)년을 기다릴 필요 없이 1년의 기록에서 구한 위험률함수로 생존 확률을 예측할 수 있을 것이다.앞에서는 이산형 변수를 사용한 함수를 formulate 했지만 연속형 변수로도 동일한 논리에 따라 표현이 가능하다.$S(t) = \\int_t ^{\\inf} f(x) dx = Pr {T\\geq t } $ 이고 이를 활용해서 위험률함수 $h(t)$를 정의할 때 i부터 j까지 생존할 확률은\\[Pr \\{ T \\geq t _1 | X \\geq t_o\\} = exp \\{-\\int_{t_0} ^{t_1} h(x) dx \\} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ -(*)\\]이고 $S(t)$는 아래와 같이 다시 정의 된다.\\[S(t) = exp \\{-\\int_0 ^t h(x) dx \\}\\](*) 증명\\(h(t) = \\frac {f(t)}{S(t)} = \\frac {d}{dt} \\{ -log S(t) \\}\\)을 활용하면 증명 가능하다.예를 들어 수명에 대한 함수 f(t)가 모수가 c 인 지수분포를 가진다면 지수분포의 무기억성으로 인해 $h(t) = Pr { T=0 } = 1/c$9.2 Censored Data and the Kaplan_Meier Estimate아래 표는 치료법 A, B에 대해 환자들의 생존 시간을 나타내는 표이다. + 기호는 censored data를 의미한다.만약 censored data가 없다면, 두가지 치료법에 대한 비교를 하기 위해서는 wilcoxon test 같은 two sample test를 하면 될 것이다. 그러나 censored data가 있는 경우에는 Kaplan_Meier 방법이 필요하다.위의 표를 9.1에서 제시된 표와 같이 변형해보자. 아래의 표는 치료법 A에 관해 표현한 표이고 l은 censored 를 의미한다.indicator $d_i$가 절단 여부를 나타낸다고 할 때(0이 절단 된 것) individual point 는\\[z_i = (t_i, d_i)\\]이고, Kaplan-Meier Estimate for $S_{(j)} = Pr { X &amp;gt; t_{(j)}}$ 는 아래와 같다\\[\\hat S_{(j)} = \\prod_{k \\leq j} (1- \\frac {1}{n-k+1})^{d_{(j)}}\\](survival time t를 순서대로 나열한 다음 각각의 시점에 대한 위험률함수를 만들었기 때문에 sensored 되지 않는 이상 각 시점마다 한명씩 사람이 죽는다. 따라서 남아 있는 사람의 수의 역수값이 위험률함수가 되는 것. 또한 표에서 절단 또한 한번에 한명씩 일어나기 때문에 위 식이 성립힌다)(또한 첫번째 section에서 정의한 것과 달리 생존함수에 등호가 안붙여져 있기때문에 추정치를 구할 때 j-1 이 아닌 j 번째까지 모두 곱했다 )K-P estimate을 그리면 아래와 같다. 예상한대로 시간에 따라 jump to downward 의 그래프가 만들어지며 여기서 알 수 있는 바는 확연히 B의 효과가 좋다는 것이다.통계학은 자연스럽게 추정치의 신뢰구간에 대해 이야기가 나오게 되므로 이를 살펴보자여기서는 두가지 방법을 제시한다. 수식이 많기 때문에 직접 손으로 작성한 식을 그림으로 첨부한다.첫 번째는 pointwise standard deviation of $\\hat S_{(j)}$ 인데, 추청량의 표준편차 값을 직접 구하는 것이다.두 번째는 h(t)를 parametric하게 추정하고 K-P estimate와 동일한 결과를 보이는지, h(t)의 표준편차는 어떠한지 살펴보는 것이다.9.3 The Log-Rank TestK-P estimator가 절단이 존재할 때 생존함수에 대한 추정이라면 log-rank test는 절단이 있는 생존 데이터에 대한 non-parametric two sample test이다. (절단이 있으나, statistic 을 만들 때에는 절단을 고려하지 않고 각 k개의 event(사망)에 대해서만 k개의 table을 만든다)==&amp;gt; 귀무가설이 $H_0 : S_A(t) = S_B(t) \\Leftrightarrow h_A(t) = h_B(t) $hypergeometric distribution을 사용해서 검정한다.전체 기간이 N일 때 각 기간마다$n_A$ : number at risk of A$n_d$ : number of death$n_s$ : number of survivaln : total number at risk를 conditional 한 뒤 y 값을 A의 death number 이라 하면 아래의 그림과 같은 2 X 2 table을 만들 수 있다. (condtion의 측면에서는 fisher의 방법론과 이어지는 것) ()hypergeometric의 평균과 분산\\[E = n_A n_d / n \\\\V = n_A n_B n_d n_s / n^2(n-1)\\]을 활용해서 log-rank statistic 을 구하면\\[Z = \\frac {\\sum (y_i - E_i)} {\\sqrt{\\sum V_i}}\\]asympotic calculations based on the central limit theorem suggest $Z \\sim N(0,1)$Z 값이 너무 커서 기각이 되는 경우, A의 death number가 그만큼 많다는 뜻이고 treatment B 의 성능이 더 좋다는 말이 된다.9.4 The Proportional Hazards Models(Cox)proportional hazards를 사용하면 censored data에 대해 full regression analysis를 사용할 수 있음을 보여준다.regression으로 바로 넘어가기에 앞서, 다른 section에서와 달리 새로운 변수가 추가된 상황을 가정하겠다. 즉 death, survival을 제외한 새로운 변수가 추가되어 세 변수 사이의 관계를 알고싶다. 그래서 K-P estimator와는 달리 여기에서는 c 값이 추가 된다.c가 생존에 영향을 주는 covariate을 나타내는 벡터라고 할 때, individual data point를\\[z_i = (c_i, t_i, d_i)\\]로 표현할 수 있다.이제 regression문제로 넘어가보자. i번째 individual point에 대해 위험률함수를 아래와 같이 표현한다.\\[h_i(t) = h_0(t)e^{c_i&#39; \\beta}\\]$\\theta_i = e^{c_i’ \\beta} $ 라면 결국 individual i의 hazard 는 baseline hazard $h_0$ 에다가 $\\theta_i $를 곱한 셈이 된다. (그래서 proportional hazard 인 듯?)이를 활용하면, 생존함수는 결국 위험률함수를 적분한 것이므로\\[S_i(t) = S_0(t) ^ {\\theta_i}\\]임을 알 수 있다. 즉 생존함수는 $\\theta$에 따라서 더 기하급수적으로 감소할 것이다.위에서 생존함수와 위험률함수를 정의했으니, 조금 더 구체적으로 들어가보자.우선 편의를 위해서 death가 발생한 시간이 모두 다르다고 가정하자. 특정 시간 이전에는 ‘위험’ 요소가 존재할텐데 이를 $R_j$라고 하자.\\[R_j = \\{i : t_i \\geq T_{(j)} \\}\\]이를 활용해서 어떤 사람이 $T_{(j)}$ 시간에 사망할 때 특정 i 번째 individual일 확률을 다음과 같이 표기할 수 있다\\[Pr\\{i_j = i | R_j \\} = \\frac {e^{c_i&#39; \\beta}} {\\sum_{k \\in R_j}e^{c_i&#39; \\beta}}\\]이를 활용해서 partial likelihood 를 구하면\\[L(\\beta) = \\prod_{j=1} ^J (\\frac {e^{c_i&#39; \\beta}} {\\sum_{k \\in R_j}e^{c_i&#39; \\beta}})\\]이고 이를 활용해서 $\\beta$에 대한 mle 값을 구할 수 있다.이를 통해 볼때 proportional hazard model은 semi-parametric model이라 할 수 있다.($h_0(t)$를 모르기 때문)" }, { "title": "Nonparametric - one sample location", "url": "/posts/%EB%B9%84%EB%AA%A8%EC%88%98-%EC%9D%BC%ED%91%9C%EB%B3%B8_%EC%9C%84%EC%B9%98%EB%AC%B8%EC%A0%9C/", "categories": "", "tags": "Nonparametric, permutation test", "date": "2021-11-02 00:00:00 +0900", "snippet": "범주형 자료분석의 보조자료를 정리한 글이다. 비모수통계학의 일표본 위치문제와 permutation test에 관한 내용들을 정리해보겠다.1. Two-sample location problem1.1 Independent sampleTest Parmetric test : independent two sample t-test Permutation test(resampling method의 일종으로 permutation test는 p-value를 찾는데 사용하며 without-replacement를, bootstrap의 경우 SE 추정을 하며 with-replacement를 사용한다) Non-parametric test : Wilcoxon rank sum test, Mann-Whitney testparametric testAssumtion :$ N(\\theta_x, \\sigma^2) , N(\\theta_y,\\sigma^2)$ (homoscadescity) (Normality)Null hypothesis : $\\theta_x = \\theta_y $Test statistic : $T = \\frac {\\bar Y - \\bar X - (\\theta_y - \\theta_x)} {S_p \\sqrt{1/m + 1/n}} \\sim t_{m+n-2}$Wilcoxon Rank Sum Test (여기서도 exact test 와 asymtotic test 로 나뉜다)Two sample t test 와 달리 정규성가정이 필요없다(: 비모수적 검정)그러나 윌콕슨 순위검정은 샘플들을 섞기 때문에 등분산에 대한 가정은 존재해야만 샘플을 섞는것이 의미 있을 것이다Null hypothesis : $\\theta_x = \\theta_y $Test statistic : $W = \\sum_i R_i$이 때 $R_i$는 두 집단의 샘플을 마구 섞은 뒤, 순위를 매기고 그 중 Y 샘플에 해당하는 순위만을 합한 것.X 샘플에 해당하는 순위를 매기고 이를 합한 것을 $W’$라고 하면 $W + W’ = N(N+1)/2$예시) X sample 두개, Y sample 두개 인 경우 $W$의 분포는 아래와 같을 것이다. Exact test위 상황에서 우리가 얻은 샘플이 $W = 3$ 이라면, 대립가설이 $\\theta_x \\neq \\theta_y$ 일 때, p-value는$ W = 3 \\ and \\ 7 $일 때의 확률값을 더해주면 된다. 따라서 p-value = 1/3만약 대립가설이 $\\theta_x &amp;gt; \\theta_y$ 라면 p-value는 $ W \\leq 3 $일 때의 확률값을 더해주면 된다. 따라서 p-value = 1/6만약 대립가설이 $\\theta_x &amp;lt; \\theta_y$ 라면 p-value는 $ W \\geq 3 $일 때의 확률값을 더해주면 된다. 따라서 p-value = 1참고추가적으로 $ W $의 평균과 분산을 구할 수 있다.$p(R_i = s) = 1/N \\ \\ , \\ S = 1,2,…,N$ 일 때$E(W_0) = n(N+1)/2 \\ \\ , \\ \\ $$Var( W_0) = nm(N+1)/12$ Asympototic test -&amp;gt; NormalCLT 에 의해, $ W \\sim N(E(W), Var(W))$ 이므로 이를 활용해서 Z 값을 만들어 준다.t-statistics-based permutation test 1permutation test 는 t 통계량(어떠한 통계량이든 상관없음)을 가져다 쓰나, t-분포를 요구하지는 않는다. 그 말인 즉슨 Normality 가정을 요구하지 않고 empirical distribution으로부터 가설검정을 하겠다는 것이다.B번의 permutations이 행해진 뒤에 아래와 같은 값으로 p-value를 구한다.(permuation의 최대 횟수는 샘플의 개수에 따라 다르다)\\[p = \\frac {\\sum I(|t^{b}| \\geq |t_0|)} {B}\\]permutation test는 exact p-value를 구한다t-statistics-based permutation test 2Assumtion : $N(\\theta_x, \\sigma_x^2) , N(\\theta_y,\\sigma_y^2)$ (homoscadescity) (Normality)Null hypothesis : $\\theta_x = \\theta_y $statistic : $T = \\frac {\\bar Y - \\bar X} {\\sqrt{S_1^2/m + S_2^2/n}} $통계량을 사용해서 permutation test 진행t-statistics-based permutation test 3프린트 상으로는 여기에 같이 설명되어 있으나, 이것은 one-sample location 문제이다.$X_i \\sim \\ iid \\ f_{\\theta}(x) = f_0(x-\\theta)$Null hypothesis : $\\theta = \\theta_0 $Test statistic : T = $\\frac {\\bar X - \\theta_0} {S/\\sqrt{n}} \\sim t_{n-1} $이제 statistic 을 활용해서 permutation test를 진행한다.permuation을 하기 위해서는 부호를 사용한다. f 의 평균이 $\\theta$이므로 이를 shift 해서 $x_i - \\theta$ 의 샘플을 만들고 난 뒤, 부호를 준다.sample { $x_i - \\theta $ }를 모아놓은 벡터와 (-1,1)에서 샘플 개수 n개 만큼 복원 추출한 벡터를 서로 element-wise product하고, 이를 활용해서 통계량 $T^b$ 를 구한다. 이를 B번 반복해서 p-value를 구한다.\\[p = \\frac {\\sum I(|T^{b}| \\geq |T_0|)} {B}\\]Comparison of Wilcoxon test with permutation test   t-test t-permutation Wilcoxon Distribution Normal No No Information Mean, Variance Mean, Variance Rank Robustness to skewness No Yes Yes Robustness to outliers No No Yes Wilcoxon rank test는 robustness to outlier 이지만 정보를 모두 순위로 바꾸기 때문에 오히려 정보를 잃어버린다는 단점.1.2 Paried comparisonconfounding effect 를 막을 수 있다. 즉 비교하고 싶은 두 효과의 차이만을 오롯이 비교할 수 있다.Test Parmetric test : t-test for the difference Permutation test Non-parametric test : Wilcoxon signed rank test parametric test 샘플이 pair 이므로 correlation이 존재한다 $\\Longrightarrow T = \\frac {\\bar Y - \\bar X - (\\theta_y - \\theta_x)} {S_p \\sqrt{1/m + 1/n}} $ 를 사용할 수 없고 $T = \\frac {\\bar Y - \\bar X - (\\theta_y - \\theta_x)} {SE(\\bar D)} \\sim T_{n-1} $ 만을 사용해야 한다.Non-parametric test 샘플의 부호를 모두 제거한 채로 오름차순 정렬한 뒤, 순위값 $R_i$을 준다 $T = \\sum sgn(X_i) R_i$ 으로 test statistic을 정한다. p-value 계산2. One-way ANOVA probelmOne-way는 factor(treatment) 가 하나인 경우 ANOVA는 two sample test 를 확장해서 여러개의 샘플(집단)을 비교하는 것. one-way ANOVA 가정 : 등분산성이 기본가정!, 만약 두 집단의 분산이 다르다면? $\\rightarrow $ log transformation 해준 다음에 ANOVA 해줘야 함.Parmetric methodtest statistic $F = \\frac {SStr/(k-1)} {SSE/(N-k)} \\sim F_{k-1, N-k}$Non-parametric methodKruskal-Wallis test (wilcoxon rank test 의 확장) - Exact testtest statistic H 는 아래와 같다\\[H = \\frac {12}{N(N+1)} \\sum_{i=1} ^k n_i(\\bar R_{i.}- \\bar R_{..})^2\\]Permutation방식은 동일하다. 통계량은 어떠한 것을 사용해도 괜찮기 때문\\[p = \\frac {\\sum I(|F^{b}| \\geq |F_0|)} {B}\\]3. Correlation analysisTest Parmetric test : Pearson’s correlation coefficient =&amp;gt; t-test Permutation test Non-parametric test : Spearman rank correlationParmetric methodbivariate normal distribution으로부터 아래와 같은 변환으로 통해 t 분포를 유도할 수 있다귀무가설 $H_0 : \\rho = 0$ 로부터\\[T = \\sqrt{n-2} \\frac {r} {\\sqrt{1-r^2}} \\ \\ \\sim t_{n-2}\\]만약 normality 가정이 만족하지 않는다면 permuation test나 혹은 spearman rank correlation, Kendall rank correlation 을 사용한다.Permuation testpaired data (X,Y)을 사용해서 새로운 데이터 set (X’, Y’) 을 만들 것이다.귀무가설 $H_0 : \\rho = 0$ 이므로 귀무가설하에서는 x와 y가 서로 독립이므로 random하게 섞을 수 있다.Non-parametricspearman rank correlation : 두 집단의 샘플 내부에서 각각의 순위를 정해서 $R_i^X , R_i^Y$ 라고 한다. 이 때 Spearman correlation은\\[R_s = \\frac {\\sum (R_i^X - \\bar R)(R_i^Y - \\bar R)} {\\sqrt{\\sum (R_i^X - \\bar R)^2} \\sqrt{\\sum (R_i^Y - \\bar R)^2}}\\]where $\\bar R = (n+1)/2 $Asymtotic distribution을 구하고 싶다면, $\\sqrt{n-1} R_s \\sim N(0,1)$참고 : pearson sample corr 같은 경우 $ \\gamma \\approx N(\\rho, \\frac {(1-\\rho^2)^2}{n}) $4. Regression AnalysisPermutation test only여기서부터는 Permutation tests for univariate or multivariate analysis of variance and regression - Marti J. Anderson 의 글을 참고했다.permutation test 의 rationale :관찰값으로부터의 통계량과 귀무가설하에서 나올 수 있는 모든 경우의 통계량들의 분포를 비교하는 것. 이때 나올 수 있는 모든 경우라는 것은, 실험 디자인이 random하게 변하는 것으로부터 나오는 것이고 샘플자체, 그리고 error term은 바뀌지 않는 것이다. 즉 고정된 샘플에서 permuation이 행해지는 것을 의미한다.실험 디자인이 random하게 변한다는 것은 test의 validity를 보장할 수 있다는 것이다. 즉 연구자가 정한 type 1 error 의 값을 유지하면서 실험 결과를 얻어낼 수 있다. 이것은 마치 일반적으로 perametric method of test에서 normality를 가정하거나 asymtotic normality를 얻는 것과 일맥상통한다고 할 수 있겠다.simple linear regressionpermutation test를 위해서는 귀무가설 하에서 exchangeable한 것을 찾아내야 한다.model $Y = \\beta_0 + \\beta_1 X + \\epsilon $ 일 때, 귀무가설 $H_0 : \\beta_1 = 0$ 하에서는 Y 는 X와는 무관하기 때문에 이를 randomly permute 가능하다. 이후에는 permutation 된 (X,Y)를 사용해서 원하는 통계량을 구한 뒤 p-value를 찾아낸다.이러한 논리는 multiple linear regression $Y = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\epsilon $ 에서 귀무가설이 $H_0 : \\beta_1 = \\beta_2 = 0$ 일 때에도 동일하게 적용될 것이다.multiple linear regressionmultiple linear regression 중 partial regression에 대해 알아보면,model : $Y = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\epsilon $null hypothesis : $H_0 : \\beta_2 = 0$인 경우, 검정하고 싶은 대상은 “relationship between Y and Z given X 이다. simple linear regression과 동일한 논리로 접근하면, 귀무가설 하에서 무엇이 exchangeable 한 것인지 찾아야한다. 귀무가설 하에서의 model $ Y = \\beta_0 + \\beta_1 X + \\epsilon $ 에서 X 혹은 Y를 permute 하게 되면 $\\beta_1$의 실제 값이 바뀌기 때문에 exchange에 주의해야 한다. 귀무가설하에서 실제로 exchange 가능한 것은 $ Y - \\beta_0 - \\beta_1 X $ 인데 베타 값에 대한 참값을 알 수 없기 때문에 추정치인 $\\hat \\beta$를 사용해서 잔차를 구하고 잔차를 permute 한다. 그런 다음 실제로 알고 싶은 관계를 나타내는 변수인 Z와 잔차의 linear 모델을 만들어서 귀무가설을 검정하게 된다.이외에도 multiple linear regression에서 몇가지 소개할 방법들이 있다.첫번째로 소개할 것은 R- package의 glmperm 작동원리가 되는 방법이다. 가설과 모델이 모두 위와 동일할 때, 귀무가설하에서 얻어낸 잔차값을 Z 를 대신해 모델에서 사용하는 것이다. 즉 잔차 $\\gamma$에 대해 모델 $Y = \\beta_0 + \\beta_1 X + \\beta_2 \\gamma + \\epsilon $ 을 가지고 test를 진행할 것이다.여기서는 LR statistic을 찾아낸다. 잔차값을 permutation(without replacement) 한 뒤 각각 case 에 대해서 LR statistic을 구해 카이제곱분포로 근사시켜 p-value까지 직접 구한다. 그런 다음 permutation case에 대한 p-value $p_b^*$ 에 대해 최종적인 p-value 로\\[p = \\frac {\\sum I(p_b^* \\leq f*p)} {B}\\]로 p-value 를 구한다.(여기서 f의 값은 numerical instability를 고려한 1과 가까운 매우 작은 값이다.)두번째로 소개할 방법은 만약 잔차를 계산하는 것의 비용이 많이 들 때의 해결방법이다. 이때는 X와 Z를 고정 시키고 Y를 permute 해서 귀무가설을 검정할 수는 있겠으나, 이 경우 X의 outlier가 존재할 때 상응하는 Y의 값이 random allocation에 의해 관계를 잃어버리게 된다는 한계가 있으므로 주의해야 한다 (sample size가 작을 때 좋을 것)마지막 방법으로는 residual을 이용하되, 대립가설하에서 exchangeablility를 보는 것이다. 즉 full model하에서의 잔차를 구하고 permute 한 뒤, 이를 검증하고 싶은 변수와 적합해서 계수값에 대한 p-value를 구하는 것이다. 이 값은 각 가설하에서 error term의 분포에 기반한 검정이므로 표본이 매우 작을 경우에는 사용하기 어렵다( 표본이 크면 정규근사하기 때문에 error term의 분포가 각 가설하에서 다르더라도 표본이 클 경우 사용가능하다는 말!)" }, { "title": "CDA - ROC/AUC", "url": "/posts/ROC_AUC/", "categories": "", "tags": "categorical data", "date": "2021-10-31 00:00:00 +0900", "snippet": "이 글은 범주형 데이터분석과 관련한 아티클을 읽고 정리한 글이다.아티클 주소는 (https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb) 이다.ROC ( Receiver Operating Characterisitc ) curvebinary classification algorithm에서 주로 사용되는 모델 성능 평가 기준 중 하나이다.binary 케이스에서 나올 수 있는 4가지 케이스의 결과는 다음과 같다true / false는 예측값과 실제값이 맞는지를 표현하며, postive / negative 값은 예측값이 양성인지 아닌지를 표현한다.여기서에서 TP 와 FP를 활용해서 여러가지 threshold 값에 따른 ROC curve를 만들어낸다.이를 통해서 최적의 threshold 값을 선택할 수 있을 것이다.이제 ROC curve의 각 축인 sensitivity와 1- specificity에 대해 자세히 알아보겠다.SensitivityTrue Positive Rate = Sensitivity = P(Diagnosis of Test is Positive $\\mid$ person has disease) = $\\frac {TP}{TP + FN}$FN 은 음성으로 예측했는데 실제로는 암이 있는 상황이므로 TP와 합쳐져서 실제로 암이 있는 환자의 전체 개수를 나타낸다1 - SpecificityFalse Positive Rate = 1 - Specificity = P(Diagnosis of Test is Negative $\\mid$ person doesn’t have disease) = $\\frac {FP}{TN+ FP}$FPR 은 쉽게 말해서 ‘false alarm’ 이다. 즉 병이 없는데 병이 있다고 잘못 알람하는 것!Curve위 그림에서 보면 회색 점선은 랜덤 추측 (즉 찍기) 에 기반한 curve 이며, 보라색 선은 perfect classifier를, 파란색 선은 연구자가 설정한 threshold하에서의 curve를 나타낸다. 모델의 성능을 높이기 위해서는 같은 FPR이라면 TPR이 높을수록 좋을 것이다. 이를 면적으로 표현해서 설명한 것이 AUC이다. (curve에 대한 single metric)AUC (Area Under the Curve)curve 그림에서 회색선이 auc = 0.5, pefect classifier = 1.0" }, { "title": "CDA - chap2", "url": "/posts/CDA2/", "categories": "", "tags": "categorical data", "date": "2021-10-27 00:00:00 +0900", "snippet": "Describing Contingency Tables2.1 Probaility structure for contingency tables2.1.1 Contingency TablesI rows for categories of XJ columns for categories of Y==&amp;gt; IJ possible combinations of outcomes2.1.2 Joint/Marginal/Conditional Distributions for Contingency Talbes그림에서 보듯 X와 Y가 모두 변수이면 table안에는 $\\pi_{12}$ 와 같이 joint probability가 들어가겠지만, 제시된 상황이 X에 대한 Y의 조건부분포라면 아래와 같이 $\\pi_{1|2}$와 같이 표기 될 것이다. 즉 분할표 안의 확률값은 어떤 상황을 table로 바꾸었는지 파악해야 알 수 있다.2.1.3 Example : Sensitivity and Specificity for Medical Diagnosessensitivity : P(Diagnosis of Test is Positive $\\mid$ person has disease)specificity : P(Diagnosis of Test is Negative $\\mid$ person doesn’t have disease)$\\pi_{1\\mid1}$ = sensitivity, $\\pi_{2\\mid2}$ = specificity위와 관련한 자세한 내용은 다른 글에서 다룰 예정2.1.4 Independence of Categorical Variables$\\pi_{ij} = \\pi_{i+} \\pi_{+j} $2.1.5 Poisson, Binomial and Multinomial sampling포아송 -&amp;gt; 다항분포 -&amp;gt; 초기하분포 로 연결되는 관계를 보여준다 Poisson samplingtable 안의 셀 $Y_{ij}$가 모두 독립인 포아송분포 Poi($\\mu_{ij}$)를 따른다고 생각해보자.이 때는 table 안의 각 셀 $n_{ij}$ 에 대한 joint probability는 다음과 같다.$P(Y_{ij}= n_{ij}) = \\Pi_i \\Pi_j exp(-\\mu_{ij}) \\mu_{ij}^{n_{ij}}/n_{ij}! $ Multinomial sampling각 셀들이 포아송분포를 따르는데, 전체 샘플사이즈 n 이 고정되어 있으면$P(Y_{ij}= n_{ij}) = [n! / (n_{11}! \\cdots n_{IJ}!)] \\ \\ \\Pi_i \\Pi_j \\pi_{ij}^{n_{ij}} $ Independent Multinomial sampling ( = product multinomial sampling)전체 샘플사이즈 n 이 고정되어 있으며, 설명변수 X에 대해 반응변수 Y가 서로 다른 설명변수에 대해서는 독립적으로 나타날 때$P(Y_{ij}= n_{ij}) = \\Pi_i [\\frac {n_i !} {\\Pi_j (n_{ij}!)} \\Pi_j \\pi_{j\\mid i}^{n_{ij}}]$ Hypergeometric전체 샘플사이즈 n이 고정되어 있으며, row 와 column 모두 고정되어 있을 때.2.1.6 ~ Example실험 설계의 방법 (1) Prospective - Clinical trials(연구자가 임의로 대상을 특정 군에 넣은 뒤 어떤 현상이 일어나는지 관찰), Cohort studies(연구 대상자가 특정 군을 선택한 뒤 어떠한 결과가 발생하는지 지켜보는 것) - 설명변수 X를 사전에 control 하기 때문에 marginal sum 이 정해져 있는 경우가 많다 ==&amp;gt; independent multinomial Cross-sectional - 특정군에서 발생하는 현상을 미리 setting 한 뒤에 sample을 동시에 배치하는 것 - total N 이 정해진다 =&amp;gt; multinomial Retrospective - 반응변수 Y를 사전에 control 하고 marginal sum이 정해지는 경우가 많다 =&amp;gt; multinomial아래 표에서 나오는 예시는 case - control study의 예시인데, 여기서는 암환자와 그렇지 않은 환자를 각각 709명씩 모집하고(즉 margianl is fixed) 그들이 흡연자인지 아닌지 살펴보는 retrospective sampling design 이다.위와 같은 연구에서는 암환자 중에서 흡연자의 비율만 알 수 있기 때문에, Bayes rule을 사용해서 흡연자 중에서 암이 발생할 확률을 알기 위해서는 전체 암 환자의 비율을 알고 있어야 한다.실험 설계의 방법 (2) Experimental Study - clinical study - power of randomization, group balance, control the confounding effect Observational Study - case-control, cohort, cross-sectional - bais 에 대한 위험성, causal connection이 생길 수 있음.2.2 Comparing two proportions2.2.1 Difference of Proportionsi 번째 row에 대해서, $\\pi_{1|i}$를$\\pi_i$ 라고 표현할 때 첫번째 열에 대한 확률값을 차이를 표현하면 $\\pi_1 - \\pi_2$ 이고 이를 difference 라고 한다. 만일 row 들이 동일한 분포를 가지고 있다면 difference = 0 일 것이다.(당연한 것) 즉 diffence =0 이면 row에 대해서 독립2.2.2 Relative RiskRR = $\\pi_i / \\pi_j$difference는 값의 차이만 나타낼 뿐 상대적 크기를 나타낼 수 없는 한계를 가지고 있는데, 이를 보완해서 RR을 만들었다. RR =1 이면 독립RR 은 확률이므로, table에 도수로 나와있는 경우 확률값을 구해서 비를 구해야 한다!참고 : attributable risk = $\\pi_i - \\pi_j$2.2.3 Odds Ratio Odds = 성공의 비율 / 실패의 비율따라서 오즈값을 알면 역으로 성공의 확률을 알 수 있다. Odds ratio = odds1 / odds2joint distributions with cell probabilities {$\\pi_{ij}$} 에 대해서 오즈비는 아래와 같이 다양한 형태로 표현된다\\[\\theta = \\frac {\\pi_{11}/\\pi_{12}} {\\pi_{21}/\\pi_{22}} = \\frac {\\pi_{11}\\pi_{22}}{\\pi_{12}\\pi_{21}} = \\frac {n_{11}n_{22}}{n_{12} n_{21}}\\]제일 마지막 term 때문에 cross-product ratio 라고도 불림.2.2.4 Properties of the Odds Ratio 모든 셀에 대한 odds ratio 값이 1 이면 X와 Y는 서로 독립이다. 오즈비가 1보다 크다면, i 번째 성공에 대한 오즈가 j 번째 성공에 대한 오즈에 비해 크다 (성공률이 아니라 성공에 대한 오즈에 대한 비율이 오즈비!!) 오즈비와 RR을 구분하자. 예를 들어 오즈비가 3인 것이 $\\pi_i = 3\\pi_j$을 의미하는 것은 아니다. 표를 해석하는 방향에 따라 오즈비는 기존 값의 역수값이 될 수 있다. $log \\theta $ 를 사용하면 독립일 때 로그 오즈비 = 0 ;; 표의 해석방향을 다르게 할 시(행 방향이든 열 방향이든 한쪽으로만), 로그오즈비는 부호가 바뀌게 됨. (sign 만 제외하고는 로그오즈비의 값이 같아지기 때문에 해석하기도 더 편하다.) tabel 자체를 transpose해서 생각하면 오즈비는 동일하다. 이러한 성질때문에 오즈비는 RR과 달리 prospective, retrospective, cross-sectional sampling design에서 모두 가능하다. (예를들어, 위의 흡연과 암환자 테이블에서 보면 흡연에 따른 암에 대한 RR을 구하고 싶어도 후행적 연구에서는 구할 수 없다. 그러나 오즈비는 이와 상관없이 항상 동일하기 때문에 후행적연구에서도 구할 수 있는 것이다) table의 특정 행 또는 특정 열의 셀들에서 동일한 비율로 샘플 수를 늘리면 오즈비는 변하지 않는다. 예를들어 열 방향으로 marginal sum이 각각 50, 50 이었는데 첫번째 열에는 1.5를 곱하고 두번째 열에는 2를 곱해서 각 샘플수를 만들었다고 해도 오즈비는 변하지 않는다. (RR와 difference의 차이)2.2.7 Relationship between Odds Ratio and Relative RiskOdds ratio = RR * $(1-\\pi_2) / (1- \\pi_1)$즉 $\\pi_i$ 가 0에 가까울수록 오즈비와 RR의 값은 유사해질 것이다.위의 흡연과 암환자 테이블에서, 만약 흡연 여부와 관련없이 암이 생길 확률이 매우 낮다면 오즈비의 값은 RR과 유사할 것이다.위 테이블에서 오즈비가 약 3인데, 흡연 했을 때 암이 걸릴 확률은 그렇지 않을 경우에 비해 3배 정도 높다고 할 수 있다.2.3 Conditional Association in Stratified 2 X 2 TablesX가 Y에 미치는 영향을 알고싶은데, 어떤 covariate이 X와 Y 모두에 영향을 주는 경우? 이 때를 X와 Y 관계가 confounding을 나타낸다고 말한다. (relationship between X and Y shows confounding)이런 효과를 제거하기 위해서는 X의 각 다른 level에 대상들을 랜덤하게 할당함으로써 해결해볼 수 있겠으나, 후행적 연구라면 이 또한 불가하다.따라서 confounding variable을 통제하면서 X와 Y 간의 association을 분석하는 것이 중요하다.2.3.1 Partial Tablesthree way contingency table을 생각해보자.Z의 각 수준을 통제한 채로 X와 Y의 관계를 보고자 하는데 이 경우 실제로 보고자 하는 내용은 two way table이 된다.(예를 들어 Z가 1인 경우의 X, Y table을 보는 것) 이를 partial table이라고 한다.만약 이러한 partial table을 합치게 된다면 이는 marginal table between x and y 가 될 것이다.partial table에서의 association을 conditional association이라고 하는데 이는 marginal table에서의 association과 다를 수 있다. 아래 예시를 잘 보자.2.3.2 Simpson’s Paradox아주 유명한 예제이다.아래 three way table을 3차원으로 표현한 것이 figure 2.1 이다.3차원 그림은 victim’s race를 covariate으로 보고 각각의 case에 대해 conditional association (percentage) 를 보여주고 있다. 이렇게 보면 피해자들의 인종과 관련 없이 피고의 인종이 흑인일 경우에 사형판결을 받을 확률이 더 높아보인다. 그러나 marginal table을 보면 (즉 피해자의 인종을 완전히 무시하면) 피고의 인종이 백인일 경우 사형판결을 받을 확률이 훨씬 높아보인다 왜 이런 일이 발생하는 것일까?이는 victim’s race 라는 공변량이 X 혹은 Y에 영향을 주기 때문이다. 특히 이렇게 marginal와 conditional의 association이 다르게 나오려면 공변량이 x 혹은 y 에 미치는 영향이 매우 커야함이 증명되었다.2.3.3 Conditional and Marginal Odds Ratiossimpson’s paradox를 설명하는 table에서보면, conditional odds ratio는 victim의 각 인종에서 모두 1보다 작다. $\\hat \\theta_{XY(1)} = 0.43$ 이므로 (1,1) 원소인 백인이 사형판결받는 case의 odds 값이 흑인 case odds의 43% 밖에 되지 않음을 알수있다.그러나 margianl odds를 비교해보면 그 값이 1을 넘어선다.이 역시 conditional association와 marginal association을 잘 구분해야함을 말한다.2.3.4 Marginal independence VS Conditional independenceX and Y are siad to be conditionally independence given Z when they are conditionally independent at every level of Z\\[P(Y = j | X = i , Z = k ) = p(Y = j | Z = k), \\ \\ \\forall i,j\\]이를 이용하면 conditional independence 가 성립하는 경우\\[\\pi_{ijk} = P(X=i, Z=k)P(Y=j | Z=k) = \\pi_{i+k}\\pi_{+jk} / \\pi_{++k}\\]임이 증명된다.또한 앞서 simpson’s paradox에서 계속 설명한 것처럼, 여기서도 conditional independence와 marginal indepence는 서로 동일한 개념이 아님을 보일 수 있다.참고 : marginal independence = $\\pi_{ij+} = \\pi_{i++}\\pi_{+j+}$2.3.5 Homogeneous Association만약 X와 Y의 association이 homogeneous 이면\\[\\theta_{XY(1)} = \\theta_{XY(2)} = \\theta_{XY(3)} = \\cdots =\\theta_{XY(k)}\\]2.4 Measuring Association in I X J tables2X2 table에서는 odds ratio를 통해서 변수간의 요약정보를 전달할 수 있었다. 그러나 일반적인 I X J table에서는 odds ratio를 사용하는 경우 일부 변수간의 관계는 고려되지 못한다.이를 어떻게 해결할 수 있을까?2.4.1 Odds ratios in IXJ tables첫 번째 방법으로, odds ratio의 set을 모두 살펴보는 것이다.여기서 알 수 있는 오즈비의 성질을 살펴보자I X J table에서는 $\\binom{I}{2} \\binom{J}{2}$ 개의 odds ratios 가 존재한다.local odds ratio를 아래와 같이 정의하면\\[\\theta_{ij} = \\frac {\\pi_{i,j} \\pi_{i+1,j+1}}{\\pi_{i,j+1} \\pi_{i+1,j}}\\]local odds ratio는 (I-1)(J-1) 개 존재한다. 이를 활용해서 원하는 변량 간의 오즈비를 곱셈을 통해 구할 수 있다.예를 들어 $\\alpha_{ij}$ 를 X의 i level 와 I 번째 level, Y의 j 번째 level와 J 번째 level 간의 오즈비라고 할 때\\[\\alpha_{ij} = \\frac {\\pi_{i,j} \\pi_{I,J}}{\\pi_{i,J} \\pi_{I,j}} = \\theta_{i,j}\\theta_{i+1,j}\\cdots\\theta_{I-1,J-2}\\theta_{I-1,J-1}\\]로 표현할 수 있다. 이로부터, 오즈비를 만드는 방법은 유일하지 않음을 알 수 있다.또한 변수가 독립이라면 (I-1)(J-1) 개의 오즈비는 모두 1이 나올 것이다.2.4.2 Association Factors두 번째 방법으로는 모두 독립일 때를 가정할 때의 기대값과 실제 데이터값을 비교해보는 것이다.association factor 를 아래와 같이 정의한다\\[\\pi_{i,j} / (\\pi_{i+}\\pi_{+j})\\]이 값이 1이면 level 간 독립이 성립하는 것을 의미하며 양 극단 값인 0 와 $min(1/\\pi_{i+}, 1/\\pi_{j+})$ 로 갈수록 독립 관계에서 멀어진다 할 수 있다.2.4.3 Summary Measures of Associationassociation을 보기 위해서 새로운 summary index 를 설정할 수도 있다.아래와 같은 식을 생각할 수 있을 것이다.\\[\\frac {V(Y)-E[V(Y|X)]}{V(Y)}\\]여기서 $V(Y)$는 marginal distribution인 ${\\pi_{+j}}$ 의 분포에 대한 분산을 나타낸다.만약 entropy를 사용한다면 위 식을 아래와 같은 과정을 통해 새롭게 정의할 수 있을 것이다. 명목형 반응변수에 대해서 variation 에 대한 measure로 $V(Y) = \\sum j \\pi{+j} log \\pi_{+j}$ 를 설정 : negative entropy ‘conditional entropy = $- \\sum j \\pi{j \\mid i} log \\pi_{j \\mid i} $’ 에 대해 기댓값과 기존의 entropy 차를 구한다. 두개의 비를 구한다. 그 값은 아래와 같다 이에 대해 expectation of conditional entropy - entropy 와의 비를 구하면 association에 대한 새로운 index를 정의할 수 있다.\\[\\frac{ - \\sum_i \\pi_{i+} \\sum _j \\pi_{j|i} log \\pi_{j|i} - (-\\sum _j \\pi_{+j}log \\pi_{+j})}{- \\sum _j \\pi_{+j}log \\pi_{+j}} = \\frac{\\sum _j \\pi_{+j}log \\pi_{+j} - \\sum_i \\pi_{i+} \\sum _j \\pi_{j|i} log \\pi_{j|i}}{\\sum _j \\pi_{+j}log \\pi_{+j}} = - \\frac {\\sum_i\\sum_j\\pi_{i,j}log(\\pi_{i,j}/\\pi_{i+}\\pi_{+j})}{\\sum _j \\pi_{+j}log \\pi_{+j}}\\]값을 uncertainty coefficient 라고 한다.(참고 1. cross entropy = $- \\sum _j \\pi_{+j} log \\pi_{i+}$ )(참고 2. 분할표의 특성상; 이 값이 1이라면 조건부 확률인 $\\pi_{j|i}$에 대해서 $ \\forall i, \\exists j, \\pi_{j|i}=1$ ;; 이 값이 1이면 X와 Y는 서로 독립이다라고 말할 수 있다)2.4.4 Ordinal Trends위에서는 nominal data에 대한 association을 살펴보았다. 그럼 ordinal 데이터는 어떻게 보아야 할까?ordinal 데이터에 대해서는 concordant 와 discordant 를 살펴볼 수 있다.concordant : x 의 rank가 높아질 때 , y 의 rank도 높아짐을 의미 $\\Leftrightarrow$ discordant아래 table에서 total number of concordant를 C ; total number of discordant를 D라고 하면C = 34(174+304+75+172) + 53(304+172) + 80(75+172) + 174(172)D = 88(80+174+29+75) + 53(80+29) + 304(29+75) + 174(29)C &amp;gt; D 인 것을 알 수 있으므로 나이가 많을수록 직무 만족도가 크다는 것을 알 수 있다.concordant와 discordant의 확률값은pair로 계산하기 때문에 2가 붙은 것을 알 수 있다.2.4.5 Ordinal Measure of association : Gamma위에서 구한 total number of concordant and discordant를 가지고 gamma값을 구할 수 있다\\[\\gamma = \\frac {\\Pi_c - \\Pi_d} {\\Pi_c + \\Pi_d}\\]이 gamma 값은 상관계수와 유사하다. -1와 1 사이의 값을 가지고 있다. ordering이 반대로 된 ordinal 데이터의 경우 gamma값의 부호가 바뀔 것이다. 상관계수는 perfect linear 이면 절댓값 1을 갖지만 gamma는 monotonicity 가 성립하면 절댓값이 1이다. 독립이면 gamma =0 인데 역은 성립하지 않는다.이 개념을 연속형 변수로 확장하면 상관관계에 대한 비모수 추론인 Kendall’s tau value를 얻게 된다.2.4.8 Correlation for underlying Normalityordinal variable의 경우, 각 셀에 특정 값을 준다던가 혹은 중위수를 선택해서 pearson correlation formula 를 사용할 수도 있을 것이다." }, { "title": "Online Covariance Estimation - paper - 4", "url": "/posts/Online_COV_paper_4/", "categories": "", "tags": "estimation, statistical computing, machine_learning", "date": "2021-10-26 00:00:00 +0900", "snippet": "4. Simulation Studiesevaluate the empirical performance of the proposed online approachtwo class of example : linear regression &amp;amp; logistic regressionsettingdata( iid sequence of pair ) : $ { \\xi \\equiv (a_i, b_i)} $ &amp;amp; $a_i \\sim N(0, \\mathbf{I}_d)$$x^*$ : true parameter$\\eta_j = 0.5 j^{-\\alpha}$ : step size$\\alpha = 0.505$ (chosen)$a_m = [Cm^{2/(1-\\alpha)}]$ : seqence ==&amp;gt; 이것을 가지고 block B = $ {B_i : a_m \\leq i &amp;lt; a_{m+1} } $ 를 만들어 낸다.$+$200번 run 이후 average = ASGD4.1 Empirical performance of the porposed online approachlinear regression 가정 : $b_i = a_i^Tx^* + \\epsilon_i $$f(x^*)$는 negative log-likelihood function4.1.1 Convergence of the recursive estimatorlimmiting covariance matrix\\[\\Sigma = A^{-1}SA^{-1} = \\mathbf{I}_d\\]where\\[A = E[\\nabla^2f(x^*)] = E(aa^T) = \\mathbf{I}_d \\\\ S = E([\\nabla f(x^*, \\xi)][\\nabla f(x^*, \\xi)]^T)=E(\\epsilon^2)E(aa^T) = \\mathbf I_d\\]이므로, online estimator의 convergence를 확인하기 위해서는 추정한 분산행렬을 사용한 operator norm Loss를 계산해본다.Figure 1 은 이를 나타낸 것이다.y축은 $log loss = || \\hat \\Sigma_n - \\Sigma ||_2$x축은 log of total number of steps = $log \\eta_i$ 를 의미한다(limiting covariance 가 위와 같이 나오는 것은 $\\dot l(\\theta) = \\dot l(\\hat \\theta) + \\ddot l(\\hat \\theta)(\\theta - \\hat \\theta) $ 식을 통해 limiting covariance를 찾는 과정에 기인.)아래의 Figure 2 는 relative efficiency(MSE of full overlapping / MSE of non-overlapping)를 나타낸 것이다. 그림에서도 알 수 있듯 C 값은 performance와 그리 큰 관련이 있어보이진 않는다.4.1.2 Asymtotic normality and CI coverage공분산을 추정했으니 이를 활용해서 신뢰구간을 구할 수 있다.\\[[1^T \\bar x_n - z_{1-q/2}\\sqrt{1^T \\hat \\Sigma_n 1 /n} , 1^T \\bar x_n + z_{1-q/2}\\sqrt{1^T \\hat \\Sigma_n 1 /n} ]\\]true limiting covariance matrix 를 활용해서 CI를 구할 수 있는데 아래 그림인 figure3 에서 보듯, empirical coverage rate이 95%로 수렴하고, SE와 CI length 또한 참값과 유사하다." }, { "title": "CDA - chap1", "url": "/posts/CDA1/", "categories": "", "tags": "categorical data", "date": "2021-10-25 00:00:00 +0900", "snippet": "Introduction : Distributions and Inference for Categorical Data1.1 Categorical Response Data범주형 자료의 다양한 예시 e.g. classification, how good a product1.1.1 Response-Explanatory variable Distinction설명변수의 데이터 형태는 다양하다!1.1.2 Binary-Nominal-Ordinal Scale Distinction binary - two categories nominal - more than two categories without ordering ordinal - ordered categories - distances between categories are unknown - e.g. patient condition interval variable - numerical distances exist - e.g. annual income+ discrete interval variable continuous variable어떻게 변수를 측정하는지에 따라 같은 자료에 대해 여러가지 형태의 변수를 만들 수 있다.binary ~ interval variable 은 lower level 에서 higher level로 정렬되어 있는데, 낮은 수준에서 사용한 분석법은 높은 수준의 변수에서도 사용가능 (역은 안됨)1.1.3 Discrete-Continuous Variable Distinctiondiscrete 와 continuous 의 차이는 셀수 있는지 여부. discrete 변수의 값이 너무 많으면 그건 연속형 변수로 보겠다!1.1.4 Quantitative - Qualitative Variable DistinctionNomial - Qualitativeoridnal - fuzzy (순서형 자료의 경우 크고 작고는 있으므로 이를 활용해서 양적변수처럼 인식할 수도 있을 것이다 =&amp;gt; scale을 잘 활용해서 numerical score를 할당하면 가능할 것) (nomial data에서 ordinal data로 바뀌면 자유도가 줄어들기 때문에 Power는 더 커진다)interval - Quantitative예제 ) $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$ 에서 x가 nominal 데이터라면 더비 변수를 활용하기 때문에 x의 케이스가 4 인 경우 $\\beta_1 = 0$ 임을 검정하는 것은 $\\beta_1=\\beta_2=\\beta_3 = 0$ 을 검정하는 것과 동일하게 된다. 따라서 f statistic은 자유도가 (3, n-4) 인 분포에서 나오게 된다.반면 x가 oridnal 데이터라면 이미 변수 안에 크기 관계가 정해져있으므로, $\\beta_1 = 0$ 을 검정하는 것이므로 f statistic은 자유도가 (1, n-2) 인 분포에서 나오게 된다.1.2 Distributions for Categorical Data binomial —- binary obs 가 독립이 아니라면 hypergeometric Multinomial —- $E(n_j) = n \\pi_j$ , $var(n_j)=n \\pi_j ( 1- \\pi_j)$ , $cov(n_j, n_k) = -n \\pi_j \\pi_k$ Poisson —- binomial 에서 n이 매우 크고 $\\pi$ 가 매우 작을 때 포아송 근사 가능. 포아송분포는 평균값이 증가면서 정규근사 됨.1.2.4 Overdispersion정의 : 특정 분포를 가정하고 관측을 했을 때, 매우 특이한 이상치들이 나올 수 있다.상황 : 특정 상황의 변화에 따라 분포의 모수가 바뀔 수 있음(베이지안 관점).e.g. $Poi(\\theta)$ 에서 $var(Y) = E[var(Y \\mid \\mu)] + var[E(Y \\mid \\mu)] = E(\\mu) + var(\\mu) &amp;gt; \\theta $ 분포가 서로 다른 모수를 가진 binomial 분포의 mixture 분포해결 : Quasi-Likelyhood and GLM (chapter 4.7)일반적으로 GLM에서 score function을 구하면 다음과 같다exponential dispersion family\\[f(y ; \\theta_i, \\phi) = exp(\\frac {y_i\\theta_i - b(\\theta_i)} {a(\\phi)} + c(y_i,\\phi))\\]에 대해\\[Score \\ f = \\sum_{i=1} ^N \\frac{(y_i - \\mu_i)x_{ij}}{var(y_i)} \\frac{\\partial \\mu_i}{\\partial \\eta_i} = 0 \\ \\ -- (*)\\](단, $g(\\mu_i) = \\eta_i$)반면 Quasi-likelihood estimate 은 특정 분포가 아닌 평균과 분산의 관계만을 가정한다. (예를 들자면 포아송분포의 평균은 분산과 동일한데, 이때 그 관계를 $\\nu(\\mu_i) = \\mu_i$ 이런식으로 정의하는게 끝)그럼 평균과 분산만의 관계로 어떻게 추정이 가능할까? ===&amp;gt; 위의 (*) 함수를 사용한다! (exponential family 가 아니어도 이 식을 사용한다)\\[\\sum_{i=1} ^N \\frac{(y_i - \\mu_i)x_{ij}}{\\nu(\\mu_i)} \\frac{\\partial \\mu_i}{\\partial \\eta_i} = 0\\]를 만족하는 모수값을 추정값으로 삼는다. 이 때 평균과 분산의 관계에 의해서 식이 아래와 같이 변형되고 포아송분포에서는 quasi-likelihoood 를 사용한 추정량이 MLE와 동일한 것을 알 수 있다.\\[\\sum_{i=1} ^N \\frac{(y_i - \\mu_i)x_{ij}}{\\mu_i} \\frac{\\partial \\mu_i}{\\partial \\eta_i} = 0\\]추가적으로, QL estimateor 는 GLM에서 찾은 MLE의 점근적 분산과 동일하다. $var(score \\ f) = I_n(\\beta) = var(X^TDV^{-1}(y-\\mu)) = X^TWX$이제 실제로 overdispersion을 quasi-likelihood를 사용해서 다뤄보자.\\[\\nu(\\mu_i) = \\phi \\mu_i\\]라고 가정하면, $\\phi &amp;gt; 1 $ 일 때 overdispersion을 다룰 수 있다.즉 분산이 $\\nu(\\mu_i) = \\phi \\nu^* (\\mu_i) $ 일 때\\[\\chi^2 = \\sum_{i=1} ^N \\frac{(y_i - \\hat \\mu_i)}{\\nu^*(\\hat \\mu_i)}\\]에 대해 $E(\\chi^2 / \\phi) \\approx N-p$ 이므로 $\\hat \\phi = \\chi^2 / (N-p)$ 로 추정 가능하다. 이를 활용해서 일반적인 GLM 에서 찾은 분산값에 $\\hat \\phi$ 를 곱해주면 overdispersion을 다룰 수 있다.1.2.5 Connection between Poisson and Multinomial Distributionsiid 포아송분포의 합은 당연히 포아송분포를 따르게 되는데, 만약 그 합의 개수가 N으로 정해져있다면?$N= \\sum Y_i $ 가 given이면 $Y_i$는 절대 N을 넘을 수 없고 이때는 더이상 Y 가 포아송분포가 아니게 된다.pf)1.2.6 The Chi-Squared Distribution카이제곱분포는 데이터들의 분포가 아니라 sampling distribution 이다.자유도가 증가하면 normal로 근사par(mfrow = c(1,4))n &amp;lt;- c(5,30,50,100)for (i in 1:4){ chi.square &amp;lt;- c() for (j in 1:1000) { x &amp;lt;- rnorm(n[i],0,1) chi.square[j] &amp;lt;- sum(x*x) } hist(chi.square,probability=T, main = paste0(&#39;df=&#39; , n[i])) y &amp;lt;- seq(from=0, to=10*n[i], by=0.1) fy &amp;lt;- dchisq(y, n[i]) lines(y, fy, col=&#39;red&#39;)}1.3 Statistical Inference for Categorical Data1.3.1 Likelihood Functions and Maximum Likelihood EstimationMLE 는 regularity condition 하에서 asymtotically consistent and asymtotically efficient(MLE 정의? likelihood function을 최대로 하는 추정값. 관찰된 데이터가 가장 잘 일어나게끔 하는 파라미터 추청값)그렇기 때문에 Likelihood function이 더욱 curvature 할수록 estimator의 분산은 더욱 줄어든다.( 더욱 curvature 할수록 mle 값에서 멀어질수록 곡선이 빠르게 감소한다 )1.3.2 Likelihood Function and ML Estimate for Binomial Parameterbinomial distribution에 대한 mle를 구하면 $\\hat \\pi = y/n$ , $E(\\hat \\pi)$ 와 $var(\\hat \\pi)$ 를 구할 수 있음.또한 $\\hat \\pi$ 에 대한 asymtotic variance를 fisher information을 통해 구할 수 있는데, 이는 $var(\\hat \\pi)$ 와 같다.1.3.3 Wald - Likelihood Ratio - Score Test Traid우선 여기서 제시하는 3가지 방법이 모두 likelihood function을 활용해서 추정을 하는 것임을 숙지해야 한다.null hypothesis : $\\beta = \\beta_0$Waldstandard error 를 사용하는 방법. 가장 기본 form은 다음과 같은데, fisher information이 모수에 대한 f 이므로 모수 추정값을 plug-in\\[Z = (\\hat \\beta - \\beta_0)/SE, \\ \\ \\ where \\ \\ \\ SE = 1/\\sqrt{\\mathbf(I(\\hat\\beta )}\\]Z 통계량은 샘플이 커질 수록 Normal로 근사하고, 양측검정일 경우 Z의 제곱값은 카이제곱분포를 따르므로 카이제곱 분포를 활용한 검정이 가능하다.Multivariate으로 확장하면\\[(\\hat \\beta - \\beta_0)^T[cov(\\hat \\beta)]^{-1}(\\hat \\beta - \\beta_0)\\]LR\\[-2 log \\Lambda = -2 log (L_0/L_1) = 2(l_1 - l_0)\\]이 통계량은 귀무가설하에 카이제곱분포로 근사하고, 자유도는 전체모수공간에서 파라미터 dimension 과 귀무가설하에서 파라미터 dimension의 차이이다.Scorescore function을 사용하기 때문에 score test라고 불린다. 다른말로는 Lagrange multiplier testscore function $\\dot l(\\beta)$에 대해서\\[\\dot l(\\beta)^T [\\mathbf{I}(\\beta)]^{-1} \\dot l(\\beta)\\]형태를 생각하자. 그런 다음 귀무가설 하에서 모수값에 대한 MLE인 $\\beta_0$ 값을 위 식에 plug-in즉\\[\\dot l(\\beta_0)^T [\\mathbf{I}(\\beta_0)]^{-1} \\dot l(\\beta_0)\\]1.3.4 Constructing Confidence Intervals by Inverting Tests위에서 제시한 세가지 추정 방법을 통해 각기 다른 CI를 찾아낼 수 있다. 특히 Normal 가정하에서 regression setting이면 추정량에 대한 CI는 모두 동일$100(1-\\alpha)%$ Confidence intervalWald\\(|\\hat \\beta - \\beta_0|/SE &amp;lt; Z_{\\alpha /2}\\)LR\\(2(l_1 - l_0) &amp;lt; \\chi^2 (\\alpha)\\)신뢰구간을 구하기 복잡함Score이건 특별한 조건 하에서만 가능.종합하면…. 만약 sample size N 이 충분히 크지 않아 Normal 가정이 성립하지 않는다면 신뢰구간 또한 올바르지 않을 것이다. 또한 parameter의 개수가 너무 많으면 MLE 추정량의 정확성이 떨어지기 때문에 이를 고려할 필요가 있다.1.4 Statistical Inference for Binomial Parametersbinomial setting에서 wald와 score를 비교해보면 모수값에 대한 SE가 형태는 동일하되, wald 는 추정값을, score는 귀무가설 값을 plug-in 하기 때문에 귀무가설하에서의 추청량을 활용한 극한분포는 score의 경우에 normal 근사가 더욱 잘될 것이다. 특히 참값이 귀무가설과 유사할 경우는 더욱 그러할 것.1.4.4 Exact Small-Sample Inference and the Mid P-Valuecomputation power로 인해서, normal 근사를 하지 않고도 Exact p-value를 구할 수 있다.다만 이산형자료의 경우 정확하게 p-value가 0.05가 되지 않기 때문에 때로는 보수적인 검정을 하게된다. 즉 유의수준보다 더 작은 값을 갖는 p-value를 기준으로 기각역을 설정하게 된다. 표본이 작은 경우 이산형 자료에 맞는 p-value 값을 주기 위해서 아래의 p-value를 활용할 수 있다.\\[mid \\ \\ P-value \\ = \\frac {P(T=t_0)}{2} + P(T&amp;gt;t_0)\\]이 값을 활용하면 이산형에서도 p-value = 0.5를 만들 수 있다 (즉 홀수개의 자료에서도 p-value 값을 합리적으로 구할 수 있다.)1.5 Statistical Inference for Multinomial Parameters1.5.1 Estimation of multinomial parameters라그랑지안을 사용해서 증명이 가능하다.\\[\\hat \\pi = n_j / n\\]1.5.2 Pearson Chi-Squared Test of a Specified Multinomialpearson chi-squared test는 categorical data 분석에 아주 큰 영향을 주었다.귀무가설 $H_0 : \\pi_j = \\pi_{j0} $ ,=1,2,3,…,c 에 대한 통계량은 다음과 같다. $\\mu_j = n\\pi_{j0}$ 일 때\\[\\chi^2 = \\sum_j \\frac{(n_j - \\mu_j)^2}{\\mu_j} \\ \\ \\sim \\chi^2 (c-1) \\ \\ under \\ H_0\\]multinomial 에서 score statistic과 일치한다1.5.3 Likelihood-Ratio Chi-squared test of a specified multinomial귀무가설 $H_0 : \\pi_j = \\pi_{j0} $ ,=1,2,3,…,c 에 대한 통계량은 다음과 같다.\\[G^2 = 2log\\Lambda = 2 \\sum_j n_j log(n_j/n \\pi_{j0}) \\ \\ \\sim \\chi^2 (c-1) \\ \\ under \\ H_0\\]1.5.5 Testing with Estimated Expected Frequencies만약 귀무가설 $H_0 : \\pi_j = \\pi_{j0} $ 에 대해 $\\pi_{j0} = \\pi_{j0}(\\theta)$ 라고 하자. 즉 귀무가설이 어떤 추정량의 함수형태로 나온다.(1.5.6 참고) MLE의 plug-in 성질에 의해 $\\hat \\mu_j = n\\pi_{j0}(\\hat \\theta)$ 이고 이를 활용해 $\\chi^2$ 이나 $G^2$ 값을 구한 다. 이 때 자유도는 $\\theta$의 차원이 p 일 때 (c-1)-p 이다.1.5.7 Chi-Squared Theoretical JustificationCLT 에 의해\\[\\sqrt{n}(\\hat \\pi - \\pi _0) \\Rightarrow^d N(0, \\Sigma_0)\\]1.6 Bayesian Inference for Binomial and Multinomial Parameters베이지안은 CI 대신에 poeterior interval or credible interval을 사용한다. 이때는 tail 양 끝 값의 확률이 동일하도록 신뢰구간을 설정.(예를 들어 95% 신뢰수준이면 2.5 ~ 97.5로)unimodal의 경우 highest posterior density(HPD) 을 사용하는데 이는 구간의 길이를 가능한 짧게 만드는 신뢰구간이다." }, { "title": "Computer Age Statistical Inference - chap 3", "url": "/posts/CASI3/", "categories": "", "tags": "datascience, statistical method, Efron", "date": "2021-10-21 00:00:00 +0900", "snippet": "Bayesian Inferenceposterior odds\\[\\frac {g(\\mu_1 | x)}{g(\\mu_2 | x)} = \\frac {g(\\mu_1)f_{\\mu_1}(x)}{g(\\mu_2)f_{\\mu_2}(x)}\\]continue…." }, { "title": "Computer Age Statistical Inference - chap 2", "url": "/posts/CASI2/", "categories": "", "tags": "datascience, statistical method, Efron", "date": "2021-10-20 00:00:00 +0900", "snippet": "Frequentist Inferenceestimator : functionestimate : estimator의 realization (single number)즉 estimate은 실제로 구현된 값들이고 이 값의 error가 어느정도인지 알고 싶을 땐 estimator를 보아야한다. (그럼 estimator는? data로부터!)Frequnetist says the accuracy of an observed estimate $ \\hat \\theta $ is the probabilistic accuracy of $\\hat \\Theta$ as an estimator of $\\theta$Frequentist in practice plug - in Taylor series approximationse.g. $ \\bar X^2 = \\bar x + 2 \\bar x (\\bar X - \\bar x) $ -&amp;gt; $ se(\\bar X ^2) = 2 |\\bar x| se(\\bar X) $ parametric family and Maximun likelihood theory simulation and the boostingi.e. value $\\hat \\Theta^{(k)} = t(X^{(k)})$ simulated from $\\hat F$, $\\hat \\Theta^{(k)}$ 들의 표준편차로 모 표준편차를 추정 Pivotal statisticsi.e. Normal 가정하에 파라미터 값에 상관없이 t statistic 이 만들어지는 것.e.g. 95% 신뢰구간에 대한 정의 : 신뢰구간이 모수값을 포함하는 것에 대해 95% confident Frequentist Optimality parametric modelMLE는 minimum (asymptotic) standard error 관점에서 optimum estimate 이다.정보량 부등식 (CRLB)에 의하면 $Var_{\\theta}(\\hat \\eta_n ) \\geq (\\frac {\\partial} {\\partial \\theta}E_{\\theta}(\\hat \\eta_n )^T[n \\mathbf(I)(\\theta)]^{-1} (\\frac {\\partial} {\\partial \\theta}E_{\\theta}(\\hat \\eta_n ) $ 인데, MLE 는 점근적으로 unbiased 이고 점근적으로 최소분산이다. hypothesis testingNeyman Pearson lemma에 의해 단순가설에서 \\[t_c(x) = \\Big \\{ \\ \\ \\ \\ \\begin{align} &amp;amp;1 \\ \\ if \\ \\ log \\frac {f_1(x)} {f_0(x)} \\geq c \\\\ &amp;amp;0 \\ \\ if \\ \\ log \\frac {f_1(x)} {f_0(x)} &amp;lt; c \\end{align}\\]는 $E_{\\theta_0}(t_c(x)) = \\alpha $ 일 때 power를 최대로 하는 검정이 가능하다.(일반적인 가설에서는 전역최강력 검정을 구하게 되는데, 이때는 귀무가설하의 검정함수 기댓값의 max 가 type 1 error 보다 작게 맞춘 상태에서 power를 최대로)figure 2.2 &amp;gt;c 값을 0.75 로 주었을 때의 type 1 error 와 type 2 error를 보여준다. Neyman Pearson lemma를 따르지 않는 검정은 모두 검은 색 선 기준으로 더 위쪽에 존재하게 된다." }, { "title": "Computer Age Statistical Inference - chap 1", "url": "/posts/CASI1/", "categories": "", "tags": "datascience, statistical method, Efron", "date": "2021-10-20 00:00:00 +0900", "snippet": "Algorithms and Inference서론 답게 아주 간단한 내용을 담고 있다이론이란 Algorithm 이 먼저 정의되고 그것의 accuracy에 대한 inference가 순차적으로 진행됨을 말해줌.==&amp;gt; 표본평균?? ==&amp;gt; 이것이 왜 좋을까?, 신뢰구간은? 가장 작은 분산을 가진 추정량일까? 등등등요즘은 대용량 데이터를 다룰 수 있는 algorithm 이 각광 받을 것.1.1lowess, bootstrapingbootstrping 을 통해서 추정량의 accuracy를 구할 수 있다! ( bootstraping 은 10장에서 자세히 다룰 것)1.2two- sample t-testt statistic 이 3.1 정도로 p-value 0.056.그러나 기존 데이터를 히스토그램으로 그려보면(우리가 t statistic을 구했기 때문에 t statistic들이 어떠한 분포를 따르는지 알아봐야하는데 이를 permutation으로 구함) 가정한 t 분포에 비해 smooth curve 가 너무 뾰족하다!figure 1.5&amp;gt;즉 통계량이 t 분포를 따른다는 가정 자체가 잘못되었기 때문에 기각여부도 잘못 판단될 것이다. 가정을 더욱 뾰족한 분포로 잡는다면 3.1 이라는 통계량은 유의수준 0.05를 고정시킨 상태에서는 기각될 것.(왜 t를 따르지 않을까? - statistic 간 상관관계 + other covariates)" }, { "title": "Python_code 2", "url": "/posts/python_code-2/", "categories": "", "tags": "", "date": "2021-08-25 00:00:00 +0900", "snippet": "DataFrame 와 Numpy array 헷갈리는 점import pandas as pdimport numpy as npN = np.random.randn(3, 3) # 행과 열이 3개 =&amp;gt; 인덱스는 0, 1, 2D = pd.DataFrame(N)print(&#39;D is \\n &#39;, D)print(&#39;N is \\n&#39; ,N)print(&quot; &quot;)print(&#39;D [0:2] 슬라이싱 \\n&#39;, D.iloc[0:2]) # dataframe은 iloc을 , numpy array는 그냥print(&#39;N [0:2] 슬라이싱 \\n&#39;, N[0:2]) #dataframe 이든 numpy 배열이든 index로 slicing 할 때는 첫번째는 시작점, 두번째는 slicing 개수 이다. print(&quot; &quot;)print(&#39;첫번째 행 인덱스 \\n&#39;, D.iloc[0])print(&quot; &quot;)print(&#39;첫번째 행 인덱스 \\n&#39;, N[0])print(&quot; &quot;)print(&#39;D shape \\n&#39;,D.shape)#인덱스가 0,1,2 일 뿐 shape는 3 x 3print(&#39;N shape \\n&#39;,N.shape) &quot;&quot;&quot;D is 0 1 20 -1.823920 1.167075 -0.0396691 0.885826 0.189862 0.7980642 -0.101932 0.743357 -1.509573N is [[-1.82391985 1.16707517 -0.0396687 ] [ 0.8858258 0.18986165 0.7980638 ] [-0.10193204 0.74335654 -1.50957268]] D [0:2] 슬라이싱 0 1 20 -1.823920 1.167075 -0.0396691 0.885826 0.189862 0.798064N [0:2] 슬라이싱 [[-1.82391985 1.16707517 -0.0396687 ] [ 0.8858258 0.18986165 0.7980638 ]] 첫번째 행 인덱스 0 -1.8239201 1.1670752 -0.039669Name: 0, dtype: float64 첫번째 행 인덱스 [-1.82391985 1.16707517 -0.0396687 ] D shape (3, 3)N shape (3, 3)&quot;&quot;&quot;" }, { "title": "EM algorithm", "url": "/posts/EM-algorithm/", "categories": "", "tags": "datascience, bayesian, applied statistics in SNU", "date": "2021-08-24 00:00:00 +0900", "snippet": "이 글은 서울대학교 정성규 교수님의 응용통계 강의 EM algorithm 내용을 정리한 것입니다.EM-algorithm주요 개념: optimization / missingness / parameter estimation결측치가 존재하면 likelihood가 매우 복잡해지는데 EM 알고리즘은 이 경우에 문제를 단순화 시켜 모수 추정을 돕는다 .E-step(expectation) &amp;amp; M-step(maximization)※ E-step :파라미터 값을 알고 있다면 결측치를 쉽게 채워넣을 수 있을 것이다. 파라미터값을 모른다면 현재까지의 얻어낸 파라미터 추정량을 사용해서 log-likelihood의 기댓값을 찾기 위한 함수를 만들어 낸다.(이 기댓값으로 결측치를 대신한다) (결측치가 변수인 경우 그 분포를 찾아내어 기댓값으로 결측치를 대체할 수 있다)(어찌되었든 결측치를 찾아내는 것이 핵심!!!)나중에 내용이 나오겠지만 Q function을 찾아내서 이를 최대화 하는데 기댓값 안에 들어가는 함수가 가능도 함수이기에 모수에 대한 가능도함수 혹은 데이터들의 결합분포 두가지 측면에서 모두 사용가능하다.※ M-stpe :모든 데이터를 가지고 있다면 MLE 를 구하기 쉬울 것이다. 그렇지 않은 경우 E-step에서 찾은 log-likelihood의 기댓값을 최대하하는 parameter값으로 추정한다.아래는 EM 알고리즘 기본 유제를 풀이한 것이다.(이는 GMM(Gaussian Mixture Model 의 학습과 관련이 있다는 것을 알게 되었다!)Formal EM algorithm※ E-step :compute ‘Q-function’\\[\\begin{align} Q(\\theta | \\theta^{(t)}) = E\\{logL(\\theta | Y_{obs},Y_{mis})|y_{obs},\\theta^{(t)}\\} \\\\ = E\\{logf(Y_{obs},Y_{mis} | \\theta)|y_{obs},\\theta^{(t)}\\}\\end{align}\\]※ M-step : Maximize Q - function\\[\\theta^{(t+1)} = argmax_\\theta Q(\\theta | \\theta^{(t)})\\]아래 문제는 포아송 mixture 모델에 대한 EM 알고리즘 문제이다.풀이를 하면서 잊지 말아야할 것은 E - step에서는 결측치를 기존 모수들을 가지고 업데이트 해준다는 것이다.또한 결측치를 업데이트 할 때, 아래첨자 i 는 고려하지 않는데 이는 업데이트할 모수들이 모두 j와 관계있는 변수이기 때문이다.The nature of EM Ascent property쉽게 생각해보자. EM알고리즘은 로그가능도의 값을 최대화 하는값이므로 Q - function을 계속 높이려고 할 것이다.\\[- H(\\theta | \\theta^{(t)}) = log f(y_{obs};\\theta) - Q(\\theta | \\theta^{(t)})\\]이 값은\\[\\theta = \\theta^{(t)}\\]일 때 최소가 된다.ascent property을 증명하는 또 다른 수식이 있는데 여기서는 surrogate function 인 G - function 을 찾아내어 이를 최대화 하는 것이 EM 알고리즘과 같은 것임을 보이고 있다. Convergence order\\[\\epsilon^{(t)} = x^{(t)} - x^*\\]일 때,\\[lim_{t \\rightarrow \\infty} \\epsilon^{(t)} = 0 \\ \\ \\&amp;amp; \\ \\ lim_{t \\rightarrow \\infty} \\frac {|\\epsilon^{(t+1)} |}{|\\epsilon^{t} |^\\beta} = c \\\\ where \\ \\ c \\neq 0 \\ \\ \\&amp;amp; \\ \\beta&amp;gt;0\\]를 만족하는 beta 값을 order of convergence라고 한다.이 값이 클수록 수렴속도는 빠르나 robustness를 희생해야 한다. 뉴턴법이나 할선법(secant method)가 수렴 속도가 빠르다. the EM mapping\\[mapping \\ \\ \\ \\Psi : \\Theta \\rightarrow \\Theta\\]에 대해\\[\\theta^{(t+1)} = \\Psi(\\theta^{(t)})\\]을 EM mapping 이라 하자. 프사이의 값은 데이터와 문제에 의해 항상 바뀐다.만약 EM 알고리즘이 수렴한다고 가정하면,\\[\\hat \\theta = \\Psi(\\hat \\theta)\\]이고 Taylor’s expansion은\\[\\Psi( \\hat\\theta) \\approx \\Psi( \\theta^{(t)}) + \\Psi&#39;( \\theta^{(t)})(\\hat \\theta - \\theta^{(t)})\\]이고 알고리즘의 수렴성에 의해서\\[\\hat \\theta = \\Psi( \\hat\\theta) \\ \\ \\&amp;amp; \\ \\ \\theta^{(t+1)} = \\Psi( \\theta^{(t)})\\]\\[\\frac {|\\hat \\theta - \\theta^{(t+1)}|}{|\\hat \\theta - \\theta^{(t)}|} \\ \\approx \\Psi&#39;(\\theta^{(t)})\\]이 때 t 가 무한대로 갈 때 우변의 값이 C로 수렴하고, C 값이 작을 수록 수렴 속도가 빠르다." }, { "title": "robust regression", "url": "/posts/robust-regression/", "categories": "", "tags": "datascience, robust statistics", "date": "2021-08-23 00:00:00 +0900", "snippet": "Anomaly detection by robust statistics 논문을 읽던 중 1학기 응용통계 시간에 배웠던 breakdown value와 influence fucntion에 대한 개념이 헷갈려 이와 관련된 내용을 다시 한번 정리해보았다.아래 정리한 내용은 모두 서울대학교 통계학과 정성규 교수님의 ‘응용통계 1’ 수업에서 기반한 것이다.Robust regressionsensitivityHow sensitive is the estimator when F varies?민감도이기 때문에 도함수와도 연관되어 있다.우선 influence function을 정의하기 위해서는 statistical functional 의 개념을 이해해야 한다.statistical functional이란 함수들의 함수를 의미한다. 즉 family of distribution을\\[\\mathbb{F} = \\{F_\\theta : \\theta \\in \\Theta\\}\\]라고 정의할 때,\\[\\eta = T(F)\\]를 statistical functional이라 한다.이에 대한 예로※ mean\\[T(F) = \\int x dF(x)\\]를 생각하면 statistical functional 에 대한 이해가 좀 더 쉬울 것이다.이때\\[\\hat{T(F)} \\approx T(F)\\]라고 가정하고 F가 변화할 때 추정량이 많이 바뀌지 않는다면 파라미터값이 robust 한 성질을 가지고 있지 않을까 생각할 수 있다.문제는 F가 함수라는것에 있다. 만약 F가 실수라면 그 점에서의 미분값을 생각하면 변화율을 알 수 있을 것이다. 그러나 F가 함수라면 F가 바뀔 때 T(F)의 변화율은 어떻게 구할 수 있을까?이를 위해 Cateaux differentiable이라는 개념이 등장한다.functional T 가 F에서 Gateaux differentiable 하다는 것은\\[\\exists \\ a(X) ( a : X \\rightarrow \\mathbb{R})\\ \\ such \\ that\\ \\ G \\in \\mathbb{F}\\]에 대해서\\[lim_{\\epsilon \\rightarrow 0} \\frac{T(F + \\epsilon(G-F)) - T(F)}{\\epsilon} = lim_{\\epsilon \\rightarrow 0} \\frac{T((1-\\epsilon)F + \\epsilon G) - T(F)}{\\epsilon} = \\int a(x)dG(x) = T_a(G)\\]으로 정의된다.T(G)의 값을 Gateaux derivative 라고 하고 a(x)의 값을 gradient라고 하면 Gateaux derivative는 방향도함수와 같다.(아래 사진에서 GAteaux derivative가 방향도함수와 같은지 알 수 있습니다. 방향도함수는 gradient와 방향벡터 v 와의 내적으로 구성되는데 내적은 결국 원소들의 곱에 대한 합과 동일하기 때문에 Gateaux derivative에서 a(x)는 gradient와 동일하다.)이제 influential function을 정의하기 위해 필요한 마지막 notation들을 정의한다\\[\\delta_x(u) = \\begin{cases} 0\\ \\ if \\ \\ u&amp;lt;x \\\\ 1 \\ \\ if \\ \\ u&amp;gt;x\\end{cases}\\]여기서 델타는 point mass\\[F_{x \\cdot \\epsilon} = (1 - \\epsilon)F + \\epsilon \\delta_x\\]이를 ‘perturbed F at X with fraction epsilon’influence function 정의CDF F에 대해 functional T가 존재하고 이때\\[IF(x ; T,F) = lim_{\\epsilon \\rightarrow 0} \\frac {T(F_{x \\cdot \\epsilon}) - T(F)}{\\epsilon}\\]을 influence function이라 정의한다.이때 fluence function은 T에 대한 measure이다 만약 T가 Gateaux differentiable이면 $\\exists \\ \\ a(x) \\ \\ s.t. \\ \\ IF(x;T,F) = \\int a(u)d\\delta_x(u) = a(x)$ 이므로 결국 influence function은 gradient a(x)와 동일. gross error sensitivity\\[r^*(T,F) = sup_x |IF(x;T,F)|\\] 만약 $r^*(T,F) &amp;lt; \\infty$ 가 성립하면 functional T는 F에 대해 B-robutst 하다고 말한다. 3에서 언급한 gross error sensitivity 를 고려할 때 population breakdown point를 다음과 같이 정의한다\\[\\epsilon^* = inf\\{\\epsilon : b(\\epsilon) = \\infty\\} \\\\ where \\ \\ b(\\epsilon) =sup_x|T(F) - T(F_{x \\cdot \\epsilon})|\\] resistencyHow many gross outliers to make the estimator garbage? ( ※ gross outlier? 특정 값이 무한대로 매우 큰 값)breakdown point 정의파라미터 추정량 $T_n = T_n(x_1, x_2, … , x_n)$ 에 대해 이 추정량에 대한 breakdown point를“the largest fraction of gross outliers before T_n becomes arbitarily large” 라고 정의한다.이 정의에 따르면 평균의 경우, 평균을 이루는 원소 중에서 단 하나의 값만이라도 매우 커진다면 통계량이 크게 변화하기 때문에 breakdown point = 0 이라고 할 수 있다. 상대적으로 median의 경우는 breakdown point 가 크고 breakdown point 가 클수록 resistance가 크다고 말할 수 있다.수식으로 breakdown point를 정의해보자.\\[let \\ \\ R_m(T_n ; x_1,...x_n) = Max_{i_1},...,{i_m} \\{Sup_{y_1},...,{y_m} |T_n(z_1,...,z_n)\\}\\\\where \\ \\ Z_j = \\begin{cases} x_j &amp;amp; if \\ \\ j \\notin \\{i_k\\}_{k=1} ^ m \\\\ y_k &amp;amp; if \\ \\ j = i_k \\ for \\ some \\ k=1,2,...,m \\end{cases}\\]즉 x 중에서 임의로 m 개를 골라서 매우 큰 y로 바꾸었을 때의 값이 R_m 이 되는 것이다.이 때 breakdown pointf를 입실론이라 하면\\[\\epsilon_n^* = \\frac{1}{n} Max\\{m;R_m(T_n;x_1,...,x_n) &amp;lt; \\infty\\}\\]" }, { "title": "python code", "url": "/posts/python_code/", "categories": "", "tags": "datascience, machinelearning, python, coding", "date": "2021-08-13 00:00:00 +0900", "snippet": "한동안 구글에서 열어준 머신러닝 부트캠프에 참가해서 딥러닝을 공부하던 중이었는데 간단한 코드를 통해 조건에 맞게 리스트 인자를 변형시키는 코드를 알게 되어 만드는 글이다A = [[0.4,0.7]][[_ &amp;gt; 0.5 for _ in __] for __ in A]# Out[16]: [[False, True]]A= np.array(([0.4,0.7])np.where(A&amp;gt;0.5, True, False) #np.where은 numpy.ndarray 에서 사용됨.#Out[18]: array([False, True])또한 삼차원 행렬 같은 경우에도 reshape를 통해서 이차원으로 축소가 가능한데 코드는 다음과 같다.A = np.array([[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]]) # 3차원 배열A.shape #Out[31]: (3, 3, 3) # 삼차원 배열 하나B = np.array([[[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]],[[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]],[[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]],[[1,1,1],[2,2,2],[3,3,3]]]]) # 3차원 배열B.shape #Out[34]: (3, 3, 3, 3) # 삼차원 배열 3개B = B.reshape(B.shape[0],-1)B.shape #Out[37]: (3, 27) # 3차원 배열을 2차원으로 축소시키기" }, { "title": "ISLR - LAB9", "url": "/posts/ISLR9-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-13 00:00:00 +0900", "snippet": "9장 코드 정리## support vector classifier#kernel 값을 linear로 주면 svm() 함수에서 support vector classifier를 실행할 수 있다.set.seed(1)x = matrix(rnorm(20*2), ncol=2)y = c(rep(-1,10), rep(1,10))fix(x)x[y==1,] = x[y==1,] + 1 #y==1 에 해당하는 부분, 즉 x 데이터 중에서 11행 부터 20행까지의 수에 1을 모두 더해주어라.plot(x, col=(3-y))#svm이 작동되기 위해서는 y 변수를 as.factor를 통해서 범주형 변수로 만들어 주어야 한다.dat= data.frame(x=x, y=as.factor(y))datlibrary(e1071)svmfit = svm(y~., data = dat, kernel =&#39;linear&#39;, cost =1000, scale = FALSE) #cost 값이 작으면 margin 값이 더욱 넓어진다.plot(svmfit, dat)svmfit$indexsummary(svmfit)#library e1071에 있는 tune 함수를 통해 CV를 할 수 있다. cost가 작으면 margin이 넓어진다.set.seed(1)tune.out = tune(svm, y~., data=dat, kernel = &quot;linear&quot;, ranges = list(cost = c(0.001,0.01,0.1,1.5,10,100)))summary(tune.out)#tune 함수는 best model을 저장한다bestmod = tune.out$best.modelsummary(bestmod)#predictxtest = matrix(rnorm(20*2), ncol=2)ytest = sample(c(-1,1),20, rep=TRUE)xtest[ytest==1, ] = xtest[ytest==1,] + 1testdat = data.frame(x=xtest, y =as.factor(ytest))testdatypred = predict(bestmod,xtest)table(predict = ypred, truth=testdat$y)## support vector machineset.seed(1)x = matrix(rnorm(200*2), ncol=2)x[1:100,] = x[1:100,] + 2x[101:150,] = x[101:150,] -2y = c(rep(1,150),rep(2,50))dat = data.frame(x=x,y=as.factor(y))plot(x,col=y) # boundary is non-lineartrain = sample(200,100)svmfit = svm(y ~ .,data = dat[train,], kernel=&#39;radial&#39;, gamma =1, cost=1)plot(svmfit, dat[train,])#cost 값을 키우면 training error를 줄일 수 있긴 하지만 overfitting의 위험 존재. ==&amp;gt; CV를 통해 최적값 구하기set.seed(1)tune.out = tune(svm, y~., data= dat[train,], kernel=&#39;radial&#39;, ranges=list(cost = c(0.1,1,10,1000), gamma = c(0.5,1,2,3,4)))summary(tune.out)#예측해보기table(true=dat[-train,&quot;y&quot;],pred=predict(tune.out$best.model,newx=dat[-train,]))## ROC curve ( TP rate / FP rate )library(ROCR)rocplot = function(pred, truth,...) { predob = prediction(as.numeric(pred), as.numeric(truth)) perf = performance(predob, &quot;tpr&quot;,&#39;fpr&#39;) plot(perf,...)}svmfit.opt = svm(y~., data = dat[train,], kernel=&#39;radial&#39;, gamma=2, cost=1, decision.values=T)fitted = predict(svmfit.opt, data= dat[train,], decision.values=T) #decision.values=T를 줌으로써 확률값이 아닌 예측 class 가 나옴rocplot(fitted, dat[train,&#39;y&#39;], main = &#39;training data&#39;)#gamma를 조절해서 boundary를 flexible 하게 만들 수 있다.#gamma 값이 커진다는 것은 커널 function K 가 커지는데 특히 gamma에 의해서 K 가 커지면 본래 support vector와의 거리가 작았음에도 그 거리를 확대시키고, 음의 부호에 의해 커널 자체의 값을 작게 만들어 버린다. 즉 모델 자체가 매우 flexible 해진다는 것이다.svmfit.flex = svm(y~., data = dat[train,], kernel=&#39;radial&#39;, gamma=50, cost=1, decision.values=T)fitted = predict(svmfit.flex, data= dat[train,], decision.values=T) #decision.values=T를 줌으로써 확률값이 아닌 예측 class 가 나옴rocplot(fitted, dat[train,&#39;y&#39;], add=T, col=&#39;red&#39;)# plot에서도 볼 수 있듯, FPR이 낮을때에도(1종 오류 / 전체 오류 가 낮을 때에도) TPR이 높다. 즉 specifity를 유지하면서 sensitivity를 높였다. # 즉 training data에 대한 accuracy를 높인것.(과적합의 위험)#test data에 모델이 얼마나 잘 작동하는지 보기 위해fitted = predict(svmfit.opt, data= dat[-train,], decision.values=T) #decision.values=T를 줌으로써 확률값이 아닌 예측 class 가 나옴rocplot(fitted, dat[-train,&#39;y&#39;], main = &#39;test data&#39;)fitted = predict(svmfit.flex, data= dat[-train,], decision.values=T) #decision.values=T를 줌으로써 확률값이 아닌 예측 class 가 나옴rocplot(fitted, dat[-train,&#39;y&#39;],add=T, col=&#39;red&#39;)## SVM with multiple case(Response class 가 여러개 일 때)set.seed(1)x=rbind(x, matrix(rnorm(50*2), ncol=2)) #행 결합y = c(y, rep(0,50))dat = data.frame(x=x, y=as.factor(y))plot(x, col=(y+1))svmfit = svm(y~., data=dat, kernel = &#39;radial&#39;, cost=10, gamma=1)plot(svmfit, dat) " }, { "title": "ISLR - LAB10", "url": "/posts/ISLR10-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-13 00:00:00 +0900", "snippet": "10장 코드 정리## Principal Components Analysis#row namestates= row.names(USArrests)states#columns namenames(USArrests)apply(USArrests, 2, mean) #여기서 두번째 인자는 1일 때 행, 2일 때 열 &quot;&quot;&quot; Murder Assault UrbanPop Rape 7.788 170.760 65.540 21.232 &quot;&quot;&quot;pr.out = prcomp(USArrests, scale=TRUE) #sclae = T 를 통해서 PCA 이전에 정규화를 해줌pr.out$center #PCA 이전의 평균과 표준편차가 제시된다.pr.out$scalepr.out$x # 각 데이터의 pc score 값이 나온다pr.out$rotation #loading 값을 제공.&quot;&quot;&quot; PC1 PC2 PC3 PC4Murder -0.5358995 0.4181809 -0.3412327 0.64922780Assault -0.5831836 0.1879856 -0.2681484 -0.74340748UrbanPop -0.2781909 -0.8728062 -0.3780158 0.13387773Rape -0.5434321 -0.1673186 0.8177779 0.08902432&quot;&quot;&quot;# 두개의 PC 값으로 biplot 그리기biplot(pr.out, sclae=0) #sclae=0를 주면 화살표가 loading 을 나타냄pr.out$sdev #loading의 표준편차pr.var = pr.out$sdev^2pve = pr.var / sum(pr.var)pve # 0.62006039 0.24744129 0.08914080 0.04335752#의미는 첫번째 PC가 전체 분산의 62%를 설명plot(pve, xlab = &quot;PC&quot;, ylab = &#39;proportion of variance&#39;, ylim=c(0,1), type=&#39;b&#39;)plot(cumsum(pve), xlab=&#39;PC&#39;, ylab=&#39;culmulative proportion of variance&#39;, ylim=c(0,1), type=&#39;b&#39;)#이렇게 일일이 하지 않더라도 summary를 통해 수치로 체크하고 plot함수를 바로 쓸 수 있다.summary(pr.out)plot(pr.out) #pc 들의 분산 비율을 알 수 있게 해줌## Clusteringset.seed(2) #nstart에서 random 값을 주기 때문에 seed 값을 고정해야 reproducible 하다.x= matrix(rnorm(50*2), ncol=2)x[1:25,1] = x[1:25,1] +3x[1:25,2] = x[1:25,2] -4km.out = kmeans(x, 2,nstart=20) #K=2, nstart 값은 1보다 크면 처음 임의로 cluster를 random으로 할당km.out$cluster #50개의 데이터셋에 대해 어떻게 클러스터 되었는지 나온다km.out$tot.withinss # within cluster sum of squre : K-means clustering 에서 줄이고자 하는 것.plot(x, col=(km.out$cluster+1), main=&quot;k-means with k=2&quot;,pch=20, cex=2)## Hierarchical Clusteringx=scale(x) # 표준화 해주기.hc.complete = hclust(dist(x), method = &#39;complete&#39;) # dist() 함수는 matrix 원소간 거리를 잰다.hc.average = hclust(dist(x), method = &#39;average&#39;)hc.single = hclust(dist(x), method = &#39;single&#39;)plot(hc.average, main=&quot;complete linkage&quot;, cex= 0.9)cutree(hc.average,2) #cluster label을 제시하는데 몇개로 컷 할건지지#dissimilarity 의 또다른 측도인 correlation - based distanceX = matrix(rnorm(30*3), ncol=3)dd = as.dist(1-cor(t(x)))plot(hclust(dd, method=&#39;complete&#39;))## clustering은 PCA 이후에 할 수도 있다. 오히려 이게 결과가 더 좋을 때도 있다. #즉 PCA는 noise를 제거하는 단계 처럼hc.out = hclust(dist(pr.out$x[,1:3]), method=&#39;complete&#39;)plot(hc.out)" }, { "title": "ISLR chap 10", "url": "/posts/ISLR10/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-10 00:00:00 +0900", "snippet": "10. Unsupervised Learningsupervised learning : X를 가지고 Y를 예측하는 것unsupervised learning : X 데이터만을 가지고 어떠한 특성을 밝히는 것. visualize… subgroups…대표적인 비지도학습 : PCA : visualization, pre-processing / clustering : subgroup10.1 The Challenge of Unsupervised Learning앞서 지도학습에서는 분류 혹은 회귀 라는 분석 목적이 뚜렷했으며, 지도학습 분석의 성능에 대해 평가하는 기준이 명확했다(e.g CV).그러나 비 지도학습의 경우에는 분석의 목적이 다소 주관적이며 exploratory data analysis(EDA) 의 성격을 가지고 있다. 또한 분석의 결과가 얼마나 신뢰할 수 있고 바람직한지를 평가하는 기준이 없다.(Y 관측치가 존재하지 않는다!!)그럼에도 불구하고 비지도학습의 중요성은 점점 커져간다. 이는 데이터 자제의 숨겨진 속성들을 추출해냄으로서 더 많은 부가가치를 창출할 수 있기 때문이다.10.2 Principal Components AnalysisISLR 6.3.1 부분의 PCR 을 참고하자10.2.1 What Are Principal Componentsfeature의 개수가 많다면, 정보의 관계를 한눈에 파악하기 힘들다. 대신 이러한 정보들을 추출해서 2차원 데이터로 만들어 시각화 한다면 훨씬 이해하기 편하다. ==&amp;gt; PCApca는 관심 정보들을 작은 차원에서 설명하려는 노력. 축소된 차원은 본래의 p 개의 feature들에 대한 조합first PC of normalized data 는 다음과 같이 조합된다.\\[Z_1 = \\phi _{11}X_1 + \\phi_{21}X_2 + ... + \\phi_{p1}X_p\\]여기서 phi 값은 방향을 의미하고 Z_1이 first PC라면 phi는 가장 분산이 큰 방향을 의미하게 될 것. 그리고 Z 값은 score 값으로 phi에 의해 정해진 방향에 X를 사영시켰을 때 나오는 projected value이다.(pc loading phi 의 제곱합은 1 : 이런 제약 조건이 없다면 분산을 가장 크게 만든다는 데이터의 조합에 대한 기준이 없어짐.)pc loading 을 찾는 공식은 아래와 같다\\[max_{\\phi_{11},..., \\phi_{p1}} \\frac {1}{n} \\{\\ \\sum_i^n(\\sum_j^p \\phi_{j1}x_{ij})^2\\} \\ \\ subject \\ \\ to \\ \\ \\sum \\phi^2_{j1} = 1\\]위 공식을 처음보면 어떻게 나온 것인지 헷갈릴 수 있다. i는 obs, j 는 feature를 의미하며, 데이터가 표준화되어있다는 전제하에 $\\sum i x{ij} = 0$이므로 maximization 하고자 하는 값은 결국 분산을 의미한다. 또한 이렇게 분산을 극대화시키는 pc score를 찾는 것은 결국 데이터의 eigen-value 값을 찾는 것과 동일한데 이 내용은 책에 생략되어있다.두 번째 PC score Z_2 를 찾기 위해서는 분산이 Z_1 다음으로 크게 하면서도 Z_1과는 uncorrelated 되어있는 X들의 linear combination을 찾아야 한다. 이는 loading벡터의 방향이 이전 first PC score의 loading 벡터와 직교하도록 만들면 된다. 즉 PC loading 을 찾기위해 제약조건하에서의 최적화 식에서 추가적으로 직교성을 추가하면 된다.기하학적으로 생각해보자. 주성분을 계산하고 나면 낮은 차원에서 이를 plot 할 수 있는데, PC score 벡터는 본래 데이터(X)를 방향벡터인 phi로 span 된 공간에 사영시킨 것을 의미한다.방향벡터 \\(\\phi\\)들은 \\(X&#39;X\\)의 eigenvector가 되고(X’X는 표준화된 X에 대한 분산행렬이다) PC score의 분산값은 eigen value가 된다기하학적 내용에 대해 수식으로 접근해보면단위벡터 e에 의해 span 된 공간에 X 데이터를 사영하는 것은\\(Xe\\)이고 이것의 분산이 최대가 되도록 사영하는 것을 목적으로 하기 때문에\\(Max_e \\ \\ [Var(Xe)] \\ \\ subject \\ \\ to \\ \\ \\sum e_i^2 = 1\\)를 풀면\\(\\Sigma e = \\lambda e\\)를 만족할 때 위 식을 최대로 만들 수 있다. 여기서 lambda는 고유값이고 e는 고유 벡터가 된다. 즉 데이터의 분산을 최대로 하는 방향벡터는 X의 분산에 대한 고유벡터이고, PC score의 값은 고유값 lambda가 된다\\[Var(\\Sigma e) = e&#39;\\Sigma e \\ = e&#39; \\lambda\\ e = \\lambda\\]PCA는 요인분석과도 연관이 깊은데 이에 대한 내용이 살짝 언급되어 있다.아래 표를 보자pc1의 loading vector를 보면 Murder, Assault, Rape 의 비율이 높다. 즉 pc1은 중범죄율이라는 새로운 변수로 해석할 수 있다. 반대로 pc2를 보면 UrbanPop의 비율이 높다. 즉 pc2는 도시화율이라는 변수로 해석될 수 있다. 즉 pc1의 score 값이 높은 obs의 경우 높은 범죄율을 가지는 데이터라 말할 수 있다. 만약 어떤 obs가 각 score의 값이 0 인 경우는 범죄율이나 도시화에 대해서 그냥 평균정도의 상황임을 드러내는 것이라 할 수 있다.10.2.2 Another Interpretation of Principal ComponentsPrincipal component의 또 다른 해석은 바로 관측치와 가장 가까운 low dimensional linear surface를 제공한다는 것이다. first pc loading vector는 p 차원의 데이터에서 이들과 가장 가까운 line을 의미한다. 여기서 더 나아가 first two pc loading vector는 데이터와 가장 거리가 가까운 평면을 만들어 낸다.즉 차원이 매우 클 때, M개의 pc score 값 혹은 pc loading vector 들이 원 데이터를 잘 설명하는 근사치가 될 수 있다.\\[x_{ij} \\approx \\sum ^M z_{im}\\phi_{jm}\\]또한, $M = min(n-1,p)$이면 정확히\\[x_{ij} = \\sum ^M z_{im}\\phi_{jm}\\]가 성립한다.10.2.3 More on PCA(1) 분산을 기준으로 데이터를 축소하기 때문에 측정 단위가 동일해야 한다. =&amp;gt; 표준화가 꼭 필요하다.(2) prinicpal component loading vector는 유일하다. 즉 단위가 바뀌거나 flip되어도 벡터는 동일하다. 또한 score vector 또한 유일하다. 이는 z에 대한 분산이나, -z 에 대한 분산이 동일한 것과 같은 이치이다.(3) Principal component 중 몇개를 뽑는 것으로 전체 데이터를 축약한다면 데이터의 소실량은 얼마인가? 분산의 비로 나타내보자.==&amp;gt; proportion of variance explained(PVE) of the m-th principal component\\[\\frac {\\sum^n(\\sum^p \\phi_{jm} x_{ij})^2}{\\sum^p(\\sum^n x_{ij^2})}\\](4) 그럼 principal component를 몇개 골라야 할까?전체데이터를 잘 설명하는 축소된 변수가 작으면 작을수록 좋을 것이다.scree plot을 가지고 볼 때 분산 비율이 크게 감소하지 않는 지점 직전까지로 principal component의 개수를 정하면 좋을 것이다. 그러나 이는 각 데이터마다 어떻게 할지 모두 다르므로, 각 principal components 마다 어떠 패턴이 존재하는지 확인해보면 좋을 것이다. 만약 PC regression(지도학습) 을 하는 경우라면 CV 값이 제일 작은 principal component개수를 설정하면 될 것이다.10.2.4 Other Uses for Principal Components차원 축소를 통해서 regression, classification, clustering에 모두 사용될 수 있다. 차원 축소가 잘 된다면 데이터의 nosie를 줄여 보다 올바른 결과가 나올 수도 있다.10.3 Clustering Methods군집화를 할 때는 무엇이 같고 무엇이 다른 것인지에 대한 기준이 필요하다. 이는 domain 지식을 요구할 수도 있다. pca와 clustering은 데이터를 단순화 시킨다는 데서 공통점이 있지만, pca는 feature의 dimension을 줄이려는 시도이고, clustering은 obs안에서 subgroup을 찾으려는 시도라는 데서 차이점이 존재한다.그런데 clustering 과정에서 X matrix를 transpose한다고 하면 obs를 기반으로 해서 feature를 나누는 시도 또한 가능하다. 이는 새롭게 배우는 idea인데 충분히 생각해볼 필요가 있다.10.3.1 K-Means Clustering바람직한 K를 clustering 이전에 미리 정해야한다. 또한 각 clusteing은 서로 겹치지 않아야 하며 그 합이 전체 데이터 set을 만들어야 한다K-Means의 아이디어는 무엇인가? 우선 각 cluster 내부의 데이터들은 작은 분산을 가질 것이라는 것이다. 각 cluster의 within-variance를 W라고 하면 clustering의 문제는 아래의 식을 푸는 것과 동일하게 된다.\\[minimize _{ C_1, C_2,...,C_k} \\{\\ \\sum^K W(C_k)\\}\\]W를 정의하는 방법은 여러가지가 있지만 책에서는 pairwise squared Euclidean distance의 총합을 cluster의 원소 개수로 나누는 것을 제시한다\\[W(C_k) = \\frac { 1} {|W_k|}\\sum_{i,i&#39; \\in C_k} \\sum _j ^ K (x_{ij} - x_{i&#39;j})^2\\]그런데 이런 방식은 계산량이 매우 많다. K^n 만큼의 경우가 존재.따라서 local optimum을 찾는 방식의 알고리즘이 존재한다.알고리즘에서는 K-Means 라는 명칭에 걸맞게 평균을 사용해서 clustering을 하는데 이것이 가능한 이유는 아래와 같다. 앞서 말했던 within-variance를 최소화 하는 식은 다음 식과 동일하다\\[\\frac { 1} {|W_k|}\\sum_{i,i&#39; \\in C_k} \\sum _j ^ K (x_{ij} - x_{i&#39;j})^2 = 2\\sum_{i\\in C_k}\\sum_{j=1}^K(x_{ij} - \\bar x_{kj})^2\\]즉 분산을 최소화하는 값이 바로 clustering 내부의 평균값과의 차이 합인 것이다.그러나 여전히 이러한 방법은 global opitmum이 아닌 local optimum이므로 초기값을 다양하게 설정함으로써 clustering이 보다 잘 되게 할 수 있다. 알고리즘의 결과치를 비교할 때에는 within-variance의 총합을 최소로 하는 clustering을 찾는다.아래는 알고리즘을 그림으로 표현한 것이다10.3.2 Hierarchical ClusteringK-Means와는 달리 K 값을 미리 정하지 않아도 된다. 결과값으로 tree-based representation을 준다. 이를 dendrogram이라고 한다.핵심용어는 bottom - up, agglomerative clustering, upside-down treeInterpreting a Dendrogramdendrogram에서 관측지들이 유사할수록 더 빨리(dengrogram의 아랫부분) 결합될 것이다.또한 dendrogram은 vertical axis를 기준으로 유사성을 판단하게 되는데, 서로 다른 brach이면 그 값들이 horizontal 하게 떨어져있을 때는 유사성이 차이가 없다. 아래 그림을 참조그럼 clustering을 어떻게 할 것인가? horizontal cut을 사용. horizontal cut을 어떻게 하는가에 따라 cluster K 값이 달라진다. 아래 그림의 점선이 horizontal cut을 나타내고, 그에 따른 clustering을 보여준다.heirarchical의 의미는 cutting에 의한 cluster들이 다른 cluster 에 nested 되어 있다는 것이다. 그러나 모든 데이터에서 이런 계층적 구조가 발생하는 것은 아니다. 예를들어 남 / 녀, 한/ 중/ 일 데이터를 성별, 그리고 국적으로 clustering 할 수 있겠지만 어떤 cluster가 다른 cluster 안에 계층적으로 포함되지는 않는다.The Hierarchical Clustering Algorithm알고리즘은 다소 단순하다. 관측치가 n개 있을 때, 유클리디안 거리를 기준으로 dendrogram의 제일 하단 부분에서 가장 유사한 두 관측치를 결합해서 n-1개의 cluster를 만든다. 마찬가지 방식으로 n-2, n-3, … 으로 cluster의 개수를 줄여나가고 dendrogram의 제일 윗 부분에서는 하나의 cluster만이 남는다.이제 또 다른 문제를 살펴보자. 관측치들의 여러개 들어있는 그룹들의 거리는 어떻게 측정할 수 있을까? 이를 위해 linkage 라는 개념이 등장한다. 그 종류로는 Complete, Single, Average, Centroid가 있고 각 likage 마다 dissimilarity를 측정하는 다른 기준이 있다. 일반적으로 complete이나 average linkage는 single linkage 에 비해 훨씬 균형적이다. 또한 Centroid linkage는 inversion의 위험이 있다.hierarchical 알고리즘과 linkage에 대한 내용이 책에 나온다.Choice of Dissimilarity Measure지금까지는 유클리디안 거리를 기준으로 dissimilarity를 체크했는데 다른 방식의 측도에 대해서 알아보자.correlation-based distance는 두 obs 간의 상관성을 비교하는 것으로 유클리디안 거리가 크기를 가지고 비교했다면, correlation-based distance는 관측치 profile의 모양을 가지고 dissimilarity를 판단하는 것이다. 어떠한 기준을 선택하는지는 데이터의 형태 혹은 분석의 목적에 따라 달라진다. 예를들어 마케팅 팀에서 소비자들을 대상으로 군집분석을 하는데, 구매 패턴이 비슷한 소비자를 같은 그룹으로 할지, 아니면 소비액이 유사한 소비자를 같은 그룹으로 할지 차이가 있는 것이다.또한 변수를 표준화하는 것에 따라 dissimilarity가 달라질 수 있으므로 이데 대해서도 고려해야한다(K-means 도 마찬가지)10.3.3 Practical Issues in Clusteringclustering 과정에서 고려해야할 부분이 몇가지 있다.(1) Small Decisions with Big Consequences obs 혹은 feature가 standardize 되어야 한다. 왜? 분산으로 clustering을 하기 때문에 hierarchical clustering 의 경우 - dissimilarity measure / linkage / where to cut the dendrogram K-Means cluster에서 K의 값은?(2) Validating the Cluster Obtainedclustering이 제대로 된 것일까? 아님 noise 때문에 우연히 cluster 된 것일까? 이를 평가하는 기준은?p - vlaue로 cluster가 우연에 의한 것인지 아닌지를 평가하는 방법이 있긴한데 이 또한 학자들이 모두 인정한 그런 방식은 아니다.(3) Other Considerations in Clusteringclustering 은 데이터의 작은 변동에도 크게 바뀐다( robust X)대다수의 obs가 몇개의 소그룹에 속해있는 경우, 그리고 그 소그룹들이 서로 매우 다른 경우 ==&amp;gt; clustering에 왜곡이 일어날 수 있다. clustering 은 특정 그룹에 데이터를 강제로 분류하기 때문에. 이를 막기위해 mixture model을 사용한 soft K-means 가 등장(4)clustering을 하는 여러가지 방법을 배웠는데(standardize, linkage,…) 이들을 모두 사용해서 반복적으로 나타나는 패턴이 있는지 파악하는 것이 중요. non - robust한 성질을 가지고 있기 때문에, clustering을 절대적인 분류로 생각하지 말고, 연구를 하는데 어느정도의 도움을 얻고 또 출발점이 되는 그런 정도의 용도로 사용하는게 좋다." }, { "title": "ISLR chap 9", "url": "/posts/ISLR9/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-09 00:00:00 +0900", "snippet": "9. Support Vector Machines사람들은 흔히 the maximal margin classifier, the support vector classifier, the support vector machine을 통틀어서 support vector machine이라 부른다.SVM은 ‘out of the box’ classifier인데 특수한, 제한된 경우에서만 쓰이는 모형에서 더 일반적인 모형 순으로 나열할 때maximal margin classifier =&amp;gt; support vector classifier =&amp;gt; support vector machines 순이다. 오른쪽으로 가면서 class가 선형모델로만 구분되는데서 비선형모델로도 구분이 가능한 것으로 발전해왔고, 또한 현재 SVM이 binary class 뿐만 아니라 다양한 class로도 구분되도록 모형이 발전해왔다.9.1 Maximal Margin Classifier9.1.1 What Is a Hyperplane?p-dimensional space에서 hyperplane의 정의는 ‘flat affine subspace of dimension p-1’p-dimension에서 hyperplane에 대한 수식$\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + … + \\beta_pX_p = 0$hyperplane은 p-dimension을 두개로 나눈다9.1.2 Classification Using a Separating Hyperplaneclassification의 방법으로 chap 4에서 logistic, LDA, chap 8에서 trees, bagging and boosting을 배웠다. 이제 새로운 접근법을 배운다. 여기서는 hyperplane을 나누는 방식의 접근을 배울 것이다.separating hyperplane이 존재한다면 이를 활용해서 classifier를 만들수 있다. 예를들어 predictor를 대입한 값이 hyperplane보다 크면 1, 그렇지 않으면 -1을 부여해서 class 분류가 가능. 또한 predictor를 대입한 값 \\(f(X^*)\\)가 크면 이 데이터는 hyperplane에서 멀다는 것이므로 hyperplane에 의한 분류가 보다 확실하다고 말할 수 있다.9.1.3 The Maximal Margin Classifierhyperplane을 통해서 data를 완벽히 분류해낼 수 있다면, 무수히 많은 hyperplane이 존재할 것이다. 그렇다면 이러한 것들 중에서 어떤 hyperplane을 어떻게 선택해야 할까? 합리적인 기준은 무엇일까?하나의 방법으로 제시되는 것은 Maximal Margin Hyperplane 이다. 이는 training observation에서 가장 먼 hyperplane이다.“the hyperplane that has the farthest minimal distance to the training observation”라고 표현되는데 이는 수직거리 중 가장 짧은 거리(Margin, minimal distance)들 중에서 가장 먼 거리를 갖는 hyperplane을 선택하는 것이다. 그러나 여기서도 overfitting의 문제가 나타난다. 특히 변수의 개수가 많아지는 경우 maximal margin classifier 는 오버피팅될 가능성이 높다.maximal margin이므로, hyperplane이 놓일 수 있는 가능한 공간에서 가장 ‘가운데’에 평면이 놓이게 될것이다. 이를 설명하는 것이 아래의 그림이다.그림 아래 설명부분에 보면 support vector라는 것이 나온다. 왜 support vector인가?우선 이들은 p 차원 공간안에 있는 벡터이며, 이 벡터가 아주 살짝만 움직여도 maximal margin hyperplane이 바뀔 수 있기 때문에 maximal margin hyperplane을 ‘support’ 한다고 하여 support vector라고 명명된다.또한 maximal margin hyperplane은 support vector와 같은 일부 데이터에만 의존하기 때문에 hyperplane에서 멀리 떨어진 데이터가 움직이는 것은 hyperplane에 영향을 안준다.9.1.4 Construction of the Maximal Margin ClassifierMaximal margin hyperplane은 optimization의 문제이다. 즉$Maximize_{\\beta_0, \\beta_1,…,\\beta_p } M$$subject \\ \\ to \\sum^p \\beta_j ^2 = 1$$y_i(\\beta_0 + \\beta_1 x_{i1} + … \\beta_{p}x_{ip}) \\geq M$세번째 조건은 분류가 올바르게 되었는지(M은 양수)이며 두번째 조건은 hyperplane의 경우 \\(\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p = 0\\)이므로 평면을 만들때 해당되는 조건은 아니다. 다만, 이 조건으로 인해서 \\(y_i(\\beta_0 + \\beta_1 x_{i1} + ... \\beta_{p}x_{ip})\\)가 margin을 나타내는 수직거리가 되고 이 값이 M 보다 크게 되는 최대의 M 값을 구하는 것은 결국Maximal Margin Hyperplane을 의미하는 것이다.9.1.5 The Non-separable Casehyperplane을 만들 수 없는 경우?soft-margin이라 불리는 class를 ‘‘거의’’ 나누는 hyperplane을 만드는 것이다. 이를 다음 장에서 support vector classifier로 배운다.9.2 Support Vector Classifiers9.2.1 Overview of the Support Vector Classifier(1) hyperplane을 통해 데이터를 완전히 분류할 수 없는 경우 존재(2) 완전히 분류되더라도 오버피팅의 위험이 있거나, 아주 작은 변동에도 모델 자체가 크게 변할 위험 존재==&amp;gt; soft margin을 활용해서 robustness를 달성하며, 소수의 데이터를 제외한 대부분의 데이터에서 더 좋은 성능을 가지도록 만들 수 있다.이러한 방법을 책에서는 support vector classifier 혹은 soft margin classifier 라고 부른다.일부의 데이터에 대한 분류 오류(wrong side of the margin, wrong side of the hyperplane)를 감소하고 서라도 대부분의 데이터에서 훨씬 더 좋은 분류 성능을 가진다면 이러한 모델을 선택하게 될 것.9.2.2 Details of the Support Vector Classifiersupport vector classifier의 식은 아래와 같다.$Maximize_{\\beta_0, \\beta_1,…,\\beta_p,\\epsilon_1,…,\\epsilon_n } M$$subject \\ \\ to \\sum^p \\beta_j ^2 = 1$$y_i(\\beta_0 + \\beta_1 x_{i1} + … \\beta_{p}x_{ip}) \\geq M(1-\\epsilon_i)$$\\epsilon_i \\geq 0 \\ , \\ \\ \\sum \\epsilon_i \\leq C$여기서 epsilon의 값은 slack variable로 관측치가 margin이나 hyperplane 기준 반대 방향에 있도록 허용하는 정도를 나타내는 수치이다. 만약 모든 i 에 대해 epsilon_i 이 0이라면 모든 관측치들이 올바르게 분류되도록 hyperplane을 만들어야 한다. 그러나 epsilon_j 값이 0보다 크다면, j 관측치는 반드시 올바른 분류의 margin의 반대 방향에 위치하게 될 것이다. 나아가 epsilon_k 값이 1보다 크다면 k 관측치는 hyperplane의 반대방향에 위치하게 될 것이다.tuning parameter C의 역할은 epsilon이 용인하는 오류들의 정도와 개수를 결정해준다. C=0이라면 모든 epsilon이 0이라는 의미이므로 이는 9.1에서 배웠던 maximal margin hyperplane과 동일하다. 만일 C&amp;gt;0 이라면 C 값 이상의 점의 개수는 다른 hyperplane에 위치할 수 없다.(왜냐면 epsilon이 1 이상이어야 반대편 평면에 점이 위치하기 때문에)C가 크다는 말은 오류의 용인 범위가 넓다는 말이므로 margin은 넓어진다. Margin이 넓다는 것은 모형이 그만큼 robust하다는 것이고 bias - variance trade-off 관계를 통해서 볼 때, 분산이 작고 bias 가 커질 것이다. 반대로 C가 작아지면 용인 범위가 좁아지는 것으로 margin은 좁아질 것이다. 즉 대부분의 train 데이터가 모두 올바르게 분류되기 때문에 overfitting 의 문제를 피할 수 없다. C는 tuning parameter로 CV값을 통해 결정된다.앞에 maximal margin hyperplane에서와 동일하게 support vector classifier 또한 일부의 데이터들로 인해서 hyperplane이 결정된다. 차이점은 support vector classifier는 일부의 오류 데이터를 용인한다는 것에 있기 때문에 margin에 놓여진 모든 데이터들(참이든 오류든)이 support vector로 여겨진다. 즉 오류데이터 또한 hyperplane 결정에 관여한다는 것이 maximal margin hyperplane과의 차이라 하겠다.이제 C 와 support vector 간의 관계를 보자. C 값이 커진다는 것은 support vector 들이 많아진다는 것이다. 이 말은 곧 hyperplane을 결정하는 데에 많은 데이터가 요구된다는 것이다.logistic , LDA, SV classifiersupport vector classifier는 일부 데이터에 의해 hyperplane이 결정되는데 이는 logistifc regression과 유사하다. logistic regression 또한 boundary에서 먼 일부 데이터들은 boundary 결정에 크게 관여하지 않는다(insensitive).이는 LDA와는 정반대의 학습방법이라 할 수 있다. LDA의 경우는 class에 대한 모든 관측치들의 평균과 분산을 고려해서 분류 기준을 만들기 때문이다.9.3 Support Vector Machinesnon-linear decision boundary?? support vector machines은 비선형의 boundary를 자동으로 만들어낸다.9.3.1 Classification with Non-linear Decisionsupport vector classifier는 선형 boundary를 만들어낸다. 그러나 비선형의 boundary를 사용하고 싶다면?이전 chapter에서 공부했듯, 우리는 quadratic , cubic term을 만들어내어 비선형의 데이터를 모형에 적합시켰다. 즉 support vector classifier의 hyperplane을 만들때 이차 혹은 삼차항이 들어간 식을 사용함으로써, 비선형 boundary를 만들어 낼 수 있다. 식은 아래와 같다.feature term $X_1, X_2, …. , X_p$에서$X_1, X_1^2, X_2, X_2^2, … ,X_p,X_p^2$로 feature space를 확장시켜 최적화를 한다\\[Maximize_{\\beta_0, \\beta_{11}, \\beta_{12},,...,\\beta_{p1},\\beta_{p2}, \\epsilon_1,...,\\epsilon_n } M\\]\\[subject \\ \\ to \\ y_i(\\beta_0 + \\sum_j^p \\beta_{j1} x_{ij} + \\sum _j^p \\beta_{j2}x_{ij}^2) \\geq M(1-\\epsilon_i)\\]\\[\\epsilon_i \\geq 0 \\ , \\ \\ \\sum \\epsilon_i \\leq C \\ , \\ \\ \\sum_j^p\\sum_k^2 \\beta_{jk} ^2 = 1\\]변수의 차원을 높여서 모델에 추가하면 계산량이 많아진다. Support Vector Machine은 support vector classifier에서 사용된 feature space를 보다 확장시켜서 계산량을 적정 수준으로 맞춰준다.9.3.2 The Support Vector Machinefeature space를 어떻게 확장시켜줄 것인가? ==&amp;gt; Kernel을 사용해서.support vector classifier의 해를 찾는 과정(여기서 해는 아마 계수값 beta인듯?)은 관측치들의 내적과 관련이 있다. 즉 식으로 이를 보이면, linear support vector classifier는$f(x) = \\beta_0 + \\sum_i ^n \\alpha_i \\langle x,x_i \\rangle$여기서 x 는 new point, x_i 는 training point 인데 training data가 support vector인 경우에만 alpha 값이 non-zero이다. 즉 S를 support vector들의 집합이라고 할 때,$f(x )= \\beta_0 + \\sum _{i \\in S}\\alpha_i \\langle x,x_i \\rangle$이를 일반화 시켜서 kernel K 함수(kernel은 두 데이터들의 관계를 설명)를 통해 classifier를 만들 수 있다. 여러가지 커널에 대해 classifier의 식은 아래와 같다.$f(x )= \\beta_0 + \\sum _{i \\in S}\\alpha_i K( x,x_i)$(1)linear kernel (Pearson correlation을 통해 두 관측치 관계를 보는 것)\\[K(x_i, x_i&#39;) = \\sum _j ^p x_{ij}x_{i&#39;j&#39;}\\](2)polynomial kernel(degree of d) (linear kernel에 비해 훨씬 flexible boundary를 만들 수 있다)\\[K(x_i, x_i&#39;) = (1 + \\sum _j ^p x_{ij}x_{i&#39;j&#39;})^d\\](※ (2)와 같이 non-linear kernel을 사용해서 classifier를 만드는 것을 support vector machine이라고 한다. 만약 d=1이라면 SVM은 SV classifier와 동일한 것이다.)(3)radial kernel (Radial Basis Function , RBF) (Gaussian kernel이라고도 불림) (gamma 값이 클수록 non-linear)\\[K(x_i, x_i&#39;) = exp(-\\gamma \\sum _j ^p( x_{ij}-x_{i&#39;j&#39;})^2)\\](3)의 원리는 다음과 같다. 특정 test 데이터가 만약 training obs와 유클리드 거리가 멀다면\\[\\sum( x_{ij}-x_{i&#39;j&#39;})^2\\]의 크기는 커질것이고 결과적으로 kernel의 값은 작아질 것이다. 즉 거리가 멀리 떨어진 데이터들은 boundary(hyperplane)을 설명하는 데에 큰 역할을 하지 못할 것이고, kernel은 local behavior를 가지게 된다. 즉 training data 근처에 있는 test data 만이 정확한 분류가 될 것이다.앞서 말했지만 kernel을 사용하면 계산량이 줄어드는데, radial kernel의 경우 feature space가 implicit하고 infinite-dimensional 이므로 계산량이 절대적으로 감소한다.(?)9.3.3 An Application to the Heart Disease Data생략.9.4 SVMs with More than Two ClassesSVM은 개념적으로 두가지 이상의 분류에 적합하지 않다. 그럼에도 불구하고 class가 많을 경우 svm을 사용해서 많은 class를 분류하려는 시도가 있었다.9.4.1 One-Versus-One Classificationk개의 class가 존재할 때, 2개의 class를 뽑는 가능한 모든 조합을 찾아서 각각을 1 그리고 -1로 두고 SVM을 {k combination 2} 만큼 실행. 이 중에서 가장 빈도가 높은 class를 선택한다.9.4.2 One-Versus-All Classificationone , the others9.5 Relationship to Logistic Regressionhyperplane을 만들면서 오류에 대한 어느정도의 허용 범위를 지정한다든지, 혹은 커널을 사용해서 비선형적인 boundary를 만드는 등의 시도는 사실 매우 독창적인 시도라고 보일 수 있따. 그러나 SVM과 과거의 분류 방식들은 여전히 많은 부분에서 접점을 가진다.support vector classifier 부분에서 언급했던 제약조건하에서 최적화 식을 상기해보자. 그 식은 다음과 같이 쓸 수 있다.$minimize_{\\beta_0, \\beta_1, …, \\beta_p} {\\sum max[0, 1-y_if(x_i)] + \\lambda \\sum _j ^ p \\beta_j^2 }$우선 penalty 항을 보자.여기서 lambda가 크다는 것은 그만큼 오류를 많이 허용한다는 뜻으로 support vector classifier 최적화 식에 나왔던 C의 값이 크다는 것과 동일하게 작용한다.(ridge에서의 penalty 값 =&amp;gt; lambda가 크면 분산이 작아진다)이제 loss fuction을 보자$L(X, y , \\beta) = \\sum max[0, 1-y_if(x_i)]$이를 hinge loss라고 한다. 식에서도 알 수 있듯, support vector가 아닌 plane에 의해 올바르게 분류된 부분은 loss를 무조건 0으로 만들고, support vector 부분만이 loss를 통제할 수 있다. 즉 support vector에 의해 plane이 만들어지는 것이다. logistic function의 loss function 또한 이와 비슷한데 차이는 완전한 0을 만들지 않는것에 있다.이러한 차이에도 불구하고, 0 혹은 0에 가까운 작은 값을 만드는 것은 boundary와 매우 멀리 떨어져 있는 값이므로 logistic과 SVMs은 매우 유사한 분류 결과를 가지고 온다. class들이 매우 잘 분류되어 있다면 SVM이 더 좋은 결과를, 반대로 class들이 꽤나 겹쳐 있는 경우에는 logistic regression이 더 좋은 결과를 가지고 올 것이다.앞에서도 말했듯, C, lambda, margin 들을 잘 선택하는 것은 결국 bias - variance 를 결정하는 데에 결정적인 역할을 하게 된다.SVMs 만이 kernel을 사용하는가? 그것은 아니다. logistic에서도 사용은 가능하다. 단 SVM 만큼은 아닌듯또한 SVR도 있다. target 변수가 연속형인 경우 regression을 사용하는데, 여전히 그 원리는 loss를 최소화하는 계수값을 찾는 데에 있다. 단 loss가 바뀐다. 특정 margin 밖에 있는 잔차들의 값을 loss로 보고 이를 줄이고자 한다." }, { "title": "ISLR chap 8", "url": "/posts/ISLR8/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-08 00:00:00 +0900", "snippet": "8. Tree-Based Methodstree-based method는 간단하게 말해서 preditor space(X 공간)를 층화 / 구분 짓고 각 영역의 데이터들에 대한 평균 혹은 중간값으로 예측을 해내는 구조를 말한다.트리 기반의 방식들은 simple 하며 interpretation이 뛰어나나, 예측에 있어 다른 방법들에 비해 열등하다. 따라서 이를 보완하고자 bagging,boosting, Random Forest 등이 나왔는데 이 방식들은 트리를 여러개 만들어서 이들을 결합해 예측력을 높이려는 시도들이다. 즉 기존의 트리 기반 방식에 비해 모델의 해석력은 떨어지나, 예측력을 높인 것이다.8.1 The Basis of Decision Trees8.1.1 Regression Treesupside-down 형식으로 계속해서 가지를 쳐 나가며 분류하는데 각 가지에 의해 구분된 공간들을 terminal nodes 혹은 leave 라고 한다. 또한 predictor space가 나눠지는 점들을 internal nodes 라고 한다. Node를 이어주는 부분들을 branch라고 한다.upside down 형식의 tree 구조를 해석해보자years 가 target 변수를 해석하는 가장 큰 요인이 됨을 그림에서 알 수 있다. 또한 hits의 경우 years가 낮은 집단에 대해서는 target 변수를 결정하는 큰 요인이 되지는 못하지만, years가 높은 경우에는 hits가 target변수를 결정하는 큰 기준이 된다. 그림에서 나타듯, tree based method는 직관적이고 모델을 해석하기 쉽다.building regression tree predictor space를 겹치지 않게 나눈다. R_j 각 영역 R_j 에 속한 관측치들은 모두 같은 값으로 예측하게 된다어떻게 겹치지 않게 predictor space를 나눌 수 있을까?여기서도 결국 RSS를 최소화 하는 방식으로 space를 나누고자 한다. 즉,\\(\\sum_j \\sum _ i (y_i - \\hat y_{R_j})^2\\)를 최소화하는 box\\(R_1, R_2, ....,R_J\\)로 영역을 나누면 된다.그러나 현실적으로 모든 box들을 고려하는 것은 계산상으로 문제가 있기 때문에 top down 방식으로 각 step마다 최고의 성능(가장 rss를 작게하는)의 split을 고른다. 이를 recursive binary splitting이라 한다(변수 선택의 forward selection과 유사). 특이한 점이 있다면, 가지수를 무한대로 늘리는 것이 아니라 각 변수마다 여러가지 branch 중 하나만 선택해서 terminal nodes를 만든다는 것에 있다.tree pruningtree의 split이 너무 많게 되면 복잡해지고 분산이 커져 예측력이 떨어질 수 있다. (1) 이를 해결하기 위해, 모델을 결정할 때 모델의 복잡성에도 불구하고 RSS가 더 작아지는 이점이 더 클 때까지 분할을 하는 방법을 생각할 수 있다. 그러나 이는 어쩌면 매우 작은 tree(분할이 몇개 없는)를 만들거나 혹은 직관적으로 의미없는 tree 일 수도 있다(즉 더 많은 분할이 이뤄진 뒤에 RSS의 급격한 감소가 일어날 수도 있는데 이를 고려하지 않기 때문에). 따라서 교재에서 추천하는 방법은 (2) 매우 큰 모델을 하나 만든 다음 역으로 이를 줄여나가 subtree를 찾는 것이다.이제 모델을 줄여나가는 방법을 알아보자pruning 의 방법으로서 test error rate을 확인하는 것이 있다. 그러나 이를 위해서 각 subtree 마다 CV 혹은 validation set approach를 하는 것은 복잡한 계산을 더욱 복잡하게 만드는 것이다. 따라서 subtree를 몇개 선정해서 CV를 진행한다.그럼 subtree는 또 어떻게 결정할 것인가?==&amp;gt; Cost Complexity prunning(weakest link pruning) : nonnegative tuning parameter alpha 를 가지고 판정. 수식은 아래와 같은데 T는 terminal node를 의미한다.\\[\\sum _m ^ {|T|} \\sum _{x_i \\in R_m} (y_i - \\hat y_{R_m})^2 + \\alpha |T|\\]lasso 처럼 alpha값을 가지고 node의 개수를 조절하면서 RSS를 최소화 하는 모델을 결정하는 것이다.CV값을 가지고 몇개의 후보군 alpha를 선택pruning의 알고리즘은 다음과 같다.정리하면 큰 모델을 만들어낸 다음, 적절한 alpha 후보군을 가지고 CV를 해서 test error rate(이에 대한 예측값이 CV)을 최소로 하는 alpha를 정한다. alpha를 정한다는 것은 곧 변수의 개수를 통제하고 정하는 다는 것이므로 CV error 를 최소로 하는 변수의 개수를 선택하게 된다.8.1.2 Classification Trees어떤 class에 속할지 예측하는 데에 목적. class prediction, class proportion 두 개 다 관심 대상tree growing은 여전히 classification tree에서도 주요 사항인데 regression에서는 RSS를 기준으로 삼았던 것과는 달리 여기선 classification error rate을 기준으로 삼는다.classification error rate : the fraction of the training observation in that region that do not belong to the most common class (class는 본래 분류, region은 추정 분류)책에는 아래와 같은 식을 보여주는데 이는 1-error rate으로 accuracy를 말하는 것 같다.$E = 1 - max_k(\\hat p_{mk})$\\(\\hat p _{mk}\\)는 proportion of the training observation in the m-th region that are from the k-th class.방금 전에도 기술했지만 error rate은 prediction accuracy와 관련된 것으로 accuracy를 목적으로 할 때에는 error rate을 주목해서 보겠지만, tree-growing에 대한 판단을 할 때에는 다른 기준을 사용한다. Gini index ( a measure of total variance across the K classes)$G = \\sum \\hat p_{mk}(1- \\hat p _{mk})$이는 각 노드의 purity 를 측정하는 것으로 hat p 값이 0 혹은 1에 가까울 수록 그 값이 낮아진다. 따라서 이 값은 작으면 작을수록 좋은 것이다. Cross-entropy$D = - \\sum \\hat p _{mk} log (\\hat p _{mk})$이 값 역시 hat p 값이 0 혹은 1에 가까울수록 0에 가까운 값을 가진다. 이 또한 purity를 측정하는 값이다.질적 변수 또한 분류의 기준이 될 수도 있다. 또한 purity를 기준으로 tree-growing을 실행했을 때, 같은 predicted value를 갖는 terminal node 도 존재한다. 즉 하나의 기준에 따라 나눠진 값이 모두 같은 값을 가질 수도 있다.8.1.3 Trees Versus Linear Methods본래 데이터 관계가 선형이면 당연히 linear 한 방법이 좋을 것.본래 데이터 관계를 차치하고서도 분석의 목적이 interpreability나 visualization에 있다면 tree-based method 가 더 좋을 것.8.1.4 Advantages and Disadvantages of Trees장점 다른사람들에게 모델에 대해 설명하는 경우 linear regression 보다도 설명하기가 쉽다 보다 인간의 사고 방식과 유사하다 시각적으로 보여주기 쉽다 더미변수 없이도 질적변수를 다룰 수 있다.단점 예측력이 떨어진다. 이를 극복하기 위해 아래 내용들이 나옴.8.2 Bagging, Random Forest, Boosting위 세가지는 tree를 예측력이 높은 모델을 만들기 위한 하나의 block으로 여긴다.8.2.1 Bagging(creating, fitting, combining)boostrap + aggregation목적 : 예측력을 위해 분산을 줄여보자.어떻게? 평균으로 예측하면서 ( 표본평균의 분산이 모 분산에 비해 작아지는 것과 동일한 원리)그런데 multiple training set을 얻기 힘드니까 boostrap을 사용하는 것.B개의 다른 boostrapped training data set을 가지고 학습을 시켜 모델\\(\\hat f ^{*b}(x)\\)을 만들고 이를 평균 내어 추정한다.그럼 붓스트랩 data set 개수 B는 어떻게 결정되는 것인가? 딱히 정해진 것은 없으며 개수가 많아도 overfitting의 위험이 없다. 즉 error를 가장 작게 만드는 큰 값이 좋을 것이다.bagging은 사실 많은 회귀문제에 사용될 수 있는 방법인데 특히 분산이 큰 decision tree에 유용하다. 또한 boostraping을 사용할 때 block으로 여겨지는 tree들은 deep하고 prune 되지 않은 것이다.classification 에서 bagging을 사용하는 방법은 각 트리에서 나온 분류 예측값들을 가지고 voting을 통해 결정한다.Out - of - Bag Error Estimationboostrap 방법의 특징을 이용해서 error를 측정하는데 이는 boostrap data set B가 매우 클 때 leave-one-out cross-validation과 유사하다(즉 데이터가 부족할 때 k-fold 처럼 많은 수의 데이터를 validation set으로 놓기 힘들 때 유용하다). Data set이 너무 큰 경우 CV error를 계산하는데 필요한 계산량이 매우 많은데 이 대신에 OOB error를 사용할 수 있다.방법은 다음과 같다. boostraping 을 하는데 사용하는 observation 중에서 2/3 만 사용해서 boostrapping sample을 만든다. 그 뒤 이를 적합시켜 모델을 만들고 남은 1/3의 관측치에 대한 예측값을 구하고 OOB MSE를 구한다. 이 error 값이 bagged model의 test error에 대한 추정값이 된다.Variable Importance Measuresbagging을 하면 해석력이 떨어지고 visualization이 어렵다. 즉 더이상 statistical learning procedure을 트리 형태로 보이기 어렵다. 이는 어떠한 변수가 더 중요한 것인지 시각화하기 어렵다는 것이다. 단 이러함을 감수하고서도 예측력은 더 좋아질 것이다.그럼에도 불구하고 bagging을 통해 알아낼 수 있는 부분은, 각 변수들에 대해서 그 변수를 split 했을 때, RSS 감소량 혹은 Gini-index의 감소량의 총합(각 모델과 bagging에 의한 rss, gini-index)이 크면 그 변수는 상대적으로 더 중요한 것이라고 할 수 있다.8.2.2 Random ForestsRandom Forest는 bagged tree를 개선시킨 것으로서 boostarping 이전 변수의 일부분만 뽑아서 이들을 가지고 모델에 적합시킨다. 이 방법은 예측값의 correlation을 낮춰줄 수 있다. 만일 특정변수가 매우 영향력이 크다면 bagged tree들은 모두 특정변수를 top split으로 둔 model이 될 것이다. 이러한 경우 결과값이 매우 유사해질 것이고 평균 시 variance의 감소 효과가 미미하다. Random Forest는 predictor 중 일부분만 변수로 넣게 함으로써 uncorrelated quantity들을 평균시킬 수 있다.이때 각 split은 m 개의 변수로 이뤄지며 전체 변수 개수가 p 일 때\\(m =\\sqrt (p)\\)이다.(oob는 행을 떼어내는 것, RF는 열을 떼어내는 것)RF는 bagging의 일종이므로 bagging data set B의 크기는 overfitting과 관련이 없다.8.2.3 BoostingBoosting 또한 tree-based method 뿐만 아니라 다른 regression 혹은 classification에서도 쓸 수 있다.Boosting의 방식 또한 ‘creating + fitting+combining’으로 bagging과 유사하다.단 tree가 sequentially 증가한다는 데에 차이가 있다. “each tree is grwon using information from previously grown trees” 이 말 뜻은 정해진 모델들에서 나온 값들을 combining하지는 bagging과는 다르게, boosting 은 잔차를 살피고 이에 따라 가중치를 달리주면서 모델을 점점 만들어나간다는 것이다.또한 boostrapping을 통해 표본을 만들어 내는 것이 아니라, 각 tree들이 본래 데이터의 변형된 형태에 적합이 된다는 것에 차이가 있다.알고리즘은 다음과 같다알고리즘이 의미하는대로, boosting은 y의 값이 아닌 업데이트 된 잔차를 target 변수처럼 생각하고 적합하는 데에 있다. 적합된 모델은 기존의 적합 모델과 더해지고 lambda에 따라서 여러가지 적합 모델이 잔차를 attack(상쇄시키려 노력, 잔차를 없애려고 노력)한다.충분히 예상하겠지만 이러한 과정은 모델의 학습 속도를 늦추게 한다.boosting은 세가지 tuning parameter를 갖는다.(1) the number of trees B. 여기서 B는 그림의 알고리즘에 나오는 B이다. 즉 업데이트 횟수. boosting은 bagging이나 RF와는 달리 overfitting이 될 수 있기 때문에 CV를 통해 최적의 횟수를 결정해야한다.(앞에서 보았듯, bagging이나 RF는 B의 개수가 overfitting을 결정하진 않았다)(2) the shrinkage parameter lambda. 이는 부스팅을 통해 학습을 하는 비율을 조절한다. 일반적으로 0.01 혹은 0.001을 사용한다. 이 값이 작으면 좋은 성능을 위한 학습의 횟수가 많이 요구된다.(3) the number of d. 즉 변수의 개수. 이는 앙상블의 복잡성을 통제. 변수의 개수인 만큼 interaction depth를 결정한다고 말할 수 있다. 즉 변수가 많아지면 변수간의 교호작용도 많이 고려해야한다.또한 Boosting은 RF와 다르게 tree의 성장이 이전 tree에 영향을 받기 때문에 더 작은 tree 또한 설명력이 좋을 수 있다." }, { "title": "ISLR - LAB8", "url": "/posts/ISLR8-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-08 00:00:00 +0900", "snippet": "8장 코드 정리## Fitting Classification Treeslibrary(tree)library(ISLR)attach(Carseats)High = ifelse(Sales&amp;lt;=8, &quot;No&quot;,&quot;Yes&quot;)High = as.factor(High)Carsetas = data.frame(Carseats,High) #기존의 Carseats data와 High를 합치는 것. tree.carseats = tree(High ~ . - Sales, data = Carseats) # 회귀 할 때 lm 처럼 tree 를 사용함.summary(tree.carseats)&quot;&quot;&quot;Classification tree:tree(formula = High ~ . - Sales, data = Carseats)Variables actually used in tree construction:[1] &quot;ShelveLoc&quot; &quot;Price&quot; &quot;Income&quot; &quot;CompPrice&quot; &quot;Population&quot; [6] &quot;Advertising&quot; &quot;Age&quot; &quot;US&quot; Number of terminal nodes: 27 Residual mean deviance: 0.4575 = 170.7 / 373 Misclassification error rate: 0.09 = 36 / 400&quot;&quot;&quot;plot(tree.carseats)text(tree.carseats, pretty=0, cex=0.5) #display node labels, pretty는 categorical 변수 안에 항목 중에 어떤 값으로 분류되었는지도 말해주는 것.tree.carseats #plot의 내용을 라인별로 console에 띄어줌.#predictionset.seed(2)train = sample(1:nrow(Carseats),200)Carseats.test = Carseats[-train,]High.test = High[-train] #high는 데이터프레임이 아니라서 [-train,]라고 쓰면 오류남tree.carseats = tree(High ~ . -Sales, Carseats, subset = train)tree.pred = predict(tree.carseats, Carseats.test, type=&#39;class&#39;) #type = &#39;class&#39; 명령어를 통해 실제 class 예측값을 return 받는다. # tree.pred = predict(tree.carseats, Carseats.test)table(tree.pred, High.test)#pruneset.seed(3)cv.carseats = cv.tree(tree.carseats, FUN=prune.misclass) #pruning 과정에서 classification error rate을 최소화하는 cv 값을 가지고 모델을 선택하게 하는것.names(cv.carseats) # 항목이 무엇인가cv.carseats # 결과값을 보고 dev(corresponde to cv - error) 를 가장 작게 하는 terminal node의 개수를 찾아 이에 해당하는 size 그리고 k값(alpha 값)을 선정plot(cv.carseats$size, cv.carseats$dev, type=&quot;b&quot;)plot(cv.carseats$k, cv.carseats$dev, type=&quot;b&quot;)#9개의 노드로 prune 하기 : prune.misclass() 명령어 사용해서 기존에 적합한 tree.carseats를 prune 하기prune.carseats = prune.misclass(tree.carseats,best=9)plot(prune.carseats)text(prune.carseats, pretty=0, cex = 0.5)#pruning 한 모형의 예측력이 얼마나 뛰어날까tree.pred = predict(prune.carseats, Carseats.test, type=&#39;class&#39;)table(tree.pred, High.test)#결과를 보니 terminal node를 줄여서 더 해석력도 좋으면서도 accuracy도 높은 모델이 완성이 되었다. ## Fitting Regression Treeslibrary(MASS)set.seed(1)train = sample(1:nrow(Boston),nrow(Boston)/2)tree.boston=tree(medv ~ ., Boston, subset=train)summary(tree.boston)plot(tree.boston)text(tree.boston, pretty=0)cv.boston = cv.tree(tree.boston)plot(cv.boston$size, cv.boston$dev, type=&#39;b&#39;)prune.boston = prune.tree(tree.boston, best=5)plot(prune.boston)text(prune.boston,pretty=0)#predictionyhat = predict(tree.boston, newdata = Boston[-train,])boston.test = Boston[-train,&#39;medv&#39;]plot(yhat, boston.test)#plot이 왜 이산형처럼 나올까? =&amp;gt; tree기반 모델이니까 각 region 마다 동일한 값으로 예측abline(0,1)mean((yhat - boston.test)^2)## Bagging and Random Forest#Bagging은 Random Forest의 특별한 경우이므로 randomForest() function으로 randomforest와 bagging을 모두 사용할 수 있다. library(randomForest)set.seed(1)bag.boston = randomForest(medv~., data= Boston, subset = train, mtry=13, importance = TRUE) #mtry=13 의 의미는 각 split에 13개의 변수 모두 들어가도록 = baggingbag.boston#randomForest 에 ntree 인자를 통해 tree의 개수를 조절할 수 있다,bag.boston = randomForest(medv~.,data=Boston, subset= train, mtry=13, ntree=25)yhat.bag = predict(bag.boston, newdata = Boston[-train,])mean((yhat.bag - boston.test)^2)#randomForest에 mtry를 조절해서 bagging에서 RF로rf.boston = randomForest(medv~., data= Boston, subset = train, mtry=6, importance = TRUE) rf.bostonyhat.rf = predict(rf.boston, newdata = Boston[-train,])mean((yhat.rf - boston.test)^2)importance(rf.boston) #importance는 변수의 중요도를 보여준다. 이 결과값은 모두 감소량을 의미하는데, 첫번째는 각 변수가 빠졌을 때 OOB 샘플의 예측 정확성의 평균 감소, 두번째는 split 과정에서 줄어드는 node impurity의 total 값이며 그 total 값을 모델마다 평균한것.varImpPlot(rf.boston) #교과서 figure 8.9## Boostinglibrary(gbm)set.seed(1)boost.boston = gbm(medv~., data=Boston[train,], distribution = &#39;gaussian&#39;, n.trees=5000, interaction.depth=4)#distribution = &#39;gaussain&#39; 은 회귀에서, distribution = &#39;bernoulli&#39;는 분류에서#n.trees 는 tree 원하는 개수#depth는 tree의 깊이#shrinkage를 주려면 인자로 shrinkage = 0.2 와 같이 준다.boost.boston = gbm(medv~., data=Boston[train,], distribution = &#39;gaussian&#39;, n.trees=5000, interaction.depth=4, shrinkage = 0.2)yhat.boost = predict(boost.boston, newdata = Boston[-train,], n.trees=5000)mean((yhat.boost - boston.test)^2)#boosting 과정에서 변수의 중요도 보기summary(boost.boston)names(summary(boost.boston)) # &quot;rel.inf&quot; 는 relative influence statistic. 즉 중요한 변수plot(boost.boston, i = &#39;rm&#39;) # rm 변수가 y 에 미치는 marginal effect" }, { "title": "ISLR - LAB7", "url": "/posts/ISLR7-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-06 00:00:00 +0900", "snippet": "7장 코드 정리##Non - linear modelinglibrary(ISLR)attach(Wage)#polynomialfit = lm(wage~poly(age,4), Wage) #orthogonal polynomialcoef(summary(fit))&quot;&quot;&quot; Estimate Std. Error t value Pr(&amp;gt;|t|)(Intercept) 111.70361 0.7287409 153.283015 0.000000e+00poly(age, 4)1 447.06785 39.9147851 11.200558 1.484604e-28poly(age, 4)2 -478.31581 39.9147851 -11.983424 2.355831e-32poly(age, 4)3 125.52169 39.9147851 3.144742 1.678622e-03poly(age, 4)4 -77.91118 39.9147851 -1.951938 5.103865e-02&quot;&quot;&quot;fit2 = lm(wage~poly(age,4, raw = T), Wage)coef(summary(fit2))&quot;&quot;&quot; Estimate Std. Error t value Pr(&amp;gt;|t|)(Intercept) -1.841542e+02 6.004038e+01 -3.067172 0.0021802539poly(age, 4, raw = T)1 2.124552e+01 5.886748e+00 3.609042 0.0003123618poly(age, 4, raw = T)2 -5.638593e-01 2.061083e-01 -2.735743 0.0062606446poly(age, 4, raw = T)3 6.810688e-03 3.065931e-03 2.221409 0.0263977518poly(age, 4, raw = T)4 -3.203830e-05 1.641359e-05 -1.951938 0.0510386498&quot;&quot;&quot;#orthogonal polynomial은 제곱항 세제곱항 등이 가지는 높은 상관계수를 제거한 변수들이다. 회귀계수 추정값을 보면 orthogonal poly일 때 추정 계수 값이 훨씬 크다. 그러나 단점으로는 orthogonal 변수로 바뀌었기 때문에 모델의 해석력이 떨어진다.#orthogonal인지 아닌지는 모델의 의미 자체에는 영향을 안준다. 즉 fitted value는 orthogonal 여부에 상관없이 동일하다. #raw=TRUE와 같은 polynomial regression은 아래 두가지이다.fit2a = lm(wage ~ age + I(age^2) + I(age^3) + I(age^4), data=Wage)coef(fit2a)&quot;&quot;&quot; (Intercept) age I(age^2) I(age^3) I(age^4) -1.841542e+02 2.124552e+01 -5.638593e-01 6.810688e-03 -3.203830e-05 &quot;&quot;&quot;fit2b = lm(wage~cbind(age,age^2,age^3,age^4), data=Wage)coef(fit2b)agelims = range(age) #r 에서 range는 범위를 나타낸다.age.grid = seq(from=agelims[1], to=agelims[2])preds = predict(fit, newdata = list(age=age.grid), se=TRUE)se.bands = cbind(preds$fit + 2*preds$se.fit,preds$fit - 2*preds$se.fit )se.bands #예측값에 대한 신뢰구간 코딩으로 직접 구하기.# polynomial 의 차수를 결정하기위해 anova를 사용하자#단 여기서 각 모델은 nested model이어야.fit.1 = lm(wage~age, data=Wage)fit.2 = lm(wage~poly(age,2), data=Wage)fit.3 = lm(wage~poly(age,3), data=Wage)fit.4 = lm(wage~poly(age,4), data=Wage)fit.5 = lm(wage~poly(age,5), data=Wage)anova(fit.1, fit.2, fit.3,fit.4,fit.5)#anova 메소드를 사용한 결과는 orthogonal poly와 결과가 같다.#즉 coef(summary(fit)) 또한 동일한 p-value와 동일한 t-statistic ^2 = F-statistic 을 가지고 있다. #로지스틱에서도 polynomial을 사용할 수 있다.fit = glm(I(wage&amp;gt;250) ~ poly(age,4), Wage, family = binomial)preds = predict(fit, newdata = list(age=age.grid), se=T)#여기서 나온 preds 값은 logit 값이므로 이를 바꾼다. pfit = exp(preds$fit) / (1+exp(preds$fit))pfit#위와 같은 논리를 간단한 코드로 나타낼 수 있다. family = binomial 이므로 type=response 만 주면 확률값이 나온다.preds = predict(fit, newdata = list(age=age.grid), type = &quot;response&quot;, se=T)preds#로지스틱 신뢰구간 만들기plot(age,I(wage&amp;gt;250), xlim=agelims, type = &quot;n&quot;, ylim=c(0,.2))points(jitter(age), I((wage&amp;gt;250)/5), cex=.5, pch=&quot;l&quot;, col=&quot;darkgray&quot;)lines(age.grid, pfit, lwd=2, col=&#39;blue&#39;)matlines(age.grid,se.bands, lwd=5, col=&quot;green&quot;)se.bands#step function -- use cut() functiontable(cut(age,4))fit = lm(wage ~ cut(age,4), data=Wage)coef(summary(fit)) #dummy 이므로 4개로 구간 cutting 하면 변수는 3개&quot;&quot;&quot; Estimate Std. Error t value Pr(&amp;gt;|t|)(Intercept) 94.158392 1.476069 63.789970 0.000000e+00cut(age, 4)(33.5,49] 24.053491 1.829431 13.148074 1.982315e-38cut(age, 4)(49,64.5] 23.664559 2.067958 11.443444 1.040750e-29cut(age, 4)(64.5,80.1] 7.640592 4.987424 1.531972 1.256350e-01&quot;&quot;&quot;## spline regressionlibrary(splines)fit = lm(wage ~ bs(age, knots = c(25,40,60)), data=Wage) #spline은 basis function을 만드는 bs 명령어를 준다.pred = predict(fit, newdata=list(age=age.grid), se=T)plot(age, wage, col=&#39;gray&#39;)lines(age.grid, pred$fit , lwd=2)lines(age.grid, pred$fit + 2*pred$se, lty = &quot;dashed&quot;)lines(age.grid, pred$fit - 2*pred$se, lty = &quot;dashed&quot;)#knots를 data의 uniform quantile로 주고 싶다면bs(age, df=6) # 왜 6인가? cubic spline에서는knot가 3개 일때 자유도가 7인데 intercept를 제외하고 6이 되는 것.fit2 = lm(wage~bs(age,df=4), data=Wage)## smoothing spline -- smooth.spline() 사용plot(age, wage, xlims=agelims, cex = .5 , col = &#39;darkgrey&#39;)fit = smooth.spline(age, wage, df=16)fit2 = smooth.spline(age, wage, cv=TRUE)fit2$df #6.8 즉 cv를 통해서 rss를 가장 작게하는 smoothness level을 결정.lines(fit, col=&#39;red&#39;)lines(fit2, col=&#39;blue&#39;)##local regression -- loess() 사용plot(age, wage, xlim = agelims, cex=.5, col=&#39;darkgrey&#39;)fit = loess(wage~age, span=.2, Wage)fit2 = loess(wage~age, span=.5, Wage)lines(age.grid, predict(fit,data.frame(age=age.grid)),col=&#39;red&#39;)lines(age.grid, predict(fit2,data.frame(age=age.grid)),col=&#39;blue&#39;)## GAMs# big linear regression model using basis function 인 경우gam1 = lm(wage ~ bs(year,4) + bs(age,5) + education, Wage)# smoothing spline을사용한 GAMs -- gam 라이브러리 사용library(gam)gam.m3 = gam(wage ~ s(year, 4)+s(age,5)+education, data=Wage)par(mfrow=c(1,3))plot(gam.m3, se=TRUE, col=&quot;blue&quot;)#par(mfrow=c(1,1))plot.gam(gam1, se=TRUE, col=&#39;red&#39;) #plot.gam 은 gam,lm 모두 사용 가능summary(gam.m3)preds = predict(gam.m3, newdata = Wage)#gam을 building 하는 데에 local regression 쓸수도 있음.gam.io = gam(wage ~ s(year, df=4) + lo(age, span=0.7) + education, data=Wage)gam.io.i = gam(wage ~ lo(year,age, span=0.5) + education, data=Wage) #localregression 과정에서 interaction term 넣기library(akima) #two-dimenstional surface 볼 수 있는 packageplot(gam.io.i)#logistic GAMsgam.lr = gam(I(wage&amp;gt;250) ~ year + s(age,df=5)+education, family = binomial, data=Wage)plot(gam.lr, se=T, col=&#39;green&#39;)" }, { "title": "MCMC", "url": "/posts/MCMC/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-05 00:00:00 +0900", "snippet": "Markov Chain Monte Carlo흔히 줄여서 말하는 MCMC에 대해서 정리해보려고 한다.우선 정상분포(stationary distribution)와 에르고딕(ergodic)이 무엇인지 알아보자(나무위키를 참조했습니다)basic theory1. stationary란?stationary distribution은 분포가 가진 통계적 특징, 즉 평균이나 모먼트, 분산 등이 시간에 따라 변하지 않는다는 것을 의미한다. 또한 stationary process란 확률분포가 시간에 따라 항상 동일함을 의미한다.2. ergodic란?ergodic theory는 장시간동안 지속되는 dynamical system 안에서의 행동을 보고자 한다. 이 이론에서는 공간 안에 있는 각 점들이 장기적으로 볼 때 언젠가는 결국 다시 되돌아 온다는 것에 주목한다.(Poincaré recurrence theorem) 즉 ergodic system은 conservative system으로서 매우 안정화 되어있다. conservative system : such systems have no friction or other mechanism to dissipate the dynamics. thus their phase space does not shrink over time. precisely speaking, they are those dynamical systems that have a null wandering set. 즉 쉽게 말해서 시스템이 매우 안정적이며 한번 만난 점은 결국 다시 만나게 된다(not dissipate). 3. irreducible란?마코프 체인이 irreducible 하다고 말하는 것은 상태 i 에서 상태 j 로의 전이 확률값이 모두 양수인 것을 의미한다. 또한 irreducible Markov Chain에서는 특정 상태에 위치할 확률을 장기적으로 계산해서(극한으로?) \\(\\pi_j\\)라고 한다.4. aperiodic란?state i에서 state i로의 전이확률값이 양수인 경우. 즉 모든 상태 i 에 대해 자기 자신으로 되돌아올 확률이 양인 chain.#What is Markov Chain? What ist Monte CarloMarkov chain이제 MCMC 알고리즘에 대해 설명해보겠다.MCMC를 개략적으로 설명하자면, target distribution이 stationary 일 때 그 분포로부터 표본을 추출하는 알고리즘의 한 부류이다(즉 목적은 sampling!). markov chain이 stationary 분포로 얼마나 빠르게 수렴할 수 있는지가 중요하다.(1) markov chain\\(X_1, X_2, ... , X_N\\)은 확률과정으로 \\(P(X_{n+1} | X_1, ...,X_n) = P(X_{n+1}|X_n)\\)이 때 irreducible 이고 ergodic 이면 n이 무한대일 때 X_n의 분포는 정상분포로 수렴한다. 그리고 이때에는 초기값 X_0와는 무관하다. 따라서 target distribution F로 부터 표본을 생성하기 위해서는 $ P(X_{n+1} | X_n) $ 에서의 표본 생성이 쉬워야 한다. F가 markov chain의 정상분포여야 한다. (1)-1 algorithm 초기값 X_0 지정 정상분포에 도달할 때까지 충분히 큰 N에 대해 X_n을 생성 수렴진단 방법을 이용해서 수렴 여부 확인, 수렴 안되면 더 많은 관측값 생성 정상분포에 도달하기 위한 burn-in 관측값(X_i)을 제거하고 이후의 X_n 들을 표본으로 선택.Monte Carlo(2) Monte Carlo위키피디아에 따르면 몬테카를로 방법이란 무수히 많은 무작위 추출을 통해 함수의 값을 확률적으로 계산하는 것을 말한다.(2)-1 몬테카를로 적분(수치적분이 가능하면 수치적분을 사용한다 ex. 사다리꼴 공식, 심슨공식) hit or miss Monte Carlo Method사각형 중에서 I의 면적 비율이 p일 때 : I = c(b-a)p사각형 중 함수 아래에 찍히는 점의 개수를 X 라고 하면\\(X \\sim B(N,p)\\)이고 \\(\\hat p = X/N\\)따라서$\\hat I = c(b-a)X/N$이 때 추정량의 분산을 작게 하기 위해서\\(c = Max_{a\\leq x \\leq b}g(x)\\)로 설정한다.또한\\(p(|\\hat I - I| &amp;lt; \\epsilon) \\geq 1 - \\frac { Var(\\hat I)}{\\epsilon^2} \\geq 1- \\alpha\\)이므로 I의 추정값이 주어진 오차한계 epsilon 내에서 100(1-a) % 신뢰도를 갖는 표본의 크기를 정하기 위해\\(N = \\frac {c^2(b-a)^2}{4\\alpha \\epsilon^2}\\)을 사용 sample mean Monte Carlo integration$X \\sim U(a,b) ==&amp;gt; E[g(x)] = \\frac { 1}{b-a}\\int g(x)dx$이므로$\\int g(x)dx = (b-a)E[g(x)]$따라서 넓이를 추정하면$\\hat I = \\frac {b-a}{N}\\sum g(x_i), \\ \\ \\ \\ \\ 난수 \\ \\ x_i \\sim U(a,b)$(2)-2 몬테카를로 추론 점추정$X_1, X_2 \\sim ^{iid} N(0,1)$에 대해$\\theta = E|X_1 - X_2|$를 추정하기 위해서 표준정규분포에서 난수를 생성해서$\\hat \\theta ^{(j)} = |x_1^{(j)} - x_2^{(j)}|$를 구하고 이를 가지고 평균을 내면 theta 값을 추정할 수 있다. 구간추정$X \\sim F_x$일 때 모수 theta를 추정한다고 하자.j 번째 랜덤표본\\(X_1^{(j)},...,X_n^{(j)}\\)을 생성해내고 이를 가지고 j번째 표본에 대한 신뢰구간 C_j를 계산한다. 이후\\(y_j = I(\\theta \\in C_j)\\)에 대해 경험적인 신뢰수준\\(\\bar y = \\frac {1} { m} \\sum y_j\\)을 계산.What is MCMC?Metropolis - Hastings Sampler지금까지 몬테카를로 그리고 마코프 체인에 대해 설명했으니 이를 조합한 MCMC를 설명해보자MCMC는 앞에서 말했듯 샘플링의 한 방법으로서 Metropolis - Hastings Sampler와 Gibbs Sampler가 있다.기본적인 구조는 다음과 같다(1) 초기값을 하나 임의로 정함 =&amp;gt; (2) 초기값을 모수로 하는 제안분포로 (g)부터 새로운 샘플 추천 =&amp;gt; (3) 새로운 샘플을 accept or reject? =&amp;gt; (4) 이런 과정을 반복하면 정상분포로 수렴할 때까지 표본들이 추출됨 =&amp;gt; 초기의 burn-in을 제외하고 나면 targeting distribution(f)으로 부터 뽑은 sample들이 등장여기서 M-H sampler는 새로운 샘플을 accept or reject 하는 과정에서 다음을 반복한다1.$\\ Y \\sim \\ g(* | X_t) \\ 생성 (X_t : parameter)$2.$\\ U \\sim U(0,1) \\ 생성$3.$\\ U \\leq \\frac {f(Y)/g(Y|X_t)}{f(X_t)/g(X_t|Y)} \\ \\ 이면 \\ \\ X_{t+1} = Y \\ 채택 \\ \\ or \\ X_{t+1} = X_t$이러한 방법으로 X_n을 쭉 뽑아내면 n 이 충분히 커졌을 때 정상분포로 수렴하게 되고 burn-in을 제외하면 target dist에서 뽑은 표본이 된다.Gibbs SamplerM-H sampler의 일종이므로 기본적인 과정은 동일하다.$X = (X_1, …, X_d)\\ 일 \\ 때 \\ X_{(-j)} = (X_1,…,X_{j-1}, X_{j+1}, … , X_d)$라고 하면 X_j의 일변량 조건부 밀도함수\\(f(X_j | X_{(-j)})\\)가 완전히 알려져있다고 가정한다.이러한 일변량 조건부 밀도함수로부터 새로운 후보변수를 추천받고 M-H sampler 와는 다르게 모든 후보점들이 채택된다.수렴 진단표본들을 계속 뽑아나가는데, 언제까지 뽑아나가야 하는걸까?(1) trace plot : 반복에 따라 생성된 표본의 경로를 그려서 주기성이나 경향성이 없는지 체크.(2) autocorrelation graph : 자기상관이 없어지는 표집시차(sampling lag) 찾기(3) 몬테칼로 오차 : ‘‘몬테칼로’’ 니까 표본들을 통해 오차를 추정해보는 것. 즉 오차가 작으면 정확도가 높다는 것을 활용=&amp;gt; N개의 표본을 K개의 batch로 분할해서 batch 당 평균과 전체 평균을 구한 뒤 몬테칼로 오차 추정값을 구한다.$\\hat {se}[\\bar{ g(X)}] = \\sqrt {\\frac {1}{k(k-1)}\\sum(\\bar{g(X)_b} - \\bar {g(x)})^2}$MCMC simulation with Rlibrary(bayesmeta)set.seed(2020)#target 분포 f : 레일리 분포f = function(x, sigma){ if (any(x&amp;lt;0)) return (0) stopifnot(sigma&amp;gt;0) return((x/sigma^2)*exp(-x^2/(2*sigma^2)))}?rgammam=10000sigma = 4x = numeric(m) #실수형으로 선언하기 x[1] = rgamma(1,1) #제안분포는 gamma 분포k=0u = runif(m)for (i in 2:m) { xt = x[i-1] y = rgamma(1, xt, 1) #rgamma 는 인수로 n, shape, rate num = f(y,sigma) * dgamma(xt,y,1) #dgamma는 인수로 x, shape, rate den = f(xt,sigma)*dgamma(y,xt,1) if (u[i] &amp;lt;= num/den) x[i] = y else { x[i] = xt k = k+1 }}print(k) #2960 왜 2960 인가? 10000개 중에 reject 된게 2960개인 것#target 분포y = seq(0,15, length=1000)plot(y, drayleigh(y,4), col = &#39;red&#39;)#M-H로 만든 분포hist(x, prob=T, add=T, breaks=200)참고Sheldon M. Ross, in Introduction to Probability Models &amp;amp; wikipedia서울시립대 박창이 교수님 강의노트https://datascienceschool.net/03%20machine%20learning/19.01%20%EB%AA%AC%ED%85%8C%EC%B9%B4%EB%A5%BC%EB%A1%9C%20%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88%20%EB%B6%84%EC%84%9D.html" }, { "title": "ISLR chap 7", "url": "/posts/ISLR7/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-05 00:00:00 +0900", "snippet": "7. Moving Beyond Linearityrelax the linearity assumption while still attempting to maintain as much interpretability as possible7.1 Polynomial Regression변수들의 제곱항이나 세제곱항을 추가한 뒤에 기존의 linear regression이나 logistic regression을 똑같이 적합시키면 된다. 차원이 높아질수록 매우 비선형적인 그래프가 만들어질것이고 이 경우 심각한 오버피팅의 위험이 있기 때문에 보통은 3차원 혹은 4차원 정도에서 적합한다.7.2 Step Functions ( piecewise constant regression )global structure을 피하고 step function을 사용해서 X 변수를 quantitative =&amp;gt; qualitative로 바꾼다.cutting 방법은 그림과 같이 cutpoint를 설정 후 categorical 변수로 바꾸는 것이다. dummy화 시키는 것각 bin을 predictor로 사용해서 회귀식에 적합$y_i = \\beta_0 + \\beta_1C_1(x_i) + \\beta_2C_2(x_i) + …+\\beta_kC_k(x_i) + \\epsilon_i$단, breakpoint를 잘못 설정하면 변수간의 증감이 드러나지 않을 수도 있다.7.3 Basis Functionspolynomial regression 혹은 piecewise-constant regression 은 basis function approach의 일종이다. basis function을 b는 연구자에 의해 사전에 정해진 것으로 이를 활용해서 predictor를 변화시켜 적합$y_i = \\beta_0 + \\beta_1b_1(x_i) + \\beta_2b_2(x_i) + …+\\beta_kb_k(x_i) + \\epsilon_i$polynomial function, step function, wavelets, Fourier series 등이 basis function으로 사용 가능regression spline 또한 basis function을 사용한 회귀이다.7.4 Regression Splinesflexible class of basis functions7.4.1 Piecewise PolynomialsX 변수의 각 영역(piecewise)에 낮은 차수의 각기 다른 polynomial을 적합시키는 것.회귀 계수가 변하는 부분, 즉 cutpoint를 knot라고 부른다.만약 single knot를 가진 piecewise cubic polynomial을 적합시키고자 한다면\\(y_i = \\begin{cases} \\beta_{01} + \\beta_{11}x_i + \\beta_{21}x_i^2 &amp;amp; if \\ \\ x_i &amp;lt; c \\\\ \\beta_{02} + \\beta_{12}x_i + \\beta_{22}x_i^2 &amp;amp; if\\ \\ x_i \\geq c \\end{cases}\\)결국 앞에서 나온 step function은 knot를 통해 나눠진 구간에, 적합시키는 polynomial의 차수가 0인 것이고 simple 한 polynomial은 knot가 0개인 Piecewise Polynomials를 의미하는 것이다.단점? 이라면 piecewise polynomial들이 불연속일 수 있고, knots의 개수가 늘어나면 모델 전체의 계수도 많아지는 것이므로 자유도가 늘어난다.7.4.2 Constraints and SplinesConstraints가 필요한 이유? knot에 의해 나눠진 각 section 별 함수가 불연속일 수 있다. 이는 데이터 자체가 가진 본연의 이유가 아니라면 매우 어색한 것.continuity와 smoothness를 주기 위해 constraints가 필요하다. 단 이러한 제약을 위해서 어느정도의 자유도는 감소된다.예를들어 cubic spline은 third ordered piecewise polynomial에 3개의 제약(continuity, continuity of the first derivative, continuity of the second derivate)을 주면서 continuity와 smoothness를 달성linear spline은 각 적합 함수가 선형이며 knot에서 연속성을 갖는 spline을 말한다.(smoothness는 달성하지 못함)7.4.3 The Spline Basis Representationbasis model을 활용해서 복잡한 spline을 표현해보자cubic spline의 경우(knots는 K개)\\(y_i = \\beta_0 + \\beta_1 b_1(x_i) + \\beta_2b_2(x_i) + ... + \\beta _{K+3}b_{K+3}(x_i) + \\epsilon_i\\)((cubic spline의 경우 자유도가 (knot 개수 K + 4)이다. 그 이유는 제약이 없을 때 자유도는 4K 인데 knot 하나당 제약으로 인해 자유도가 3씩 줄어 4(K+1) - 3K 가 최종 자유도가 되기 때문이다.))basis model을 cubic polynomial와 truncated power basis function으로 표현해보자.truncated power basis function이 다음과 같이 정의될 때$h(x,\\xi) = (x-\\xi)_+^3 = \\begin{cases} (x-\\xi)^3 &amp;amp; \\ \\ if \\ \\ x &amp;gt; \\xi \\ 0 &amp;amp; \\ \\ otherwise \\end{cases}$basis function을 \\(X, X^2, X^3, h(X,\\xi_1), h(X,\\xi_2), ...,h(X,\\xi_K)\\)로 잡으면 cubic spline을 basis function을 사용해서 표현하게 되는 것이다.그러나 이 경우에 predictor 값의 양 극단 부분에서는 분산이 매우 커지게 되는 경우가 발생한다. 이를 방지하기 위해서 ‘natural spline’이 등장하는데 양 극단 데이터에 대한 추가적인 가정을 부여하는 것이다. 단, 조건은 함수가 양 극단에서 linear 해야한다는 것. natural spline으로 인해 자유도는 기존의 cubic spline에 비해 4만큼 빠짐7.4.4 Choosing the Number and Locations of the Knots(1) location함수가 급격하게 변할것 같은 부분을 연구자가 선택?자유도를 연구자가 정한 뒤에 소프트웨어에 의해 uniform 하게 선택?(2) number가장 좋아보이는 curve를 그리는 knot의 개수를 선택?CV의 결과 RSS가 가장 낮은 K를 선택7.4.5 Comparison to Polynomial Regressionpolynomial은 flexible fit을 위해 degree(자유도, 차수)를 높여야 하는데 spline은 차수를 정해놓고, knot를 바꿔가면서 flexibility를 달성할 수 있다. 또한 함수 전체가 아닌 일부의 필요한 부분에 flexibility를 높이니까 훨씬 적합이 잘 된다. 추정량도 안정적이다. 특히 flexibility를 과하게 주면 데이터의 양 극단 부분에서 적합이 잘 안되고 분산이 매우 커지는데, natural spline의 경우 이 또한 방지 가능하다.7.5 Smoothing Splines7.5.1 An Overview of Smoothing Splinesspline regression은 knot와 basis function을 결정해서 LSE로 계수를 추정하는 것이었다면 smoothing spline은 좋은 fitting을 위해 RSS를 줄이는 것에 기반한다. 단지 RSS만을 줄이는 것이 아니라 smoothness를 고려한다. 즉 아래의 식을 최소로 하는 g function을 찾고자 한다.$\\sum (y_i - g(x_i))^2 + \\lambda\\int g’‘(t)^2dt$이는 smoothness를 주기 위해서 penalty 항을 부여하는 것이다. 이를 좀 더 자세히 설명하면 \\(g&#39;&#39;(x)\\)함수는 roughness에 대한 measure로 기울기의 변화율이다. 이를 적분해서 \\(g&#39;(x)\\)에 대한 total change를 평가한 것이 \\(\\int g&#39;&#39;(t)^2\\)이 되는 것이다.또한,Ridge, Lasso와 비슷하게 tuning parameter lambda를 가지고 bias - variance trade-off 를 조절할 수 있다. 즉 natural cubic spline의 shrunken version이 smoothing spline 이라 할 수 있다.7.5.2 Choosing the Smoothing Parameter lambda모든 unique 값인 x_i에 대해 knot를 잡고 natural cubic spline을 하면 그것이 smoothing spline이 된다.(왜냐면 rss를 줄이고자 하는것이니까 모든 x_i에 대해 knot를 주는 것과 같다!) 그러나 모든 데이터에 대해 knot을 주면 자유도가 커진다. 여기서 lambda값을 통해 자유도를 control 하는 것이다.smoothing spline에서는 knot의 개수나 위치를 따로 구할 필요가 없다. 계산에 의해 알아서 해주니까. 단, 여기서는 tuninig parameter인 lambda 값을 정해야 한다. lambda값은 커지면 모델의 flexibility가 줄어드는데 이 값과 반대의 역할을 가지는 parameter로 effective degree of freedom\\(df_\\lambda\\) 가 있다. smoothing spline에서는 모든 데이터에 대해 knot를 주고 lambda로 variance를 조절하기 때문에 effective degree of freedom으로 자유도(분산과 관련있는 것)를 판단한다.이 값을 구하는 공식은 아래와 같다. smoothing spline을 적합한 fitted value를 벡터로 표현한 것이 \\(\\hat g_\\lambda = S_\\lambda y\\)라고 할 때 \\(df_\\lambda = trace(S_\\lambda)\\)적당한 lambda 값은 어떻게 구할 것인가? CV를 이용.특히 LOOCV 같은 경우 계산이 쉽다.==&amp;gt;\\(RSS_{cv}(\\lambda) = \\sum(y_i - \\hat g_\\lambda^{(-i)}(x_i))^2 = \\sum [\\frac {y_i - \\hat g_\\lambda(x_i)}{1-\\{ \\ S_\\lambda \\}_{ii}}]^2\\)7.6 Local Regression알고리즘은 다음과 같다각 값에 대한 예측치를 주변 값을 이용해 하나하나 찾아가는 게 특징이다. (KNN과 유사)KNN에서 K 값을 어떻게 정할지가 중요한 것 처럼 여기서도 s 값을 어떻게 정할지 결정해야 하는데 일반적으로는 CV를 통해서 정한다. s의 값이 작으면 fitting이 보다 local에 맞춰질 것이다(wiggly)거리에 따라 weight를 주고 난 뒤에는 weighted least square를 통해 예측값을 정한다.또한 여러가지 변수를 종합적으로 보고 거리에 포함시킬지 말지 정할 수도 있는데 변수 개수가 너무 많은 경우, training에 필요한 변수가 적어 오버피팅 발생 가능.7.7 Generalized Additive Models가법성(additivity)을 유지하면서 선형 모델을 비선형 모델으로 확장. 반응변수가 양적 혹은 질적 변수인 경우 모두 사용 가능.7.7.1 GAMs for Regression Problems7.1-7.6에서는 하나의 변수에 대해 fitting function을 다르게 주는 법을 공부했다.GAMs 의 특징은 “we can use these(7.1-7.6) methods as building blocks for fitting an additive model”$y_i = \\beta_0 + \\sum_j f_j(x_{ij}) + \\epsilon_i$즉 각 변수마다 spline, local regression, polynomial 등등을 사용한 뒤 이를 가법모형으로 만들어 합치는 방식으로 모형을 fitting 하는 것.pros and cons장점 :(1) 모델을 쌓을 때 비선형 모델을 추가할 수 있기 때문에 선형모델이라는 제약에서 쉽게 벗어날 수 있고, 따로 변수를 변환해주는 등의 노력이 필요 없다.(2) 비선형 모델이 들어가기 때문에 fitting이 더 잘될 것(3) 가법 모형이기 때문에 나머지 변수를 고정한 채로 하나의 변수의 영향력을 알 수 있다. 그러니까 모델의 해석력이 좋을 것.(4) smoothness도 포함 가능단점:(1) 이름에서도 알 수 있듯, ‘가법’이라는 것에 모형을 한정시킨다. 따라서 변수간의 interaction이 포함되지 못한다. 그러나 애초에 변수 자체에 interaction을 포함시키고 이를 가법으로 쌓으면 앞의 문제를 상쇄 할 수 있다.GAMs는 linear 모형과 더 flexible한 모형인 RF, Boosting의 compromise7.7.2 GAMs for Classification Problems로지스틱 회귀를 예로 들면$log(\\frac {p(X)}{1-p(X)}) = \\beta_0 + \\sum_j f_j(x_{j}) $와 같이 적합된 모델을 쌓아서 분류한다." }, { "title": "ISLR - LAB6", "url": "/posts/ISLR6-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-05 00:00:00 +0900", "snippet": "6장 코드 정리## Best Subset Selectionlibrary(ISLR)fix(Hitters)sum(is.na(Hitters$Salary))Hitters = na.omit(Hitters) # 변수에 missing variable 이 존재하는 경우 이를 삭제sum(is.na(Hitters)) # 0#regsubsets 명령어를 사용해서 best subset 구하기 #best의 기준은 가장 작은 RSSlibrary(leaps)regfit.full = regsubsets(Salary~.,data=Hitters)summary(regfit.full)regfit.full = regsubsets(Salary~.,data=Hitters, nvmax = 19) #nvmax 명령어는 뽑고싶은 최대 변수 개수를 나타낸다.reg.summary = summary(regfit.full)reg.summary$rsqreg.summary$adjr2par(mfrow=c(1,1))plot(reg.summary$rss, xlab= &quot;varibale number&quot;, ylab= &quot;RSS&quot;, type=&#39;l&#39; ) #type 에 영어 l 을 붙이면 점들을 연결한 선이 그려진다. plot(reg.summary$adjr2, xlab= &quot;varibale number&quot;, ylab= &quot;ADJR2&quot; )which.max(reg.summary$adjr2) #언제 최대가 될까?points(11, reg.summary$adjr2[11],col=&#39;red&#39;, cex=2, pch=20)#점찍기#regsubsets()는 내장함수로 plot을 가지고 있음. 각 scale 별로 최적의 변수 조합을 보여준다.plot(regfit.full, scale=&quot;r2&quot;)plot(regfit.full, scale=&#39;adjr2&#39;)plot(regfit.full, scale=&#39;Cp&#39;)plot(regfit.full, scale=&#39;bic&#39;)coef(regfit.full,6) #변수가 6개일 때 RSS 기준 best인 변수들을 추출 ## Forward and Backward STepwise Selectionregfit.fwd = regsubsets(Salary~.,data=Hitters, nvmax = 19, method = &quot;forward&quot;) #nvmax 명령어는 뽑고싶은 최대 변수 개수를 나타낸다.#backward로 하고 싶으면 method = &quot;backward&quot;## validation set approach vs CV#train / test 만들기 위해 임의로 index 나눠주기set.seed(1)train = sample(c(TRUE, FALSE), nrow(Hitters), rep=TRUE)test = (!train)regfit.best = regsubsets(Salary~., data=Hitters[train,], nvmax=19)#model.matrix를 사용해서 test data 를 matrix로 만들기test.mat = model.matrix(Salary~.,data=Hitters[test,])#각 변수 개수 별로 MSE 값 보이기val.errors = rep(NA,19)for (i in 1:19){ coefi = coef(regfit.best, id=i) pred = test.mat[,names(coefi)] %*% coefi val.errors[i] = mean((Hitters$Salary[test]-pred)^2)}val.errorswhich.min(val.errors)coef(regfit.best, 7)#K-fold, k=10k=10set.seed(1)folds = sample(1:k, nrow(Hitters),replace=TRUE)cv.errors = matrix(NA,k,19, dimnames=list(NULL, paste(1:19)))#predict 메소드 만들기predict = function(obj, newdata, id,...){ form = as.formula(obj$call[[2]]) mat= model.matrix(form, newdata) coefi = coef(obj, id=id) xvars = names(coefi) mat[,xvars] %*% coefi}#j : 몇번째 fold 인지, i : 변수의 개수가 몇개인지for (j in 1:k){ best.fit = regsubsets(Salary~., data=Hitters[folds !=j,],nvmax=19) for(i in 1:19){ pred = predict(best.fit, Hitters[folds ==j,], id=i) cv.errors[j,i] = mean((Hitters$Salary[folds==j]-pred)^2) }}#cv.errors 함수를 열별로 평균 구하기mean.cv.errors = apply(cv.errors, 2, mean) #1 : 행단위 연산, 2 : 열단위 연산 par(mfrow=c(1,1))plot(mean.cv.errors, type=&#39;b&#39;)which.min(mean.cv.errors)rm(list = ls())##Ridge // glmnet의 alpha=0library(ISLR)fix(Hitters)sum(is.na(Hitters$Salary))Hitters = na.omit(Hitters) # 변수에 missing variable 이 존재하는 경우 이를 삭제sum(is.na(Hitters)) # 0x = model.matrix(Salary~., Hitters)[,-1] #model.matrix 는 계산을 위한 행렬을 만들어주며, 특히 질적 변수를 더미화 시켜주는 기능까지 있다.y = Hitters$Salarylibrary(glmnet)grid = 10^(seq(10,-2,length=100))ridge.mod = glmnet(x,y, alpha=0, lambda = grid) #glmnet은 표준화 과정이 들어가있음.ridge.mod$lambda[50]coef(ridge.mod)[,50]predict(ridge.mod, s=50, type=&#39;coefficients&#39;)[1:20,] set.seed(1)train = sample(1:nrow(x), nrow(x)/2)test = (-train)y.test = y[test]ridge.mod = glmnet(x[train, ], y[train],alpha=0, lambda=grid, thresh=1e-12)ridge.pred = predict(ridge.mod, s=4, newx=x[test, ]) #cv.glm으로 lambda 값 구하기set.seed(1)cv.out = cv.glmnet(x[train, ], y[train], alpha=0)plot(cv.out)bestlambda = cv.out$lambda.minbestlambda#가장 작은 mse를 가지는 lambda를 가지고 예측해보기out = glmnet(x,y,alpha=0)predict(out, type=&quot;coefficients&quot;, s=bestlambda)[1:20,] #여기 [1:20,] 은 predict메소드에서 나오는 결과값 중 20개를 리스트로 뽑아내느 것.##lasso는 glmnet의 인자 alpha=1 을 주면 된다.##PCRlibrary(pls)set.seed(2)pcr.fit=pcr(Salary~., data = Hitters, scale=TRUE, validation=&quot;CV&quot;) #scale=true 는 standardizing.summary(pcr.fit)validationplot(pcr.fit, val.type=&#39;MSEP&#39;)#train / valdiationset.seed(1)pcr.fit=pcr(Salary~., data = Hitters, subset = train, scale=TRUE, validation=&quot;CV&quot;) #scale=true 는 standardizing.validationplot(pcr.fit, val.type=&#39;MSEP&#39;)pcr.pred = predict(pcr.fit, x[test,], ncomp=7)mean((pcr.pred-y.test)^2)##parital least square#pcr 대신 plsr 로 함수를 바꾸면 나머지는 pcr 과 같다.set.seed(1)pls.fit = plsr(Salary~., data=Hitters, subset=train, scale=TRUE, validation=&#39;CV&#39;)validationplot(pls.fit, val.type=&quot;MSEP&quot;)pls.pred = predict(pls.fit, x[test], ncomp=2)" }, { "title": "ISLR chap 6", "url": "/posts/ISLR6/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-04 00:00:00 +0900", "snippet": "6. Linear Model Selection and Regularization6.1 Subset Selectioninference(모델의 해석력, 직관성)이 좋은 선형모델을 다른 방식으로 fitting 할 수는 없을까?(1) subset selectiondomain 지식, 혹은 계수에 대한 유의성 검정 결과 등으로 불필요한 변수를 제거 할 수 있을 것이다.(2) shrinkage특정 변수에 대한 회귀계수를 0에 가깝게 만들어줌으로써, 분산을 줄일 수 있고 특히 Lasso는 아예 계수값을 0으로 만들어 변수 선택과 같은 효과를 가져오게 한다.(3) dimension reduction(p –&amp;gt; m)p개의 변수를 m개의 linear combination으로 표현한다든지, 혹은 projection을 통해서 변수의 개수를 m개로 줄여 이를 이용해 최소제곱법으로 모형 적합.다른 방식으로 얻을 수 있는 것은?(1) prediction accuracy선형모형은 데이터셋이 많고, true 모형이 선형일 때에 뛰어난 성능을 발휘. but 그렇지 않은 경우 선형모형에 적합을 시키면 과적합이 발생. 이를 방지하기 위해, 회귀 계수에 constraining or shrinkage를 줌으로써 예측 성능을 높일 수 있다.(2) 필요없는 변수의 계수 값을 0으로 만들어줌으로써 모델의 복잡성을 줄이고 해석력을 높일 수 있다.6.1.1 Best Subset Selectionp개 변수(여기서 p가 연속형 변수)인 경우 \\(2^p\\)번 모형을 적합시켜서 최고의 모델을 선택하기. 그런데 p가 크면 모형 개수가 너무 많아진다.알고리즘은 아래와 같다.핵심은 각 변수 개수 별로 최고의 모델을 찾은 다음에(기준 RSS, R-square ※ 이 기준은 변수 개수가 같을 때 쓰는 것이다. 변수가 증가하면 R-square는 필연적으로 증가하기 때문에 변수 개수가 동일 할 때 선택 기준 ), 그 중에서 예측력이 좋은, 즉 cross-validated prediction error, mallow-cp, AIC, BIC, adjusted R-square 가 높은 모델을 선택.6.1.2. Stepwise Selection단순한 forward, backward와는 조금 다르다forward stepwise selection을 가지고 설명하자면,변수가 없는 초기모델에서변수가 하나만 있는 모델에서 RSS나 R-square 가 제일 나은 모델을 선택하고그 모델을 기준으로 또 변수를 하나 더 추가해서 그 중 RSS나 R-square 가 제일 나은 모델을 선택이 과정을 반복해서 변수의 개수 별로 최적 모델을 찾은 다음에 그 중 예측력이 좋은, 즉 cross-validated prediction error, mallow-cp, AIC, BIC, adjusted R-square 가 높은 모델을 선택.backward stepwise selection은 그 반대subset selection method 보다 계산량이 줄어든다. 그러나 첫번째 선택한 변수를 기반으로 다음 변수가 선택되기 때문에 최적의 모델(변수)를 찾지 못할 수도 있다.또한 forward 방법은 backward와 다르게 high dimension(n&amp;lt;p)에서도 적용 가능하다.이를 섞어놓은 hybrid approach도 존재6.1.3 Choosing the Optimal Model(1) indirectly estimate test error by making an adjustment to the training error to account for biasC_p$C_p = \\frac {1}{n}(RSS + 2p \\hat \\sigma^2)$p는 변수의 개수를 의미뒷 항이 변수의 개수에 대한 penalty를 주는 것으로 변수의 개수가 많아지면 뒷 항은 커진다. 그리고 C_p 값은 작아야 좋으며 분산 추정량 sigma^2는 불편추정량이므로 C_p는 test MSE에 대한 불편추정량이다.$mallow’s \\ c_p = RSS/\\hat \\sigma^2 + 2p -n \\ =\\ \\hat \\sigma^2(C_p + n) $AICmaximum likelihood를 사용해서 적합성을 설명.$AIC = \\frac {1}{n\\hat \\sigma^2}(RSS + 2p\\hat\\sigma^2)$식에서도 알 수 있듯, C_p와 비례하기 때문에 설명 생략BIC베이지안 관점$BIC = \\frac {1}{n} (RSS + log(n)p\\hat\\sigma^2)$C_p 와의 차이는 n의 크기가 커질수록, 즉 데이터 개수가 많아질 수록 변수 개수에 대한 penalty를 더욱 크게 주는 것이다. 따라서 C_p에 비해서 더욱 변수 개수가 작은 모형을 선택하려고 할 것이다.※여기서는 선형모형의 최소제곱법을 기준으로 모형을 적합하기 때문에 RSS로 썼는데 AIC, BIC의 일반적인 수식은 아래와 같다$-2 logL + kp,\\ \\ L \\ is\\ likelihood$AIC는 k=2, BIC는 k=log(n)adjusted R-square$Adjusted \\ R^2 \\ = \\ 1 - \\frac {RSS/(n-p-1)}{TSS / (n-1)}$앞서 본 C_p, AIC, BIC와는 다르게 adjusted R-square는 큰 값일 수록 모형적합 및 예측이 뛰어난 것이다.(2) directly estimate the test error using validation set or CV따로 가정이 필요없고 test error rate을 직접 추론한다. 과거에는 대용량의 계산이 어려워서 C_p, AIC, BIC 등을 사용했지만, 컴퓨팅 기술이 발달한 현재 CV가 모델 선택에 있어 훨씬 좋다.앞 장에서도 설명했듯, CV, Validation set error 는 valid set을 어떻게 설정하는지에 따라 test mse 값이 바뀔 수 있다. 즉 test mse를 최소로 하는 변수의 개수 또한 바뀔 수 있다. 그럼 변수 개수를 어떻게 해야 최적의 모델을 고를 수 있을까? 이때는 one-standard-error라는 조건으로 모형을 결정한다.아래 그림은 CMU-STAT 383C - Statistical Modeling 1 Lecture 9 강의노트에서 캡쳐해온 것이다즉 CV의 결과로 변수 개수에 따른 test error rate을 구했다고 하자. 이 때 error를 최소로 하는 값에 대한 1 standard error 범위에 속한 모델(변수 개수) 중 가장 단순한 모델(변수 개수가 가장 작은 모델)을 선택한다.6.2 Shrinkage Methods분산을 줄여준다!6.2.1 Ridge Regressiontuning parameter lambda를 사용해서\\(\\sum (y_i - X\\beta)^2 + \\lambda\\sum\\beta_j^2\\)를 minimize 하는 \\(\\hat \\beta ^R\\)를 추정하는 것.penalty 항이 존재해서 RSS를 계속해서 줄여나가지 않고 penalty 값을 줄여나가려고 한다.tuning parameter lambda는 penalty항의 크기를 결정함으로서 계수 추정값을 변화시키는데그 값이 커지면서 규제(regulation)의 효과가 커지고 계수 추정량이 0에 가까워 질 것이다. 따라서 lambda값을 적절히 설정하는 것이 중요하다.또한 predictor 값이 모두 0일 때의 response를 나타내는 intercept Beta_0는 shrinkage에 영향을 받지 않으며 만약 데이터들이 centered 된다면 절편 추정량은 response의 표본평균이 될 것이다.그림에서 보듯 적절한 lambda 값을 통해 규제를 주면 전혀 불필요한 변수들에 대한 계수값이 0이 되면서 분산이 줄어들고 fit도 더 잘되어 MSE가 줄어들 수 있다. 특히 \\(X&#39;X\\)에 대한 가장 큰 고유벡터 방향이 회귀 계수 beta 값과 일치한다면 MSE의 향상이 더 좋을 것이다. (몽고메리 부분 참고)또한 ridge에 의해 회귀계수가 축소가 되기 때문에 ridge 이전에 변수들의 scaling을 조절하는 것이 중요하다. 그렇지 않으면 (scale과 lambda값 둘 다에 영향을 받게 되어 오류가 생길 수 있음)그렇다면 왜 Ridge regression이 least square 보다 좋은 것일까?==&amp;gt; bias - variance trade offvariance를 크게 줄임으로서 test MSE를 줄일 수 있다.분산이 커지는 두가지 케이스(1) predictor와 response가 서로 선형이라면 이들 관계는 특정한 값에 의해 크게 바뀔 수 있다. 즉 분산이 커질 우려가 있다. (2) 또한 high dimension (p&amp;gt;n) 인 경우 least square 계수 추정량은 유일하지 않다.이 때 ridge regression을 사용하면 분산을 안정화시킬 수 있다.또한 변수 선택의 관점에서도 ridge를 사용하면 best subset을 하나하나 찾는것 보다 훨씬 비용이 절감되고 계산량이 줄어든다.6.2.2 The LassoRidge 의 단점은 모든 변수가 모형에 들어간다는 것이다. 그것의 계수가 비록 매우 작은 값일지라도…. 따라서 예측의 문제보다는 모형 자체의 해석을 할 때 단순하게 만들어진 모델에 비해 복잡할 것이다. 이러한 점을 고려해서 Lasso regresssion이 나오게 되었다.$\\sum (y_i - X\\beta)^2 + \\lambda\\sum|\\beta_j|$Lasso 는 계수값을 완전히 0으로 만드는데 이는 variable selection의 일종이라 볼 수도 있으며, Ridge에 비해 모델 해석이 쉽다(model interpretation , inference)또한 ridge 처럼 lambda값을 잘 구하는 것이 중요한데, 이에 대한 것은 6.2.3에서 설명하도록 하겠다.Another Formulation for Ridge and Lasso라그랑주를 사용해서 다음과 같이 표현할 수 있다.$minimize \\ \\sum (y_i - X\\beta)^2 \\ \\ \\ subject \\ \\ to \\ \\ \\sum\\beta_j^2 \\leq s$$minimize \\ \\sum (y_i - X\\beta)^2 \\ \\ \\ subject \\ \\ to \\ \\ \\sum|\\beta_j| \\leq s$이러한 방식으로 best subset selection 방식도 표현 가능한데, 단 계산량이 너무 많아서 ridge 나 lasso가 좋고, 변수 선택에 입장에서는 ridge 보다는 lasso 가 더 좋은 역할을 하게 된다.$minimize \\ \\sum (y_i - X\\beta)^2 \\ \\ \\ subject \\ \\ to \\ \\ \\sum I(\\beta_j \\neq 0) \\leq s$Variable Selection Property of the Lasso어떻게 Lasso는 계수값을 정확히 0으로 만드는 것일까? 아래 그림을 보자그림에서 보면 알 수 있듯 lasso 의 경우 코너해에서 회귀계수가 결정되는 양상을 보인다.comparing Lasso and Ridge해석력의 관점에서는 lasso가 좋다 (변수 자체가 작아지니까) 그럼 prediction 관점에서는??ridge나 lasso 모두 lambda 값에 의해 bias-variance trade-off 관계가 발생하고 lambda 값이 커지면서 분산이 안정화 된다. 다만 어떤 방식이 더 낮은 test error rate을 가질지는 데이터의 형태에 따라 다르고 변수의 개수에 따라서도 다르다.일반적으로 계수값의 편차가 큰 경우에는 Lasso가 그렇지 않은 경우에는 Ridge가 더 좋은 prediction을 갖는다.Bayesian Interpretation for Ridge and Lassobayes’ theorem 그대로 이용해서 posterior의 mode값을 계수 추정량으로 선택$P(\\beta | X, Y) \\propto f(Y|X, \\beta ) P(\\beta) $likelihood는 선형모델로 고정, epsilon은 iid 성질을 가진 normal$Y = X\\beta + \\epsilon$prior는 $P(\\beta) = \\prod g(\\beta_j)$이 때ridge는 g가 Gaussian with mean zero and standard deviation a function of lambda.lasso는 g가 Double-Exponential with mean zero and scale parameter a function of lambda6.2.3 Choosing the Tuning Parameterlambda를 어떻게 설정할 것인가?==&amp;gt; grid search. 후보를 정해놓고 cross-validation 결과 나온 error 값 중 가장 낮은 error를 갖는 lambda를 선택한다.6.3 Dimension Reduction Methods앞에서 분산을 줄이는 과정으로 predictor의 subset을 선택한다던지, ridge 혹은 lasso를 하는 방식을 설명했다. 여기에서는 적합시키는 predictor 자체를 바꾸는 방법을 설명하겠다.기본 틀은 다음과 같다(1) 기존 확률변수\\(X_1, X_2, ... , X_p\\)에 대해서 M&amp;lt;p 인 M개의\\(Z_1, Z_2, ...,Z_M\\)변수를 X들의 linear combination으로 만들어 낸다$Z_m = \\sum_{j=1} ^p \\phi_{jm}X_j$(2) 이제 확률변수 Z를 가지고 적합을 한다. lienar 모델인 경우\\(y_i = \\theta_0 + \\sum_{m=1} ^M \\theta_m Z_{im} + \\epsilon_i, \\ \\ \\ \\ \\ \\ i=1,2,...,n\\)(3) phi 값을 어떻게 설정할 것인지에 대해서는 두가지 방법이 존재한다. (6.3.1 / 6.3.2)6.3.1 Principal Components Regression가장 큰 분산을 가지는 green line : the first principal component수식을 통해 좀 더 자세히 살펴보자.formula :$Z_1 = \\phi_1 \\times(X_1-\\bar X_1) + \\phi_2 \\times(X_2-\\bar X_2)$여기서 Z 값이 principal component score이며 Z_1의 분산이 가장 크다.또한 ,이 때 \\(\\phi\\)값은 principal component loading이며 \\(\\sum \\phi_i^2 = 1\\)이라는 성질을 갖는다.(이러한 제약이 없다면 임의로 분산을 마구 키울 수 있기 때문)PCA에 대한 또 다른 해석으로는 첫번째 PC가 sum of the squared perpendicular distance를 최소화 하는 line이라는 것이다. 즉 데이터와 가능한 가장 가까운 직선을 긋는 것이라 볼 수 있다.Principal Components Regression Approach아마 PCA를 공부하면서도 가장 중요한 문장이 나온다“The key idea is that often a small number of principal components suffice to explain most of the variability in the data”즉 분산이 큰 방향을 축으로 데이터를 사영시켰을 때 나오는 principal component 몇개를 가지고 데이터를 충분히 설명할 수 있다면 이를 변수로 삼아 Y와의 관계를 찾을 때 fitting이 더 좋다는 것이다.(변수 개수가 작으니까 당연히 오버피팅도 막을 수 있고) (단, PCA를 통해 차원의 축소가 잘 안된다면 그냥 원래 데이터를 가지고 ridge나 lasso를 하는 것이 훨씬 fitting이 잘 될수 있다.)pca를 통해 축소가 잘 안되는 경우? 데이터의 변수가 원래 작아서 각각이 모두 의미를 담고 있는 경우참고 : PCR은 Ridge regression과 매우 유사하며 Ridge가 PCR의 연장선상에 있다고도 볼 수 있다how to find the number of principal componentsPCR에서 적절한 변수의 개수는 어떻게 찾을 것인가.Principal component score 들은 크기에 따라 순차적으로 정해지고 PC line은 서로 직교하게 만들어진다. 그런데 만약 다음 score 값이 거의 0에 근사한다는 것은 이전의 principal component를 가지고 데이터를 충분히 설명가능하다는 말이다.그러나 이는 다소 모호하다확실한 기준을 위해선 CV를 통해서 test mse를 최소로 하는 변수 개수를 선택하면 될 것이다.final checkPCR은 데이터의 분산을 다루는 것이므로 scale에 민감하다. 따라서 PCR을 수행하기 전에는 반드시 데이터들을 정규화해주어야 한다!6.3.2 Partial Least SquaresPCR은 PC direction을 찾는 데에 Y(target) 값을 전혀 이용하지 않는다. un-supervised way따라서 PCR을 하면서 찾은 best direction이 실제로 best가 아닐 수 있다.==&amp;gt; Y를 고려해서 차원을 축소하는 지도학습법 partial least square가 등장.요약 : PLS를 통해서 response와 predictor를 동시에 설명하는 direction을 찾자!step 1PCR과 마찬가지로 표준화를 먼저 한다. 단 PLS는 response 를 같이 고려하기 때문에 response variable 또한 표준화 해줘야 한다.step 2simple linear regression Y onto X_i ( i = 1,2, … , p) 에서 나온 각 변수들에 대한 계수 값(phi)을 가지고 새로운 변수 Z_1을 만들어 낸다. 즉,$Z_1 = \\sum \\phi_iX_i$이렇게 하면 Y와 큰 상관관계를 가지는 변수에 대해 큰 weight를 줄 수 있다.step 3second PLS direction을 만들기 위해 simple linear regression X_i onto Z_1여기서 나온 잔차들은 각 변수들에서 Z_1이 설명하지 못하는 부분이다. 이 residual을 다시 X와 simple linear regression 해서 나오는 계수를 가지고 Z_2를 만든다. 이 과정을 반복한다.step 4차원을 얼마나 축소할 수 있을까? CV를 사용해라.6.4 Considerations in High Dimensions6.4.1 High-Dimensional Data다양한 정보를 얻게 되면서 데이터 분석에서 이용되는 feature가 많아졌다. n보다 p가 더 큰 경우 오버피팅의 문제가 발생한다.6.4.2 What Goes Wrong in High Dimensions?overfitting ==&amp;gt; 예측력이 떨어짐예측력의 평가지표인 C_p, AIC, BIC 등을 계산하는 데에 문제가 있음. 왜? error의 분산인 sigma 값을 추정하기 어렵기 때문에.adjusted R-square 또한 계산이 어려움. high dimension인 경우 과적합 발생으로 R-square가 1일수도 있기 때문6.4.3 Regression in High Dimensions변수선택이나 차원 축소를 통해서 high dimension 문제를 해결할 수 있다.차원의 저주? 흔히 feature를 많이 넣으면 fitting의 결과도 좋을 것이라 생각한다. 이것은 일부는 맞다. target과 관련이 큰 feature를 집어넣으면 그리고 이 데이터들의 noise가 작다면 성능이 좋아질 수 있다. 그러나 만일 추가된 feature가 noise가 많아 target과 큰 관계를 보여주지 않는다면, 그래서 기존의 데이터 개수만으로는 충분히 관계를 찾아낼 수 없다면 모델의 성능은 더욱 악화될 것이다.또한 좋은 feature라고 할지라도 bias 감소보다 그에 따른 분산의 증가가 더 클수도 있기 때문에 이를 항상 고려해야한다.6.4.4 Interpreting Results in High Dimensionshigh dimensions 에서는 multicollinearity 의 문제도 피할 수 없다.변수선택으로 얻은 모델을 과신하지말고 다른 좋은 모델은 없는지 검증해보아야 한다.모델 평가 측도로 overfitting에 취약한 SSE(sum of squared error), p-values, R-squared 들을 선택해서는 안된다. test data 에 대한 예측력은 장담할 수 없기 때문." }, { "title": "ISLR - LAB5", "url": "/posts/ISLR5-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-03 00:00:00 +0900", "snippet": "5장 실습 코드 입니다.library(ISLR)## Validation set approachset.seed(1)train = sample(392, 196) # 392까지의 숫자 중에서 196개를 뽑음 (여기서 392는 Auto data의 행이 392개 이기 때문)?samplelm.fit = lm(mpg ~ horsepower, data=Auto, subset=train)attach(Auto)mean((mpg-predict(lm.fit, Auto))[-train]^2) #trian에 사용된 데이터를 제외하고 validation set으로 test mse 추정하기dim(Auto)lm.fit2 = lm(mpg ~ poly(horsepower,2), data=Auto, subset = train)mean((mpg-predict(lm.fit2, Auto))[-train]^2)##LOOCVglm.fit = glm(mpg~horsepower,data=Auto) # family=&quot;binomial&quot; 없으면 glm 명령어도 lm처럼 쓰임coef(glm.fit)#cv.glmlibrary(boot)cv.err = cv.glm(Auto, glm.fit)cv.err$delta #여기서 나오는 값이 LOOCV 값 (LOOCV의 경우 delta의 두가지 값 동일. 단, K-Fold 인 경우 두 값이 서로 다르고 두 번째 나오는 값이 bias corrected version)#모형마다 LOOCV를 계산하고 싶다면?cv.error = rep(0,5)for (i in 1:5){ glm.fit=glm(mpg~poly(horsepower, i), data=Auto) cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]}cv.error# 24.23151 19.24821 19.33498 19.42443 19.03321 =&amp;gt; sharp drop in the estimated test MSE between linear and quadratic## K-Fold Cross-Validation#LOOCV와 코드는 비슷한데 단지 cv.glm 안에 K=k 인자를 추가해주기만 하면 된다.set.seed(7)cv.error.10 = rep(0,10)for (i in 1:10){ glm.fit = glm(mpg~poly(horsepower,i), data=Auto) cv.error.10[i] = cv.glm(Auto, glm.fit, K=10)$delta[1]}cv.error.10##Bootstraping#bootstraping 코드 만들기alpha.fn = function(data, index){ X=data$X[index] Y = data$Y[index] return ((var(Y)-cov(X,Y))/(var(X)+ var(Y) -2*cov(X,Y)))}alpha.fn(Portfolio, 1:100)set.seed(1)alpha.fn(Portfolio, sample(100,100, replace=T)) # 샘플을 1~100에서 100개를 복원추출#위의 과정을 모두 생략하고 boot 명령을 통해 손쉽게 구할 수 있다.boot(Portfolio, alpha.fn, R = 1000) #여기서 R 은 붓스트랩 추정량의 개수 " }, { "title": "Kernel with PRML", "url": "/posts/Kernel/", "categories": "", "tags": "datascience, datamining, machinelearning, PRML, Pettern Recognition and Machine Learning", "date": "2021-08-02 00:00:00 +0900", "snippet": "Kernel 에 관해 언제 한번 전체적으로 정리해보고자 했는데, PRML에 나오는 kernel에 관련한 부분들을 종합적으로 정리해보고자 한다. 큰 목차들은 모두 PRML을 참고해서 하도록 하겠다.2.5 Nonparametric Methodsparametric method는 가정한 모델이 잘못될 경우, 예측의 문제에 있어서 매우 안좋은 결과를 가져올 것이다. 모형 가정이 거의 없는 non-parametric methods 로 히스토그램을 활용한 분포 추정에 대해 우선 살펴보자.(1) partition X into distinct bins of width$\\Delta_i$(2) count the numbr$n_i$in bin i th(3) total number N(4) normalized probability values for each bin$p_i = \\frac {n_i}{N \\Delta_i} , \\ \\int p(x)dx= 1$그림에서 보듯 델타의 값이 커질 수록 smoothing의 효과가 크다. 너무 커지면 분포를 제대로 잡아내지 못할 것.histogram의 장점 :(1) 히스토그램이 만들어지면 원래의 데이터만큼 세세한 사항들이 소실되어 버림. 그러나 데이터가 매우 크다면 이를 직관적으로 보여주는 좋은 그림이 됨(2) 시계열 데이터의 경우 적용이 쉽다(?)histogram의 단점 :(1) 히스토그램으로 변형시 데이터의 연속성이 사라질 수 있다. bin 경계의 불연속성(2) 변수(variable, predictor)가 많은 경우, 구간들이 많아지면서 데이터의 차원이 매우 커진다.이런 장 단점을 고려해 볼 때 histogram은특정 데이터의 주변 데이터를 함께 고려하려는 시도, 그리고 smoothing parameter에 대한 통제에 대한 insight를 주고 있다.2.5.1 Kernel Density Estimator(1) unknown probability density : p(x) : 추정 대상(2) small region : R(3)$P = \\int _R p(x)dx$(4) total data : N(5) total number of points that lie inside R : K$K \\sim B(N,P)$(＊) 여기서 N이 값이 매우 크다면 K 데이터는 대부분 평균값인 NP에 위치할 것즉 $K \\simeq NP$(＊＊) 추가적인 가정으로 R 이 매우 작다고 가정하자. 이 경우 R의 부피를 V 라고 하면, (3)으로부터,$P \\simeq p(x)V$(＊＊＊)두 가정을 종합하면$p(x) \\simeq \\frac {K}{NV}$위 식에 이제 주목해보자. N값은 이미 고정되어있고, V값을 가정하면 K의 값을 찾아야 p(x)를 찾을 수 있다. 이 때 K의 값을 찾는 방법으로 kernel function을 사용한다.kernel function$k(u) = \\begin{cases} 1 &amp;amp; |u_i|\\leq 1/2 \\ 0 &amp;amp; otherwise \\end{cases}$$K = \\sum k(\\frac {x-x_n} {h})$이를 다시 바꿔서 표현하면 (＊＊＊) 식을 이용해서$kernel \\ density \\ estimator :: p(x) = \\frac {1}{N} \\sum \\frac{1}{h^d} k(\\frac {x-x_n} {h})$h^d 는 V 대신 쓴 것.이렇게 커널함수를 사용해서 p(x)를 추론하면 histogram에서 발생하는 문제와 같이 인위적인 불연속점이 존재한다.smoother kernel function으로서는 가우시안 커널 function이 있다. h는 표준편차로 smoothing parameter로 쓰인다.kernel function의 성질은$k(u) \\geq 0 \\ , \\ \\int k(u) du =1$6장의 내용들은 이후에 추가적으로 적도록 하겠다." }, { "title": "ISLR chap 5", "url": "/posts/ISLR5/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-02 00:00:00 +0900", "snippet": "5. Resampling Methodsresampling 방법으로는 크게 두가지(1) Cross-Validation for estimating the test error ==&amp;gt; model assessment, model selection(2) Bootstraping ==&amp;gt; providing a measure of accuracy of a parameter estimate5.1 Cross-Validation6장에서 training error rate 을 조정해서 test error rate을 추정하기 위한 방법들을 배우지만 여기 5장에서는 train 데이터를 분리하는 방식으로 test error rate을 찾는 방법들을 공부할 것이다.5.1.1 The validation Set Approachvalidation set approach 장점 : random split을 통해 다양한 경우에서의 validation set mse를 볼 수 있다. 각 split 마다 동일한 추이가 나온다면 유용할 것validation set approach 단점 : split마다 변동성이 매우 심할 수도 있다. 각 split에 속한 일부 변수 때문에 valid error rate 이 과대 추정될 수도 있다.5.1.2 Leave-one-out Cross-Validation(LOOCV)용어 그대로 하나의 데이터를 제외하고 모두 training set으로 적합시킨다.$MSE_i = (y_i -\\hat y_i)^2$$CV_{(n)} = \\frac {1}{n} \\sum_i MSE_i$장점 :(1) 하나를 제외하고 모든 데이터를 적합시켰기 때문에 valid MSE가 far less biased.(2) 데이터를 split 하는 데서 no randomness =&amp;gt; 결과과 균일 / 동일단점 : n(데이터 개수) 가 매우 큰 경우에 반복을 계속 해야 한다그러나 이를 극복하기위한 계산법이 존재. least square linear or polynomial regression에서$CV_{(n)} = \\frac{1}{n} \\sum_i (\\frac {y_i - \\hat y_{(i)}}{1-h_i})^2$h_i 는 i 번째 데이터의 leverage 값으로 이 값이 클 수록 CV 값이 커질 것이다.5.1.3 K-Fold Cross-Validation$CV_{(K)} = \\frac {1}{K} \\sum_i MSE_i$LOOCV 보다 더 좋은 장점은(1) 계산 비용 감소(2) bias - variance trade - off결국 CV를 통해 알고싶은 것은 모형이 test set에 대해서도 어느정도의 일반성을 갖느냐 인데, LOOCV나 K-Fold 나 거의 유사하게 test mse를 가장 작게 해주는 구간이 비슷하다. 그럼 계산비용이 작은 CV가 더 좋지 않을까?5.1.4 Bias-Variance Trade-Off for K-Fold앞 5.1.3에서 살짝 나왔단 bias - variance trade off 이야기를 좀 더 이어나가 보자.계산 비용을 제외하고서라도 K-Fold 방법이 LOOCV 보다 test error rate을 더 잘 추정해준다.즉 K-Fold 는 LOOCV와 validation set approach의 중간점이라 할 수 있다. validation set approach는 적합에 사용되는 표본이 부족해서 test error rate을 과추정하게 될 수 있고, 반대로 LOOCV는 1개를 제외하고 모두 적합에 이용되기 때문에 unbiased의 장점이 있는데 이를 혼합시켜서 bias를 살짝 가지면서도 분산을 줄이는 것이 K-Fold 가 되는 것이다.그럼 LOOCV는 variance가 매우 큰 것인가? 그러할 수 있다. 왜냐하면 1개를 제외하고 모두 적합하는 과정을 n 번 반복하고 이를 평균 내어 error를 추정하기 때문에 각 error 간에 매우 큰 공분산이 생겨버리기 때문이다.5.1.5 Cross-Validation on Classification Problemserror의 척도만 다를 뿐 같다분류의 문제에서 LOOCV error rate은$CV_{(n)} = \\frac {1}{n} \\sum_i I(y_i \\neq \\hat y_i)$5.2 The Boostrap이전 글에서 boosstrap에 대해 다뤘기 때문에, 교재에 나온 그림 두개 첨부" }, { "title": "ISLR - LAB4", "url": "/posts/ISLR4-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-02 00:00:00 +0900", "snippet": "4장에서 배운 내용을 바탕으로 한 R 코드를 정리했습니다.library(ISLR)names(Smarket)dim(Smarket)cor(Smarket[,-9])attach(Smarket)plot(Volume)Smarket$Year#GLM // family = binomial 이 명령어 추가하는 것 이외에는 동일glm.fit = glm(Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial)summary(glm.fit)#train data를 가지고 예측하기glm.prob = predict(glm.fit, type =&#39;response&#39;) #response를 type으로 주면 로짓 말고 확률 값이 나온다.glm.prob[1:10]contrasts(Direction)#contrasts를 통해 볼 때 up 이 1 이므로 10개의 데이터는 대부분 up으로 분류될 것.#0 과 1을 실제값인 down와 up으로 코딩하기glm.pred = rep(&quot;Down&quot;, 1250) #down으로 크기가 1250인 벡터 만들어라glm.pred[glm.prob&amp;gt;.5] = &quot;Up&quot;#table 함수를 통해 예측값과 실제값을 한눈에 보기table(glm.pred, Direction)&quot;&quot;&quot; Directionglm.pred Down Up Down 145 141 Up 457 507&quot;&quot;&quot;#올바르게 분류될 확률mean(glm.pred==Direction) #0.52 -&amp;gt; train error rate 0.48은 너무 크다!#2005년도 class만 따로 추출해보기train=(Year&amp;lt;2005)Smarket.2005 = Smarket[!train,]dim(Smarket.2005)Direction.2005 = Direction[!train]glm.fit = glm(Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial, subset=train) #subset 인자를 통해 일부 데이터만 분석한다.glm.prob = predict(glm.fit, Smarket.2005, type = &#39;response&#39;)glm.pred = rep(&quot;Down&quot;, 252)glm.pred[glm.prob&amp;gt;.5]=&quot;Up&quot;table(glm.pred, Direction.2005)mean(glm.pred==Direction.2005) # 0.48 -&amp;gt; train error rate 0.52 오히려 더 나쁜 성능.#모델 안에 들어있는 변수들 중 유의하지 않은 변수들 때문에 성능이 안좋을 수 있으므로 이를 제거하고 다시 분석해보면 좋을 것이다. ##LDAlibrary(MASS)lda.fit = lda(Direction ~ Lag1+Lag2, data = Smarket, subset=train)lda.fit&quot;&quot;&quot;Call:lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)Prior probabilities of groups: Down Up 0.491984 0.508016 Group means: Lag1 Lag2Down 0.04279022 0.03389409Up -0.03954635 -0.03132544Coefficients of linear discriminants: LD1Lag1 -0.6420190Lag2 -0.5135293&quot;&quot;&quot;#위에서 Coefficients of linear discriminants 에 나오는 값으로 LDA decision rule이 결정된다# =&amp;gt;&amp;gt; 여기서는 -0.64 X lag1 -0.51 X lag2lda.pred = predict(lda.fit, Smarket.2005)names(lda.pred)#[1] &quot;class&quot; &quot;posterior&quot; &quot;x&quot;lda.class = lda.pred$classlda.pred$posterior#posterior 를 기준으로 class를 나눌 때 threshold를 다르게 줄 수 있다.up = lda.pred$posterior[,1]&amp;gt;0.8aa = rep(&quot;Down&quot;, 252)aa[up]=&quot;Up&quot;table(aa,Direction.2005)##QDA#LDA와 과정이 모두 같다. 단, fit 에 대한 summary에 coefficients of discriminat는 나오지 않는다. 즉 decision rule을 알기 어렵다.##KNNlibrary(class)train.x = cbind(Lag1, Lag2)[train,]test.x = cbind(Lag1, Lag2)[!train,]train.Direction = Direction[train]knn.pred = knn(train.x, test.x, train.Direction,k=3)table(knn.pred, Direction.2005)mean(knn.pred==Direction.2005)" }, { "title": "ISLR chap 4", "url": "/posts/ISLR4/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-08-01 00:00:00 +0900", "snippet": "4. Classification4.1 An Overview of Classification분류의 문제 또한 각 카테고리에 속할 확률값에 의존하는 것이기 때문에 회귀문제와 결코 다르지 않다.4.2 Why not Linear Regression?target 변수가 범주형 변수일 때 linear regression을 사용하면 coding에 따라 결과값이 크게 달라질 것이며 각 범주간 차이를 올바르게 인코딩하기도 어렵다.또한 binary variable 에 대해서 회귀식을 작성하면 prediction 값이 반드시 [0,1] 사이에 들어가지도 않는다. Y의 class가 세가지 이상인 경우에는 선형 회귀를 사용하기 위한 Y 값의 인코딩 또한 쉽지 않다.4.3 Logistic Regressionresponse variable이 binary 인 경우에 대해 사용 가능하다. 조건부 확률로 class를 결정하게 되는데, 그 기준은 연구자가 임의로 정할 수 있다. 즉 확률 0.1를 기준으로 0 or 1로 분류되도록 식을 만들 수 있다.4.3.1 The Logistic ModelP(X) 는 조건부확률$P(X) = \\frac {e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}$이를 다시 바꾸면$\\frac{P(X)}{1-P(X)} = e^{\\beta_0 + \\beta_1X}$또 바꾸면$log{\\frac{P(X)}{1-P(X)}} = {\\beta_0 + \\beta_1X}$여기서 좌변을 log-odds or logit. 즉 로지스틱 회귀에서 로짓은 X와 linear 한 관계를 가진다.(※ odds는 경마경기에서 배당을 할 때 주로 사용되는데 쉽게 말해서 “성공확률 / 실패확률” 을 의미한다)4.3.2 Estimating the Regression CoefficientsLSE 보다는 MLE로 추정한 회귀계수가 훨신 더 좋은 통계적 성질을 가지게 된다.비선형 모델에서도 MLE를 통한 추정이 가능하다로지스틱 회귀의 경우$l(\\beta_0, \\beta_1) = \\prod_{i : y_i=1} P(X_i) \\prod _ {j:y_j=0} (1-P(X_{j}))$적합 결과 계수 추정량과 standard error, Z-statistic 등을 얻을 수 있는데 여기서 Z-statistic이란 linear 모형에서의 t-statistic과 같이 계수의 유의성 검정 통계량을 의미한다.4.3.3 Making Predictions예측을 위해 변수 값을 집어넣고 나온 결과값(확률)에 따라 class를 결정한다. 또한 로지스틱회귀를 모형을 만들 때 사용되는 predictor가 반드시 quantitative 인 것은 아니다. qualitative predictor를 사용해서 로지스틱 회귀를 만들 수 있다. 예를 들어 Y 값이 A, B X 값이 C,D 라면 C or D 에 따른 A, B 확률을 로지스틱 회귀로 구할 수 있는 것이다.4.3.4 Multiple Logtistic Regression$log{\\frac{P(X)}{1-P(X)}} = {\\beta_0 + \\beta_1X_1 + … + \\beta_pX_p}$선형회귀와 마찬가지로 다중회귀에서도 변수간 영향(correlation)을 고려해야한다. 책에서 드는 예시를 살펴보자.우선 그림(figure 4.3 왼쪽) 과 같이 balance를 함께 고려한 로지스틱 회귀식은 orange line이 blue line보다 아래에 있다. 그러나 balance를 고려하지 않았을 때는 orange line이 보다 위에 있는 것을 볼 수 있다. 이는 동일한 변수에 대한 계수값의 부호가 바뀐 것이라 할 수 있다.만약 이 데이터를 보고 카드사에서 카드를 학생들에게 발급해줄지 말지를 결정한다고 하자. 학생인지 여부에 따른 평균값만을 본다면 default rate이 훨씬 높지만 만약 balance 가 높은 사람에 대해서는 학생일 때 오히려 default rate이 떨어진다는 사실을 파악해야만 올바른 전략을 제시할 수 있을 것이다.4.3.5 Logistic Regression for &amp;gt;2 Response Classesmultiple class classification 에서는 LDA를 더 많이 쓴다. 다만 R 패키지를 통해서 multiple class classification을 아래 식 처럼 기존 로지스틱 회귀로 접근 가능하다$P(Y=1|X)$$P(Y=2|X)$$P(Y=3|X) = 1-P(Y=1|X) - P(Y=2|X)$4.4 Linear Discriminant Analysis(1) response variable의 class 가 잘 나뉘어져 있는 경우에 logistic regression model이 불안정하다.(2) 데이터의 개수가 적고 response variable의 class 별로 predictor가 정규분포를 따르는 경우, LDA가 더 안정적이다.(3) response variable의 class가 여러개인 경우 LDA가 훨씬 더 많이 쓰인다.4.4.1 Using Bayes’ Theorem for Classification$\\pi_k : prior : k 번째\\ class에\\ 속할 \\ 확률$$f_k(X) = P(X=x|Y=k) : likelihood$$P(Y=k|X=x) = \\frac{\\pi_k f_k(x)}{\\sum _l \\pi_l f_l(x)} : Posterior$prior를 추정하는 것은 표본을 통해 쉽게 가능하다. 그러나 likelihood 분포를 추정하기란 쉽지 않다.이는 연구자의 가정에 의한 것이기 때문이다. 그러나 chap 2 에서 본 대로 bayes classifier는 error rate이 낮기 때문에 likelihood 분포만 잘 추정한다면 좋은 classifier를 만들 수 있을 것이다.4.4.2 Linear Discriminant Analysis for p=1여기서는 정규모형을 가정한 상태로 사후분포를 구하고 있다. 즉 LDA는 기본적으로 베이즈 추론에 기반한 방식. but bayes classifier는 가능도분포를 자체를 모두 가정하지만 LDA는 기본적인 모형만 가정하고 모수는 데이터에서 가져오며 특히 class 별 등분산 가정을 도입. 그리고 bayes classifier와 LDA 성능은 거의 유사하다.why is it linear? discriminant functions(사후분포) are linear function of xtest error rate good!4.4.3 Linear Discriminant Analysis for p&amp;gt;1분류에서 train error rate이 낮을 때?만일 데이터 개수 자체가 적은 경우 오버피팅의 위험이 존재또한 분류되는 대상의 데이터 개수 자체가 불균등한 경우 error rate이 평소 보다 낮을 수 있으므로 해석에 있어 이를 반드시 고려할 것.(이는 sensitivity와 specificity와도 관련이 있다)sensitivity(true positive) : refers to the proportion of those who have the condition that received a positive result on this test. (증상이 있다고 판명난 사람이 실제로 환자인지) (여기서 판정은 분류를 의미)specificity(true negative) : refers to the proportion of those who do not have the condition that received a negative result on this test. ( 정상이라고 판명난 사람이 실제로 정상인인지) (여기서 판정은 분류를 의미)sensitivity가 낮은 경우 분류의 기준이 되는 확률을 낮춤으로서 sensitivity를 높일 수 있다. 그러나 error rate 은 오히려 높아질 수 있다. 여기서는 분석의 목적이 더욱 중요해진다. error rate을 희생해서라도 sensitivity를 높이는 것이 중요한 때에는 분류의 기준이 되는 확률을 낮추는 것이 더욱 유리할 것이다.ROC curve : 모든 가능한 thresholds에 대해 두 종류의 error를 보여준다.여기서 두 종류의 error 란 (true postivite / false positive) =&amp;gt; 즉 sensitivity / 1- specificity =&amp;gt; 분류기의 성능을 비교 가능AUC : area under the curve : 분류기의 성능을 보여줌. 영역기 클수록 좋은 성능4.4.4 Quadratic Discriminant Analysis(QDA)LDA와 유사한데, 각 class 별 등분산 가정 X.등분산 가정이 없다면 QDA 과정에서 분산값을 모두 추정해야 하므로 그만큼 분산값이 큰 flexible한 모형이 만들어진다. LDA를 사용하면 분산이 낮고(overfitting 방지) 예측력이 좋을 수도 있다. 그러나 LDA에서 등분산으로 가정한 그 값이 매우 나쁜 값이라면 LDA 모델 자체의 bias가 커질 수 있다.즉 LDA는 데이터 개수 자체가 적어서 분산을 줄이는 것이 모델 추정에 중요한 경우, QDA 보다 매력적인 분류 방식이다.4.5 A Comparison of Classification Methods4장에서는 Logistic Regression, LDA, QDA, KNN(이건 2장)에 대해서 배웠다.Logistic 이나 LDA나 모두 parametric 방법으로서 fitting 과정에서 Logistic 은 MME를 통해, LDA는 표본을 가지고 모수를 추정해 베이즈 정리를 활용하는 것에만 차이가 있다. LDA에서 가정하는 likelihood가 맞다면 아마 Logistic 보다는 LDA가 훨씬 뛰어난 성능을 보일 것이다.$logistic : log(\\frac {p_1}{1-p_1}) = \\beta_0 + \\beta_1x$$LDA : log(\\frac {p_1(x)}{1-p_1(x)}) = c_0 + c_1x$이와 다르게 KNN은 non-parametric한 접근방식이다. 이 방법은 decision boundary에 대한 어떠한 가정도 없기 때문에 실제로 class들의 decision boundary가 비선형일 때 보다 좋은 성능을 가지고 있을 것이다. 다만 non-parametric의 특성상 어떤 변수들이 significant 한 것인지 알기는 어렵다.QDA는 KNN와 LDA 방식의 절충안이라고 생각하면 이해하기 쉬울 것이다. LDA와는 다르게 quadratic decision boundary를 가지고 있어 보다 flexible 하며, KNN에 비해 decision boundary에 대한 가정이 있기 때문에 데이터 개수가 적을 때에 보다 유용할 것이다.교재에 6가지 상황에 대한 scenario가 나온다scenario를 볼 때, true decision boundary가 linear이면 LDA나 logistic이 좋고, non-linear이거나 이것보다 더 복잡한 decision boundary를 가질 경우에는 QDA나 KNN 방식이 좋을 것이다. 그러나 KNN의 경우 K가 너무 작아서 smoothness가 떨어지는 경우 오히려 성능 저하기 있을 수 있기 때문에 올바른 K를 설정하는 것이 중요하다.또한 로지스틱 모형에서 quadratic term을 줄 수도 있지만 variance 가 늘어난 것 보다 훨씬 많은 bias가 감소하는지(즉, 이득이 있는지) 확인하자." }, { "title": "ISLR chap 3", "url": "/posts/ISLR3/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-07-30 00:00:00 +0900", "snippet": "3. Linear Regression이 장은 선형회귀에 관한 내용을 담고 있으며, 매우매우매우 많이 다루고 본 내용이기 때문에 핵심내용 + 놓치기 쉬운 포인트 들만 집고 넘어가도록 하겠다.3.1 Simple Linear RegressionY on X3.1.1 Estimating the Coefficients가장 대표적으로 쓰이는 방법은 LSE3.1.2 Assessing the Accuracy of the Coefficient EstimatesLSE 는 unbiased estimator. 즉 데이터가 매우 많아서 각 데이터 set의 LSE 값을 평균한다면 이는 모수에 매우 가까워질 것 이다.그럼 LSE의 평균은 그렇다 치고, 데이터 set 에서 나온 하나의 추정값의 성능은?이는 그 추정량의 분산을 살펴보면 알 수 있을 것.simple linear regression 에서$SE(\\hat \\beta_0)^2 = \\sigma^2[\\frac {1}{n} + \\frac {\\bar x^2}{\\sum (x_i - \\bar x)^2}]$$SE(\\hat \\beta_1)^2 = \\sigma^2 \\frac {1}{\\sum (x_i - \\bar x)^2}$slope 의 분산은 데이터가 넓게 퍼져있을 수록 작아진다. 이는 기울기 추정에 있어 leverage 효과를 가져오는 것과 같다. intercept의 분산은 데이터 셋의 평균이 0일 때에 평균에 대한 추정값의 분산과 같다.또한 모분산(무엇에 대한 모분산인가 헷갈릴 수 있는데 여기서는 입실론이 분포를 가지는 확률변수이고 이 입실론에 대한 분산을 말하는 것이다!) 의 값을 사실 알지 못하는 경우가 많기 때문에$\\hat \\sigma^2 = \\frac {\\sum(y_i - \\hat y_i)^2}{n-2}$으로 추정하게 된다.(이를 Residual Standard error ^2)또한 추정값에 대한 신뢰구간 혹은 T statistic 또한 자연스럽게 구할 수 있다.3.1.3 Assessing the Accuracy of the Model계수들의 accuracy 뿐만 아니라 모형 전체의 accuracy 도 구하고 싶다.이 때에는 Residual Standard Error(바로 위에서 제시됨) 혹은 R- square 값을 사용한다.RSEestimate of the standard devitation of Epsilon.RSE의 값은 y의 값과 단위를 맞춘 것으로 y의 평균값과 비교했을 때 얼마나 그 수치가 큰 것인지 비교 가능하다. 또한 RSE는 lack of fit에 대한 기준으로 사용가능하다.R-squareRSE와는 다르게 fit에 대한 직관적인 수치를 제공한다. 단순선형회귀에서는 상관계수의 제곱값과 동일하다.3.2 Multiple Linear Regression3.2.1 Estimating the Regression Coefficients최소제곱법 사용 가능. 변수간의 관계를 따져야 한다. multiple regression은 여러가지 변수를 predictor로 집어넣기 때문에 predictor가 모두 target값과 관련이 있을 지라도 multiple regression의 회귀계수는 이와 상이할 수 있다.예를 들어 다중회귀에서는 아이스크림 판매량과 상어에 의한 피서객 사고 간의 양의 상관관계를 잡아내고 매우 큰 회귀계수값을 추정해낼 수 있는데, 이는 온도가 높을 수록 해변으로 피서를 많이 가게되고 자연스럽게 아이스크림 판매량이 늘어나는 논리를 최소제곱법이라는 단순 계산에서는 찾아내지 못하기 때문에 발생한 결과라고 할 수 있다.3.2.2 Some Important QuestionsRelationship$H_0 : \\beta_1 = \\beta_2 = … = \\beta_p = 0$에 대한 가설검정을 해야한다. 귀무가설이 맞다는 가정 하에서 F-statistic을 만들어낼 수 있다.또한 다중회귀에서는 개별적인 회귀계수들의 p 값이 우연한 결과로 매우 작을 수 있으나, 모형 전체의 회귀계수에 대한 F-statistic은 매우 작아 유의하지 않을 수도 있다. 또한 개별적으로는 target 변수와 유의미한 관계를 가질지언정, multiple regression setting에서 볼 때 여러가지 변수들이 종합적으로 target변수와 큰 관계를 가지지 못할 수 도 있다. 물론 반대로 개별 회귀계수들의 t statistic에 대한 p 값이 매우 클지라도 multiple setting에서 F값에 대한 p 값은 매우 작게 나올 수도 있다.즉 데이터에 대한 이해를 바탕으로 유기적으로 생각하는 것이 중요하다.Deciding on Important Variables(변수선택)앞서 말한대로, multiple regression에서 ‘‘회귀계수가 모두 0이다’’ 라는 귀무가설이 기각 된다고해도, 개별적인 회귀계수의 t statistic으로 중요한(유의미한) 변수를 결정하는 것에는 한계가 있다. 따라서 변수 선택을 잘 하기 위한 여러가지 접근법이 존재하는데 이를 숙지할 필요가 있다. Mallow’s Cp AIC BIC adjusted R-square 잔차가 작은 모델만약 변수의 개수가 매우 많다면? (1) Forward selection (2) Backward selection (3) Mixed selectionModel fitsimple linear regression과 마찬가지로 (1) R-square (2) Residual Squared Error(1) R-square는 변수가 많아질수록 높아질 수밖에 없다.(2) 또한 변수가 추가될 때 RSE가 늘어날 수 있는지에 대해 생각해보아야 한다. 변수가 추가되면 자연스럽게 RSS(SSE)는 줄어들 수밖에 없다. 그러나$RSE = \\sqrt \\frac{RSS}{n-p-1}$이므로 RSS가 줄어든 것에 비해 변수의 개수가 더 많이 늘어나면 RSE는 증가할 수 있다. 이 점을 주의하자. (RSE는 변수의 개수와 관련이 있다는 사실!!)(3) 직접 그려보면 잔차들의 형태를 알수있다(negative or positive)predictions함수 f의 추정량에 대해 reducible error(비선형 모델인데 선형으로 선택, 회귀계수에 대한 추정이 잘못되었다던지)와 irreducible error(prediction 과정에서 individual point에 대한 irreducible error ) 를 모두 고려할 필요가 있다.3.3 Other Considerations in the Regression Model3.3.1 Qualitative Predictors가변수로 만들기 class가 두개 일 때(0,1) 코딩 혹은 (-1,1) 코딩 =&amp;gt; 어떤 방법을 쓰든 결과는 같다. 계수는 차이가 있을지언정 해석은 동일 class가 두 개 초과 할 때코딩할 때 category를 하나 줄여야한다. 즉 아무것도 코딩 안된 상태를 baseline으로코딩 방식에 따른 prediction 값은 차이가 없으나 어떻게 코딩하느냐에 따라 회귀계수에 대한 p-value가 달라질 수 있다. 따라서 가변수를 활용할 때, 특히 class가 3개 이상인 경우 변수에 유의성을 확인할 때는 가변수의 회귀계수들에 대한 F-test를 해야한다.3.3.2 Extensions of the Linear ModelLinear regression의 가정은 변수들이 (1)additive (2) linear 하다는 것이다.즉 변수들은 서로 독립이며 특정 변수의 한단위 증가가 target에 미치는 영향은 오로지 그 변수 뿐이라는 것이다.(1)번 가정을 완화해보자interaction effect를 고려할 수 있다.※ 또한 hierarchical principal 에 따르면 두 변수의 interaction이 중요하다고 생각될 때(사전지식에 의해), 개별 변수의 계수값의 p-value가 낮다고 하더라도 개별 변수, interaction term 을 모두 넣어줘야 한다. 또한 개별 변수를 제외하고 교차항만을 넣는것은 의미가 없다.질적변수와 양적변수에 대한 interaction term을 만들어내면 질적변수의 class에 따라 기울기와 절편이 모두 바뀐다.(2)번 가정을 완화해보자polynomial regression… 더 복잡한 것은 7장에서3.3.3 Potential Problems비단 선형회귀 뿐만 아니라 많은 모델에서 아래와 같은 문제들에 대해 고심해볼 필요가 있다Non-linearity of the response-predictor relationships(선형성 가정)선형 회귀 적합 후 잔차도를 그려봤을 때, 특별한 패턴이 발견된다면 변수를 추가할 필요가 있는데 특히 U자형의 그래프가 그려진다면 non-linearity를 고려해봐야 한다. 이를 해결하기 위해$logX,\\ \\sqrt X, \\ X^2 $ 등의 항들을 추가해야 한다.Correlation of error terms(error 간 독립성 가정)선형모형을 가정할 때$\\epsilon \\sim^{iid} (0, \\sigma^2)$인데 만약 error term 간에 상관관계가 존재한다면 standard error 추정시 과소추정이 발생한다. 그 결과 신뢰구간이나 예측구간이 실제보다 더욱 좁아진다. 또한 계수에 대한 p-value 또한 실제값 보다 작아져서 유의하지 않은 변수를 유의하다고 판단할 우려가 있다.특히 이런 상관관계는 시계열 데이터에서 자주 나타난다. 인접한 시간에서는 error들이 양의 상관관계를 가지는 경우가 많다.또한 time이라는 변수 이외에도 데이터 간의 상관관계가 나타날 수 있으므로 주의해야 한다. 예를 들어 sampling 과정에서 데이터들 간에 동질성으로 인해 서로 독립이 아닌 obs가 표본으로 잡힐 수 있다. 즉 시계열 뿐만 아니라 실험설계 과정에서도 독립성 가정이 유지되는지 확인해 볼 필요가 있다.Non-constant variance of error terms (등분산성 가정) (heteroscedasticity)잔차도를 그려보았을 때 funnel shape 형태를 띈다. 이때 로그 변환이나 제곱근 변환을 해주면 heteroscedasticity 문제를 해결할 수 있다. 또한 독립성 가정은 성립하나 등분산성 가정이 깨질 시에는 weighted least square 을 통해서 문제를 해결할 수 있다.Outliers ( y 축의 관점)아웃라이어 제거 이후에 fitting된 모델의 큰 변화가 없는 경우도 있다!그러나 RSE나 R-square는 이상치가 제거 되었을 때 보다 좋아질 것이다.잔차 또한 단위의 영향을 받으므로 잔차를 standard error의 추정값으로 나눈 studentized residual을 사용하면 이상치를 판단하는데에 더욱 유리할 것이다.(3 이상이면 이상치일 가능성이 크다) 무엇보다 잔차는 모델에 의해 나온 것이므로 모델이 잘못된 경우 실제로 이상치가 아닌 경우에도 이상치로 판정될 수 있으니 혹여나 모델이 잘못된 것은 아닌지 생각해 볼 필요도 있다.High-leverage points (x 축의 관점)leverage point는 추정 회귀 계수에 영향을 준다. 그러나 다중회귀에서는 이러한 포인트를 그림을 통해 찾기 힘들다. 따라서 leverage statistic 을 통해 이를 판정하자. 단순회귀의 경우에 통계량은 다음과 같다.\\[h_i = \\frac {1}{n} + \\frac {(x_i - \\bar x)^2}{\\sum (x_i - \\bar x)^2}\\]x가 평균으로부터 멀리 떨어져 있는 경우 statistic은 커진다. 또한 모든 관측치를 통한 statistic의 평균이 (p + 1) / n 이므로 이를 기준으로 leverage point를 찾을 수 있다.Collinearity(변수간 독립성 가정)contour를 살펴보면 다중공선성이 높은 두 변수를 사용했을 때는 변수들의 순서쌍 중 대부분이 유사한 RSS를 갖는다. 따라서 data가 살짝만 바뀌더라도 RSS를 최소로 만드는 순서쌍 값일 가능성이 높다. 즉 계수 추정치가 불안정하다. 회귀 계수 추정치가 불안정하다는 것은 계수의 분산 값 또한 크다는 의미이므로, 계수의 t-test 값이 작아진다.다중공선성을 감지하기 위해(1) 상관계수 행렬을 찾는다(2) 두 가지 이상의 변수에서 공선성이 나타나는 경우에는 (multi-collinearity) variance - influence - factor를 이용한다. 이를 구하는 공식은 다음과 같다.\\[VIF(\\hat \\beta_j) = \\frac {1}{1-R^2_{X_j|X_-j}}\\](사실, VIF는 모든 변수를 포함했을 때 $ \\hat \\beta_j $ 의 분산을 j 번째 변수만을 포함했을 때 $ \\hat \\beta_j $ 의 분산으로 나눈 값으로 정의된다)3.5 Comparison of Linear Regression with K-NearestKNN Regressor\\[\\hat f(x_0) = \\frac {1}{K}\\sum _ {x_i \\in N_0} y_i\\]K 를 정하는 기준은 bias-variance trade off 관계에 의해 적절하게 결정해야 한다.small K : flexible, risk of overfittinglarge K : smoother, bias==&amp;gt; test error rate 을 통해 최적의 K를 설정해야.(헷갈리지 말아야 할 게 위 내용은 non-parametric 인 KNN 에서 K에 따라 바뀌는 것이고, 앞에서 우리가 봤던 것 중 Interpretability / Predictability 는 Linear / Non - Linear 의 차이었다. )일반적으로 true model 을 아는 경우에는 parametric 이 낫고, 그렇지 않은 경우는 non-parametirc 접근이 더 나을 것이다. 그러나 현실에서 true model을 아는 경우는 드물다. 그럼 반드시 non-parametric 한 접근이 더 좋은 것인가?그렇지 않다.(1) 모델의 변수가 많아진다면 그에 따른 데이터 또한 많이 필요한데 non-parametric한 접근으로는 추정에 어려움이 더더욱 커진다. 따라서 비록 true model을 정확히 모른다고 할 지라도, 변수의 개수에 비해 데이터 개수가 적다면 parametric 한 접근이 더 나을 것이다.(2) simple 한 모델의 장점(해석의 편의, 단순성) 때문에 test MSE의 차이가 별로 없다면 우리는 더 쉬운 모델인 simple(여기서는 linear) 모델을 사용하는 것이 좋다." }, { "title": "ISLR - LAB3", "url": "/posts/ISLR3-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-07-30 00:00:00 +0900", "snippet": "R 코드 정리library(MASS)fix(Boston) #table 형태로 보여주기names(Boston) # 열 이름 보여주기attach(Boston)lm.fit = lm( medv ~ lstat)summary(lm.fit)&quot;&quot;&quot;Call:lm(formula = medv ~ lstat)Residuals: Min 1Q Median 3Q Max -15.168 -3.990 -1.318 2.034 24.500 Coefficients: Estimate Std. Error t value Pr(&amp;gt;|t|) (Intercept) 34.55384 0.56263 61.41 &amp;lt;2e-16 ***lstat -0.95005 0.03873 -24.53 &amp;lt;2e-16 ***---Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1Residual standard error: 6.216 on 504 degrees of freedomMultiple R-squared: 0.5441, Adjusted R-squared: 0.5432 F-statistic: 601.6 on 1 and 504 DF, p-value: &amp;lt; 2.2e-16&quot;&quot;&quot;names(lm.fit)confint(lm.fit) # confidence interval 구하기#prediction과 confidenc interval, prediction intervalpredict(lm.fit, data.frame(lstat=(c(5,10,15))), interval = &quot;confidence&quot;)&quot;&quot;&quot; fit lwr upr1 29.80359 29.00741 30.599782 25.05335 24.47413 25.632563 20.30310 19.73159 20.87461&quot;&quot;&quot;predict(lm.fit, data.frame(lstat=(c(5,10,15))), interval = &quot;prediction&quot;)&quot;&quot;&quot; fit lwr upr1 29.80359 17.565675 42.041512 25.05335 12.827626 37.279073 20.30310 8.077742 32.52846&quot;&quot;&quot;#plot하기. abline은 plot 이후에 실행해줘야지 라인을 그려줌plot(lstat, medv)abline(lm.fit, lwd=3, col = &#39;red&#39;)#plot(lstat, medv, pch=20) pch 인자를 통해 plot의 symbol을 바꿀 수 있다# 한번에 여러개 그리기( par(mfrow=c(a,b)) )par(mfrow=c(1,2))plot(lm.fit)#levrage point 찾기 (hatvalues)plot(hatvalues(lm.fit))which.max(hatvalues(lm.fit))#다중회귀lm.fit = lm(medv ~ lstat+age, data=Boston)lm.fit = lm(medv ~., -age, data = Boston) #특정변수 제외 가능lm.fit = lm(medv ~ lstat*age) # interaction 항 포함lm.fit = lm(medv ~ lstat+age+lstat:age) # 위에 것과 같은 의미lm.fit = lm(medv ~ ., data=Boston) # . 으로 모든 변수를 나타냄lm.fit = update(lm.fit, ~.-age) #함수를 교체할 때#RSEsummary(lm.fit)$sigma#viflibrary(car)vif(lm.fit)#비선형회귀lm.fit = lm(medv ~ lstat)lm.fit2 = lm(medv ~ lstat + I(lstat^2)) #I를 사용해서 제곱항 세제곱항 등을 만들수있다.anova(lm.fit, lm.fit2) #두 모형 비교 가능lm.fit5 = lm(medv~ poly(lstat,5)) #poly를 사용해서 비선형 모양 가능# dummy variable returnlibrary(ISLR)data(&quot;Carseats&quot;)fix(Carseats) # fix를 통해 보면 shelveLoc변수는 범주형 변수인데 밑에 lm을 통해서 회귀식을 만들어내면 프로그램상에서 알아서 원핫인코딩을 해준다lm.fit = lm(Sales ~ ., data=Carseats)summary(lm.fit)contrasts(Carseats$ShelveLoc) # one-hot encoding# 사용자정의함수 만들기user_f = function(){ library(ISLR) library(MASS) print(&quot;good&quot;)} # 책에서는 + 라고 나와있지만 그냥 엔터를 치면 된다 user_fuser_f()" }, { "title": "ISLR - LAB2", "url": "/posts/ISLR2-LAB/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-07-30 00:00:00 +0900", "snippet": "R 코드 정리#할당, c는 백터를 의미x &amp;lt;- c(1,2,3,4)# 백터의 원소 개수length(x)#저장되어 있는 변수 모두 호출ls()#removerm(x)rm(list=ls())#행렬x = matrix(data=c(1,2,3,4), nrow=2, ncol=2)xy = matrix(data=c(1,2,3,4), nrow=2, ncol=2, byrow=TRUE)y#standard normal randomvariable n개 추출x = rnorm(50)y = x+rnorm(50, mean = 10, sd=2) # rnorm 에서 평균과 표준편차를 조절 가능cor(x,y)#plot ( x, y, x축 이름, y축 이름, 그래프 이름)plot(x,y, xlab = &#39;aa&#39;, ylab=&#39;bb&#39;, main = &#39;practice&#39;) #pdf 파일을 생성해서 그래프 그리기getwd()pdf(&quot;ddd.pdf&quot;)plot(x,y, xlab = &#39;aa&#39;, ylab=&#39;bb&#39;, main = &#39;practice&#39;)dev.off()# sequence 만들기x= seq(1,10)x = seq(-pi, pi, length=50)x#등고선 그리기y=xf = outer(x,y, function(x,y)cos(y)/(1+x^2)) #outer는 matrix 만드는데 각 원소들은 세번째 인수의 값을 따른다contour(x,y,f) # contour 는 세번째 인수로 matrix가 와야 한다. contour(x,y,f, nlevels=45, add=T)#contour : 등고선, image : heatmap, persp : 3차원(theta와 phi로 각도 조절)fa = (f-t(f))/2contour(x,y,fa)image(x,y,fa)persp(x,y,fa, theta=30, phi=40)#indexing / slicingA = matrix(1:16, 4,4)&amp;gt; A[c(1,3),c(2,4)] [,1] [,2][1,] 5 13[2,] 7 15&amp;gt; A[-c(1,3),c(2,4)] # minus 부호는 이를 제외한다는 뜻 [,1] [,2][1,] 6 14[2,] 8 16 #plot을 할 때 변수를 쓰고 싶으면 $ 표시 사용library(ISLR)plot(Auto$cylinders, Auto$mpg)attach(Auto) #attach를 쓰면 그냥 변수 이름을 그대로 쓸 수 있음.plot(cylinders, mpg)cylinders = as.factor(cylinders) #as.factor는 categorical로 만들어 주는 것plot(cylinders, mpg)plot(cylinders, mpg, col=&#39;red&#39;, varwidth=&#39;T&#39;, xlab = &#39;cylinders&#39;)#histogramhist(mpg)hist(mpg, col=3, breaks = 15) #break는 bar의 개수#pairs : scatter plotpairs(Auto)pairs(~ mpg+displacement + horsepower + weight + acceleration, Auto) #identify를 사용하면 각 점의 이름을 click을 통해 알 수 있으며 finish를 눌러야 그 결과치를 얻을 수 있음.plot(horsepower, mpg)identify(horsepower,mpg, name)" }, { "title": "ISLR chap 2", "url": "/posts/ISLR2/", "categories": "", "tags": "datascience, datamining, machinelearning, ISLR", "date": "2021-07-29 00:00:00 +0900", "snippet": "2.1 What is statistical learning?2.1.1X : predictor, features, independent variableY : response, dependent variable$Y = f(X) + \\epsilon$$\\hat Y = \\hat f(X)$reducible error : Y를 추정하기 위해 hat Y 를 구하는 것irreducible error : Y는 Epsilon의 함수이므로 X를 가지고 추정이 불가하다Why is the irreducible error larger than zero ? the quantity epsilon may contain unmeasured variables that are useful in predicting Y the quantity epsilon may also contain unmeasurable variation $E(Y - \\hat Y )^2 \\ \\ = \\ E[f(X) + \\epsilon - \\hat f(X)]^2 \\ = \\ [f(X) - \\hat f(X)]^2 \\ + \\ Var(\\epsilon)$마지막 등식의 앞 부분이 reducible error, 뒷 부분이 irreducible error 를 의미한다.궁극적으로 풀고자 하는 문제가 prediction인지 inference(모델 해석, 독립/종속 변수 관계 해석) 인지에 따라서 f 를 추정하는 데에 다른 접근 방식이 요구된다. 예를 들어 prediction 같은 경우에는 비선형 모델이 좋다. 그러나 inference 의 경우에는 선형 모델이 더 좋을 것이다.test data를 가지고 f를 추정하게 되는데 이때 statistical learning methods로서 parametric / non-parametric 방법이 있다.2.1.21. Parametric Methods(model based approach)step 1. 함수 형태를 우선적으로 가정한다(linear or non-linear)step 2. training data를 통해 적합한다step 3. parameter를 추정한다.단점 : 모델을 잘못 설정하면 추정 자체가 의미가 없다. 1번 문제를 막기위해 flexible한 모델을 설정하면 추정해야할 파라미터가 많아진다. 추정해야할 파라미터가 많아진다는 것은 오버피팅의 위험이 있다는 것.2. Non-parametric Methods함수 형태를 우선적으로 가정하지 않는다. 대신 데이터들에 최대한 적합하는 f 를 국소적으로 찾아낸다. 대신 몇개의 파라미터에 의존하는 parametric method에 비해 수많은 데이터가 있어야만 f 에 대한 정확한 추정이 가능할 것이다. (즉 데이터 수가 적은 경우에는 단순한 모형으로 parametric 하게 접근하는 것이 좋다)7장에서 배우는 spline은 non-parametric method인데 smoothness를 크게 하면 에러를 완전히 줄이는 fitting을 하게 된다(overfitting의 문제).2.1.3 Trade off between prediction accuracy and model interpretability restrictive method(interpretability 가 높은 모델)는 쉽게 설명이 가능하고 인과성을 간단히 보이기 쉽다. spline이나 boosting 같은 복잡한 모형은 predictor들이 response와 어떻게 연결되어있는지 알기 어렵다 lasso 같은 경우는 제일 restrictive한데 이는 일부 변수를 완전히 0으로 만들어버려 변수간의 관계를 찾기 더 쉽기 때문이다. Generalized Additive Models(GAMs) 같은 경우 linear 모델을 확장해서 유연하게 만든 것으로, curve를 허용해서 새롭게 모델을 만든다. 그러나 무엇보다 오버피팅의 문제에 있어서 predictive accuracy가 높을 것이라 예상했던 flexible 한 모델이 반드시 예측력이 좋은 것이 아니므로 주의할 것.2.1.4 Supervised vs Unsupervisedlinear regression, GAMs, boosting, SVM 등은 모두 지도학습이다. 즉 찾고자하는 혹은 예측하고자 하는 target 값이 존재한다. 반면 비지도학습의 경우 관찰값(obs)만 존재할 뿐 target 값이 없다. 이 상황에서는 obs값들의 관계를 찾아내야 하는데 여기서 쓰이는 방법으로는 Clustering이 있다. 또한 predictor에 비해 response 의 개수가 적을 수도 있다. 이런 경우는 semi-supervised learning을 사용한다. 단 이 방법은 이 책의 범위를 넘는다.2.1.5 Regression vs Classification양적 변수 예측 / 질적 변수 예측이냐에 따라 다르지만, KNN이나 boosting 같은 경우에는 두 가지 속성의 변수에서 모두 사용가능하다.2.2 Assessing Model Accuracy“There is no free lunch in statistics : no one method dominates all others over all possible data sets. “2.2.1 measuring the quality of fitMSE(Mean Squared Error)$MSE = \\frac {1}{n} \\sum ^n (y_i - \\hat f (x_i))^2$그러나, 이것은 training data로 만드는 것이므로 training MSE로 부르는 것이 더 나을 수도 있다. 우리는 예측의 문제를 다루는 데 있어 새로운 데이터를 얼마나 잘 찾아낼지에 관심이 있으므로 test MSE 가 더 궁금할 수 있다. 즉, 새로운 데이터를 (x_0, y_0) 라고 할 때$Average(\\hat f(x_0) - y_0)^2$이를 최소화 하는 모델을 만들고 싶은 것이다. 그러나 새로운 데이터가 항상 full-set으로 존재하는 것은 아니므로 이를 계산 하기 어렵다.(이에 대한 해결방안으로 cross-validation 이 있다) 그렇다고 training MSE를 최소화 하는 모델을 찾는다면 오버피팅의 문제가 발생한다. 즉 training MSE는 무한정 줄어들 수 있으나(random error까지 모델에 넣어버림) 그러한 모델에서는 test MSE가 매우 커진다.또한 모델은 training data와의 error를 줄이는 방향으로 학습되고 있기 때문에, less flexible model의 test MSE가 더 적은 경우에도 overfitting 문제가 발생한 것일 수도 있다.2.2.2 The Bias - Variance Trade - OffExpected test MSE ( overall expected test MSE는 이 값을 average 한 것 )$E(y_0 - \\hat f (x_0))^2 = Var(\\hat f(x_0)) + [Bias(\\hat f(x_0))]^2 + Var(\\epsilon)$Expected test MSE를 줄이기 위해서는 hat f(x_0) 의 추정값에 대한 분산과 편의를 모두 줄여야 한다. 또한 이 값이 모두 양수이므로 Expected test MSE는 irreducible error인 Var(epsilon) 의 값을 넘지 못한다.그리고 분산과 편의의 trade-off 관계에 의해서 Expected test MSE는 모델이 특정 flexibility를 넘어서면 증가하게 된다.2.2.3 The Classification Setting분류문제에서 추정함수의 정확도(accurarcy)를 평가하는 기준은 training error rate$\\frac {1}{n}\\sum^n I(y_i \\neq \\hat y_i)$regression 과 마찬가지로 새로운 데이터에 대한 모델의 성능을 알고 싶으므로 test error rate을 살핀다$Average(I(y_0 \\neq \\hat y_0))$The Bayes Classifiertest error rate 을 최소화하는 방법으로서 bayes classifier 가 있는데 이는$P(Y=j |X=x_0)$가 가장 큰 class j 로 추정하는 분류기를 말한다.아래의 그림을 보면 노란색과 파란색으로 점들이 분류되어 있고 각각은 조건부 확률이 0.5 이상인지 여부에 따라 분류된 것이다 (두가지 class 밖에 없기 때문)또한 보라색 점선은 Bayes Decision Boundary로 확률값이 정확히 0.5 인 부분이다.앞서 말한대로 bayes classifier는 test error rate 을 최소화 하는데, 이렇게 최소화된 test error rate을 Bayes error rate이라고 한다. (즉 베이지 error 비율은 test set에서의 error 비율인 것)Bayes error rate at X=x_0$1 - max_j P(Y=j|X=x_0)$(Bayes classifier는 확률 값이 가장 큰 class 를 선택하기 때문에)simulation 결과 bayes error rate 은 0.13 정도인데 이는 경계값에 속하는 점들의 최대 분류 확률이 1 미만이기 때문에 발생하는 결과이다. 즉 이는 regression setting에서 irreducible error와 유사하다.$max_j P(Y=j | X=x_0) &amp;lt; 1 \\ \\ \\ where\\ obs\\ are \\ in \\ boundary$K-Nearest Neighbors(KNN)현실 데이터에서는 조건부 분포를 알기 어려운 경우가 많기 때문에 Bayes Classifier를 사용하기 어렵다. 따라서 조건부 분포를 추정하기 위한 시도들이 많이 전개되었는데, 이러한 시도로 탄생한 것이 KNN이다. 점 x 주변에 K개의 점들을 잡아서 조건부 분포를 살피는 것이다.$P(Y=j|X=x_0) = \\frac {1}{K} \\sum_{i\\in N_0}I(y_i=j)$이를 통해 확률이 가장 큰 값으로 class를 설정하게 된다.KNN에서는 K값을 어떻게 설정 할 지가 관건이다. 이는 flexibility를 결정하는 값이다. K의 값을 매우 줄이면 오버피팅의 문제가 있고, 반대로 매우 크게 하면 bias가 매우 커진다(underfitting)." }, { "title": "Ensemble(Bagging, Boosting, Stacking, Blending)", "url": "/posts/ensemble/", "categories": "", "tags": "datascience, machine learning, datamining", "date": "2021-07-29 00:00:00 +0900", "snippet": "1. BaggingBagging은 bootstrap aggregating을 줄인 말이다. overfitting을 방지하기 위한 앙상블 알고리즘의 하나로 분류와 회귀 모두에 사용된다. 앞선 글에서 boostrap을 상세히 설명했는데, boostrapping을 잘 알고 있다고 매우 쉬운 앙상블 알고리즘이라 할 수 있다. Boostraping은 주로 decision tree 모델에서 자주 사용되나 다른 모델에서도 사용할 수 있다.전체 샘플에서 boostraping 샘플 K개를 추출해 내어, 모델에 K번 적합한다. 이후 K개의 모델에서 나온 K 개의 결과치를 가지고 이를 평균을 내거나(회귀) 혹은 투표(voting)(분류)을 통해 최종 예측치를 뽑아낸다2. Boosting“Weak learner to Strong learner” 이것은 boosting 알고리즘의 지향점을 나타낸다. Boosting은 bias와 variance를 동시에 줄이고자 하는 앙상블 알고리즘이다. Weak learner로 부터 잘못 예측한 부분에 대해 큰 가중치를 두고 이를 조정해가면서 최적의 예측치를 찾고자 한다.(weaker learner에 주목하는 것이 bias를 줄이고자 / 모델들을 결합한다는 데서 variance를 줄이고자 )또한 부스팅 알고리즘에는 여려가지 종류가 있는데 기본적인 구조는 동일하되, weighting을 어떠한 방식으로 주는 지에 대해 차이가 있다. Adaboost는 가장 기본적인 boosting 알고리즘인데, weak learner를 다루는 첫번째 부스팅 알고리즘이었다. 순차적 학습과정에서 먼저 학습된 모델이 잘못 예측한 부분을 다음 학습시에 이용하면서 단점을 보완해나간다.$H(X) = \\sum^t \\alpha_i h_i$H : strong classifieralpha : weight of weak classifierh : weak classifier여기서 weak classifier는 weighted error가 가장 작은 모델. 또한 weighted error는 한번 시행할 때 잘못 분류할 수록 가중치를 크게 주는것. 헷갈리는 부분이 weighted error는 개별 모델의 시행에서 오차가 클 수록 가중치를 크게 주는 것이고, alpha의 값은 모델 자체의 성능에 대한 가중치이므로 모델의 성능이 좋을수록(오차가 작을수록) 가중치를 크게 준다.종합하면 잘못 예측(분류)되면 weighted error가 커지고, error 가 커지니까 weak classifier가 되지 못함. 즉 이번 단계에서 제일 좋은 모델(h)은 weighted error가 가장 작은 모델각 단계에서 나온 모델들을 가지고 alpha로 가중치를 준 앙상블이 boosting 알고리즘이다.최근에는 LPBoost, TotalBoost, BrownBoost, XGBoost 등이 나와서 많이 사용되고 있고, 다른 boosting 알고리즘이 convex opimization 인 것에 비해, BrownBoost는 noise 가 많은 상황에서도 학습이 가능한 non-convex optimization에 기반한 boosting 알고리즘이다.3. StackingStacking은 모델들의 예측값을 다시 training 데이터로 활용해 모델을 만드는 앙상블 알고리즘이다. 이는 학습 이후 최종적으로 성능을 조금 더 향상시키기 위한 최후의 수단으로 여겨진다. 그 이유는 두번의 학습과정을 거치면서 overfitting에 굉장히 취약하기 때문이다.stacking의 구조는 다음과 같다학습모델 3가지를 만들었다고 하자training set을 3가지 각 모델에 넣어 training data의 예측값을 얻고, 이 값과 training data의 target 값(실제값)을 가지고 최종 학습을 한다. 이후, test data를 가지고 최종 예측을 하게된다.파이썬 코드의 경우, 파이선 머신러닝 완벽 가이드라는 책에서 배포한 코드가 구글링하면 쉽게 찾을 수 있고 모두 동일한 코드이기 때문에 생략한다. 다만 한가지 이해가 안되는 부분이 있다. CV기반의 stacking의 경우train set을 train-validation으로 나누어서 train으로 모델링 -&amp;gt; validation data로 예측 -&amp;gt; K-fold를 통해 예측값 K 개 형성 -&amp;gt; 이를 가지고 train_target 데이터와 함께 모델 적합 -&amp;gt; K fold과정에서 만든 모델로 test data 넣어서 예측한 값을 마지막으로 만든 모델에다 넣어서 예측 이라는 순서는 쉽게 이해가 간다.다만 cv기반이 아닌 경우에 y_test를 모델 적합에 사용한다는데에서 모델에 최종 예측하고 싶은 값을 포함시킨다는게 과연 의미있는 것인지, 아니면 설명을 위해 그렇게 만든 것인지는 의문이 든다.이러한 과정을 한꺼번에 압축해서 만든 StackingCVRegressor 패키지가 존재한다from mlxtend.regressor import StackingCVRegressor#5개의 모델 위에 xgboost를 하나 더 올려서 stacking 한다.StackingCVRegressor(regressors=(gb, lightgb, xgboost, svr, lasso), meta_regressor=xgboost, use_features_in_secondary=True, n_jobs=-1)4. BlendingBlending은 stacking와 유사한 앙상블 알고리즘이다.우선 training , validation, test 로 데이터를 나누고 training data만으로 모델에 적합시킨다. 이후, valiation set에 대한 예측값과 test set에 대한 예측값을 구한 뒤에 이 두가지 데이터를 가지고 새로이 모델에 적합시켜 최종 test set에 대한 예측값을 구하는 것이다.stacking 과 blending의 차이점은 stacking은 training set의 예측값을 활용 / blending은 validation set 의 예측값을 활용 stacking은 예측값만을 / blending은 예측값과 원래의 validation / test set을 모두 활용#fittingmodel = xgb.XGBRegressor()model.fit(x_train, y_train)#predictionprediction_val = model.predict(x_validation)prediction_test = model.predict(x_test)prediction_val=pd.DataFrame(prediction_val)prediction_test=pd.DataFrame(prediction_test)#fittingmodel2 = ExtraTreesRegressor()model2.fit(x_train,y_train)#predictionprediction_val2=model2.predict(x_validation)prediction_test2=model2.predict(x_test)prediction_val2=pd.DataFrame(prediction_val2)prediction_test2=pd.DataFrame(prediction_test2)#validation 예측값과 test 예측값을 활용해서 새로이 모델에 피팅total_validation = pd.concat([x_validation, prediction_val,prediction_val2],axis=1)total_test = pd.concat([x_test, prediction_test,prediction_test2],axis=1)model3 = Ridge(alpha=10)model3.fit(total_validation,y_validation)model3.score(total_test,y_test)blending 파이썬 코드는https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/를 참조했습니다." }, { "title": "Dacon - 구내식당 식수 인원 예측 AI 경진대회", "url": "/posts/dacon(3)/", "categories": "", "tags": "datascience, dacon, machine learning, pandas", "date": "2021-07-29 00:00:00 +0900", "snippet": "대회에서 우수한 성적을 거두신 분들이 본인들의 코드를 상세히 올려주셔서 이를 참고해서 공부를 하고 있습니다. 이번 글에서는 새로운 접근 방식에 대한 아이디어 그리고 내가 사용하지 못했지만 괜찮아 보이는 코딩 방식에 대해 적어보겠습니다.또한 다른 좋은 방식들이 추가로 발견된다면 이 글에 추가로 작성하도록 하겠습니다.1. columns name 한꺼번에 바꾸기(튜플 사용)trian.columns # Index([&#39;일자&#39;, &#39;요일&#39;], dtype=&#39;object&#39;)columns = {&#39;일자&#39;: &#39;time&#39;, &#39;요일&#39;: &#39;date&#39;}train = train.rename(columns, axis=1)train.columns # Index([&#39;time&#39;, &#39;date&#39;], dtype=&#39;object&#39;)2. shift를 사용해서 전년도/ 전월/ 전일 대비 데이터 feature 만들기 x[&#39;ratio&#39;] = ( (x[&#39;A&#39;] - x[&#39;A&#39;].shift(1) ) / x[&#39;A&#39;].shift(1) ) + 0.010.01 이라는 작은수를 더해서 0과 같이 너무 작은 값에 대비하기이러한 데이터를 사용해서 예측을 할 때에는 첫번째 행의 경우 전월 대비 데이터가 없기 때문에 첫번째 행 / 나머지 행 이렇게 나누어서 새로 코드를 짜야한다.즉for i in range(0, 50) :​ if i == 0 :​ if i != 0 :3. pandas 에서 query를 사용해서 특정 조건 추출해내기(with where)#기존 내 방식mask = train[&#39;요일&#39;]== &#39;수&#39;train[mask]#query를 사용한 방식mask = &quot;요일 == &#39;수&#39;&quot;train.query(mask)#query는 비교, in, 논리연산자, 외부변수 참조 연산이 모두 가능하다#외부변수 참조(@ 을 변수 앞에 붙인다)wed = &#39;수&#39;mask = &quot;요일 = @wed&quot;train.query(mask)## 추가로 where 을 사용해서도 조건을 추출해낼 수 있다.import pandas as pdimport numpy as npaa = pd.Series(np.arange(6))aa[aa&amp;gt;2]# Out[1]: 3 34 45 5aa.where(aa&amp;gt;2)#Out[2]: 0 NaN1 NaN2 NaN3 3.04 4.05 5.0aa.where(aa&amp;gt;2, other=0)#Out[3]: 0 01 02 03 34 45 5#where 에서 axis를 사용해서 dataframe 변환하기#axis=0 는 처음 인자에 만족하지 않는 행렬 위치들에 대해 두번째 인수인 행 또는 열의 위치 값으로 행 안에서 만족하지 않는 값을 대체해라 #axis=1 는 처음 인자에 만족하지 않는 행렬 위치들에 대해 두번째 인수인 행 또는 열의 위치 값으로 열 안에서 만족하지 않는 값을 모두 대체해라 aa = pd.DataFrame([[1,2,3],[4,5,6,],[7,8,9]])aa.where(aa&amp;gt;3, aa[1], axis=0)#Out[4]: 0 1 20 2 2 21 4 5 62 7 8 9aa.where(aa&amp;gt;3, aa[1], axis=1)#Out[5]: 0 1 20 4 5 61 4 5 62 7 8 9나는 본래 특정 변수에 조건들을 할당에서 데이터프레임 뒤에 변수를 붙여주는 식으로 원하는 데이터만 뽑아냈는데 query를 사용하는 방법도 있어서 가지고 왔다.4. cross-validation 하는 도중 각각에서 중요한 변수를 찾아낼 수 있다(LGBM)lgb = LGBMRegressor(random_state=0, n_jobs=-1)output = cross_validate(lgb, train.drop([&#39;eat_lunch&#39;, &#39;eat_dinner&#39;, &#39;time&#39;, &#39;day&#39;], axis=1), train[&#39;eat_lunch&#39;], cv=10, scoring = &#39;neg_mean_squared_error&#39;, return_estimator =True)for idx,estimator in enumerate(output[&#39;estimator&#39;]): print(&quot;Features sorted by their score for estimator {}:&quot;.format(idx)) feature_importances = pd.DataFrame(estimator.feature_importances_, index = train.drop([&#39;eat_lunch&#39;, &#39;eat_dinner&#39;, &#39;time&#39;, &#39;day&#39;], axis=1).columns,columns=[&#39;importance&#39;]).sort_values(&#39;importance&#39;, ascending=False) print(feature_importances)print(np.sqrt((-output[&#39;test_score&#39;]).mean()))5. 예측력이 떨어질 때에는 특정 구간을 묶어서 분류의 형태로 회귀를 접근할 수 있다bins = np.arange(200,1400,50)train[&#39;중식계_cut&#39;] = pd.cut(train[&#39;중식계&#39;], bins=bins)train[&#39;석식계_cut&#39;] = pd.cut(train[&#39;석식계&#39;], bins=bins)이는 어떤 논문에서 얻어낸 아이디어이다. 기회가 되면 구현해보도록 하겠다. 이글은 데이콘 ‘레이’님의 코드 공유 글을 참조했습니다." }, { "title": "Boostrap", "url": "/posts/bootstrap/", "categories": "", "tags": "datascience, datamining, machinelearning", "date": "2021-07-28 00:00:00 +0900", "snippet": "bagging은 boostrap을 기반으로 한 앙상블 방법 중 하나 입니다. 다음 글에서는 bagging과 boosting에 대한 비교 글을 적을 예정인데 그에 앞서, bagging에서 빠질 수 없는 boostrap 에 대해 다시 한번 정리하고자 합니다.1. 경험분포함수Sample\\(\\{X_1, X_2, ..., X_n\\}\\\\)에 대해 모집단 분포함수 F의 추정치로 경험분포함수 \\(\\hat{F}_n(x) = \\frac{1}{n} \\sum I(X_i \\leq x)\\)를 고려하자.일반적으로 경험분포함수는 다음과 같은 성질을 가진다\\(n\\hat{F}_n(x) = \\sum I(X_i \\leq x) \\ \\ \\sim B(n, F(x))\\)\\[1. \\ \\ unbiased : E(\\hat{F}_n(x)) = F(x) \\\\\\\\ 2. \\ \\ variance : \\frac{1}{n}F(x)(1-F(x))\\]2. bootstrap 알고리즘경험분포함수를 통해 볼 때, 모평균 F(x)는 표본평균으로 점추정 된다. 또한 중심극한정리를 통해 구간 추정 또한 가능하다. 그러나 소표본인 경우는 이와 다르다. Boostrap은 통계량에 대한 분포를 모르는 상황에서 이에 대한 구간추정을 만들어 낸다. 이는 처음에 가지고 있는 표본이 정규분포를 따르지 않아도 된다라는 데서 큰 이점을 갖는다.step 1반복 횟수를 k 라고 하면 표본에서 등확률 복원추출을 통해 새로운 표본 set을 만들어 낸다\\(\\{X_1, X_2, ..., X_n\\}\\ \\longrightarrow X^{*(k)} = \\{x_1^*,x_2^*,...,x_n^* \\}\\\\)step 2theta 에 대한 통계량 theta hat을 bootstrap 표본을 통해 추정한다. 즉\\(\\hat\\theta = \\theta(X_1,X_2, ... , X_n)\\)을 추정하기 위해\\[\\hat\\theta^{*(1)},\\hat\\theta^{*(2)},...,\\hat\\theta^{*(K)}\\]에 대한 경험분포를 이용하는 것이다.즉, 표본을 활용해 모수를 추정하는 추정량을 구하고, 이 추정량에 대해 신뢰구간을 구하는 것처럼, 소표본의 경우에 등확률 복원추출을 통해 추정량에 대한 표준오차를 다시 추정해서 신뢰구간을 구할 수 있다는 것이다.추정량의 표준오차에 대한 Boostrap 추정\\(\\hat {se}(\\hat\\theta) = \\sqrt{ \\frac{1}{n-1} \\sum^K (\\hat\\theta^{*(k)} - \\bar{\\hat\\theta^*}) }\\)추정량의 bias 에 대한 Boostrap 추정\\(\\hat{bias}(\\hat\\theta) = \\bar{\\hat\\theta^*} - \\hat\\theta\\)추정량에 대한 구간추정\\(\\hat\\theta에 \\ 대해 \\ \\hat\\theta^{*(1)},\\hat\\theta^{*(2)},...,\\hat\\theta^{*(K)} \\ 의\\ \\ \\alpha / 2 \\ 와 \\ \\ 1-\\ \\alpha / 2 \\ 분위수\\) 회귀계수에 대한 구간추정 또한 마찬가지이다.3. Bootstrap 알고리즘 실험 with RR에서 boot 패키지 안의 aircondit 데이터는 기계의 고장간의 시간을 나타낸다. 이때 고장간의 시간이 모수가 lambda인 지수분포를 따른다고 할 때 이에 대한 최대가능도 추정값은\\(\\frac{1}{\\bar{X}}\\)이다. 이 때 MLE의 bias와 standard error 에 대한 boostrap 추정값을 구해보자set.seed(2020)library(boot)data(&quot;aircondit&quot;)x=airconditrate = function(x, i){return(1/mean(as.matrix(x[i,])))}boot(x, statistic = rate, R=2000)#ORDINARY NONPARAMETRIC BOOTSTRAP# Call:# boot(data = x, statistic = rate, R = 2000)# Bootstrap Statistics :# original bias std. error# t1* 0.00925212 0.001210366 0.004185513** 이 글은 서울시립대학교 통계학과 박창이 교수님의 통계 계산 과목의 강의자료를 참고했습니다." }, { "title": "Dacon - 구내식당 식수 인원 예측 AI 경진대회", "url": "/posts/dacon(2)/", "categories": "", "tags": "datascience, dacon, machine learning", "date": "2021-07-28 00:00:00 +0900", "snippet": "이번 글에서는 더 좋은 성능을 낸 참여자의 모델을 가지고와서 제가 전처리한 데이터에 적합시켜 보도록 하겠습니다.우선 첫 번째 모델로 pycaret 패키지를 활용한 AutoML 을 구현해보도록 하겠습니다.결과적으로 이 모델의 성능은 그리 좋지 않았습니다. 실제로 이 모델을 사용한 참가자와는 전처리 방식도 다르고 몇가지 feature 또한 다르기 때문일 것이라 생각합니다. 그럼에도 불구하고 pycaret 패키지는 최초 모델 탐색시에 매우 유용한 기능을 할 것이라 생각이 듭니다.제 노트북으로는 pycaret을 돌리는데에는 한계가 있어…. 구글 colab을 활용해서 결과를 도출해냈습니다.#!pip install pycaret[full] #모든 모델들을 불러오기 위해 full을 추가합니다import pandas as pdfrom pycaret.regression import *#코랩에 데이터셋 가져오기 위해 mount 하기from google.colab import drivedrive.mount(&#39;/content/drive&#39;)train = pd.read_csv(&quot;/content/drive/MyDrive/train.csv&quot;)test = pd.read_csv(&quot;/content/drive/MyDrive/test.csv&quot;)#datetime으로 변환train[&#39;일자&#39;]=pd.to_datetime(train[&#39;일자&#39;])test[&#39;일자&#39;] = pd.to_datetime(test[&#39;일자&#39;])#traintrain[&#39;년&#39;] = train[&#39;일자&#39;].dt.yeartrain[&#39;월&#39;] = train[&#39;일자&#39;].dt.monthtrain[&#39;일&#39;] = train[&#39;일자&#39;].dt.daytrain[&#39;주&#39;] = train[&#39;일자&#39;].dt.weektrain[&#39;요일&#39;] = train[&#39;일자&#39;].dt.weekdaytrain[&#39;출근&#39;] = train[&#39;본사정원수&#39;]-(train[&#39;본사휴가자수&#39;]+train[&#39;본사출장자수&#39;]+train[&#39;현본사소속재택근무자수&#39;])train[&#39;휴가비율&#39;] = train[&#39;본사휴가자수&#39;]/train[&#39;본사정원수&#39;]train[&#39;출장비율&#39;] = train[&#39;본사출장자수&#39;]/train[&#39;본사정원수&#39;]train[&#39;야근비율&#39;] = train[&#39;본사시간외근무명령서승인건수&#39;]/train[&#39;출근&#39;]train[&#39;재택비율&#39;] = train[&#39;현본사소속재택근무자수&#39;]/train[&#39;본사정원수&#39;]train[&#39;출장휴가재택비율&#39;] = train[&#39;출장비율&#39;] + train[&#39;휴가비율&#39;] + train[&#39;재택비율&#39;]#testtest[&#39;년&#39;] = test[&#39;일자&#39;].dt.yeartest[&#39;월&#39;] = test[&#39;일자&#39;].dt.monthtest[&#39;일&#39;] = test[&#39;일자&#39;].dt.daytest[&#39;주&#39;] = test[&#39;일자&#39;].dt.weektest[&#39;요일&#39;] = test[&#39;일자&#39;].dt.weekdaytest[&#39;출근&#39;] = test[&#39;본사정원수&#39;]-(test[&#39;본사휴가자수&#39;]+test[&#39;본사출장자수&#39;]+test[&#39;현본사소속재택근무자수&#39;])test[&#39;휴가비율&#39;] = test[&#39;본사휴가자수&#39;]/test[&#39;본사정원수&#39;]test[&#39;출장비율&#39;] = test[&#39;본사출장자수&#39;]/test[&#39;본사정원수&#39;]test[&#39;야근비율&#39;] = test[&#39;본사시간외근무명령서승인건수&#39;]/test[&#39;출근&#39;]test[&#39;재택비율&#39;] = test[&#39;현본사소속재택근무자수&#39;]/test[&#39;본사정원수&#39;]test[&#39;출장휴가재택비율&#39;] = test[&#39;출장비율&#39;] + test[&#39;휴가비율&#39;] + test[&#39;재택비율&#39;]식수인원수와 관계가 큰 야근 신청 인원수 데이터의 이상치를 제거한다(이에 관한 것은 추후 업로드 할 것임)#이상치 제거#IQR을 사용해서 이상치 제거하기#sns.boxplot(x=&#39;요일&#39;, y = &#39;본사시간외근무명령서승인건수&#39;, data=train)#월iqr = np.quantile(train[train[&#39;요일&#39;]==0].본사시간외근무명령서승인건수, 0.75) - np.quantile(train[train[&#39;요일&#39;]==0].본사시간외근무명령서승인건수, 0.25)iqr*1.5upper = np.quantile(train[train[&#39;요일&#39;]==0].본사시간외근무명령서승인건수, 0.75) + iqr*1.5lower = np.quantile(train[train[&#39;요일&#39;]==0].본사시간외근무명령서승인건수, 0.25) - iqr*1.5mask_time = (train[train[&#39;요일&#39;]==0].본사시간외근무명령서승인건수 &amp;gt; upper) | (train[train[&#39;요일&#39;]==0].본사시간외근무명령서승인건수 &amp;lt; lower)mask_time2 = (train[&#39;중식계&#39;] &amp;lt;= upper) &amp;amp; (train[&#39;중식계&#39;] &amp;gt;= lower)train_outliers=train[train[&#39;요일&#39;]==0][mask_time]List = list(train_outliers.index)List #705 실제 train 데이터에서 엑셀 기준 707for i in List : train.drop(index=i, inplace=True) #화 (실제로 예측해야할 데이터들이 화요일에 야근이 많다 따라서 크다고 여겨지는 이상치는 이상치가 아니다)iqr = np.quantile(train[train[&#39;요일&#39;]==1].본사시간외근무명령서승인건수, 0.75) - np.quantile(train[train[&#39;요일&#39;]==1].본사시간외근무명령서승인건수, 0.25)iqr*1.5upper = np.quantile(train[train[&#39;요일&#39;]==1].본사시간외근무명령서승인건수, 0.75) + iqr*1.5lower = np.quantile(train[train[&#39;요일&#39;]==1].본사시간외근무명령서승인건수, 0.25) - iqr*1.5mask_time = (train[train[&#39;요일&#39;]==1].본사시간외근무명령서승인건수 &amp;lt; lower)mask_time2 = (train[&#39;중식계&#39;] &amp;lt;= upper) &amp;amp; (train[&#39;중식계&#39;] &amp;gt;= lower)train_outliers=train[train[&#39;요일&#39;]==1][mask_time]List = list(train_outliers.index)List #152, 163, 223, 453*, 467, 951, 955, 1165*, 1170*, 1175* *별표는 큰 이상치for i in List : train.drop(index=i, inplace=True) #수iqr = np.quantile(train[train[&#39;요일&#39;]==2].본사시간외근무명령서승인건수, 0.75) - np.quantile(train[train[&#39;요일&#39;]==2].본사시간외근무명령서승인건수, 0.25)iqr*1.5upper = np.quantile(train[train[&#39;요일&#39;]==2].본사시간외근무명령서승인건수, 0.75) + iqr*1.5lower = np.quantile(train[train[&#39;요일&#39;]==2].본사시간외근무명령서승인건수, 0.25) - iqr*1.5mask_time = (train[train[&#39;요일&#39;]==2].본사시간외근무명령서승인건수 &amp;gt; upper) |(train[train[&#39;요일&#39;]==2].본사시간외근무명령서승인건수 &amp;lt; lower)mask_time2 = (train[&#39;중식계&#39;] &amp;lt;= upper) &amp;amp; (train[&#39;중식계&#39;] &amp;gt;= lower)train_outliers=train[train[&#39;요일&#39;]==2][mask_time]List = list(train_outliers.index)List #세자리, 네자리 수인 2,9,14,18 만 지우겠다. train.drop(index=2, inplace=True)train.drop(index=18, inplace=True)train.drop(index=652, inplace=True)train.drop(index=894, inplace=True)#목iqr = np.quantile(train[train[&#39;요일&#39;]==3].본사시간외근무명령서승인건수, 0.75) - np.quantile(train[train[&#39;요일&#39;]==3].본사시간외근무명령서승인건수, 0.25)iqr*1.5upper = np.quantile(train[train[&#39;요일&#39;]==3].본사시간외근무명령서승인건수, 0.75) + iqr*1.5lower = np.quantile(train[train[&#39;요일&#39;]==3].본사시간외근무명령서승인건수, 0.25) - iqr*1.5mask_time = (train[train[&#39;요일&#39;]==3].본사시간외근무명령서승인건수 &amp;lt; lower)mask_time2 = (train[&#39;중식계&#39;] &amp;lt;= upper) &amp;amp; (train[&#39;중식계&#39;] &amp;gt;= lower)train_outliers=train[train[&#39;요일&#39;]==3][mask_time]List = list(train_outliers.index) #TESTSET에 746 정도가 있기 때문에 매우 작은 것과 800 이상의 점 두개를 지운다.List for i in List : train.drop(index=i, inplace=True)mask_time = (train[train[&#39;요일&#39;]==3].본사시간외근무명령서승인건수 &amp;gt; upper)train_outliers=train[train[&#39;요일&#39;]==3][mask_time]List = list(train_outliers.index) #TESTSET에 746 정도가 있기 때문에 매우 작은 것과 800 이상의 점 두개를 지운다.List #415, 1137train.drop(index=415, inplace=True)train.drop(index=1137, inplace=True)#금iqr = np.quantile(train[train[&#39;요일&#39;]==4].본사시간외근무명령서승인건수, 0.75) - np.quantile(train[train[&#39;요일&#39;]==4].본사시간외근무명령서승인건수, 0.25)iqr*1.5upper = np.quantile(train[train[&#39;요일&#39;]==4].본사시간외근무명령서승인건수, 0.75) + iqr*1.5lower = np.quantile(train[train[&#39;요일&#39;]==4].본사시간외근무명령서승인건수, 0.25) - iqr*1.5mask_time = (train[train[&#39;요일&#39;]==4].본사시간외근무명령서승인건수 &amp;gt; upper) | (train[train[&#39;요일&#39;]==4].본사시간외근무명령서승인건수 &amp;lt; lower)mask_time2 = (train[&#39;중식계&#39;] &amp;lt;= upper) &amp;amp; (train[&#39;중식계&#39;] &amp;gt;= lower)train_outliers=train[train[&#39;요일&#39;]==4][mask_time]List = list(train_outliers.index)List # 400이상인 895번 index만 삭제한다.train.drop(index=895, inplace=True)#train에서 결측치 이상치 제거하기mask_oo = train[&#39;일자&#39;] != &#39;2017-09-27&#39; train = train[mask_oo]mask_ooo = train[&#39;일자&#39;] != &#39;2018-02-14&#39;train = train[mask_ooo]trainmask_0 = train[&#39;석식계&#39;]!=0train = train[mask_0]train점심 데이터 적합caret = setup(data = train_lunch, target = &#39;중식계&#39;, categorical_features = [&#39;월&#39;,&#39;요일&#39;]) #실행시키고 엔터 한번 더 눌러줘야한다.best_lunch = compare_models(sort=&#39;MAE&#39;, n_select=2)blend_lunch = blend_models(estimator_list= best_lunch, optimize=&#39;MAE&#39;)pred_holdout = predict_model(blend_lunch)#블랜딩final_model = finalize_model(blend_lunch)predictions_lunch = predict_model(final_model, data = test2)aa = predictions_lunch[&#39;Label&#39;]저녁 데이터 또한 위와 마찬가지로 적합하면 다음과 같은 결과를 얻을 수 있다즉 피처 엔지니어링 이후 모델 적합할 때 성능이 좋은 모델 몇개를 빠르게 추려낼 수 있다는 장점이 있는 것 같다. 내가 최종적으로 제출한 모델 또한 catboost를 활용했는데 여기서도 MAE를 기준으로 제일 성능이 좋음을 알 수 있다.pycaret에 대해 추가적인 설명을 덧붙이자면 다음과 같다.setup() : 주어진 데이터를 모델 별로 적합시킬 준비를 마친다compare_models() : 모델별 비교를 한다. sort를 통해 우선적으로 보고 싶은 평가 척도를 제시한다. 또한 n_select를 통해 선택할 모델의 개수를 설정할 수 있다.blend_models() : 앙상블의 일종으로 블랜딩 앙상블을 실행한다. stack_models() : 앙상블의 일종으로 스태킹 앙상블을 실행한다.ensemble_models() : 앙상블 중 배깅을 통해 모델을 만들어 낸다. method = &#39;boosting&#39; 을 통해서 부스팅을 통한 앙상블 모형을 만들 수 있다. creat_models() : compare_models() 의 결과를 통해 얻은 모델 중 일부를 선택해서 모델을 만든다.※추가로 7월 29일자로 새로운 분이 pycaret을 통해 private 10위를 하신 것을 확인했다. 이 분은 블랜딩과정에서 5개를 가져왔는데 이를 통해 overfitting 방지를 잘 하신 것 같다. 특히 이번 대회에서 test set의 특성이 train set과 다를것이라는 예상을 했다면 더 많은 모델을 블랜딩함으로써 모델의 일반성을 유지할 수 있었을 것 같다.*이 글은 데이콘 ‘찰진식수인원’ 님과 ‘학식의신’님의 코드 공유 글을 참고했습니다." }, { "title": "Dacon - 구내식당 식수 인원 예측 AI 경진대회", "url": "/posts/dacon(1)/", "categories": "", "tags": "datascience, dacon, machine learning", "date": "2021-07-28 00:00:00 +0900", "snippet": "처음으로 참여했던 데이콘 대회에서 프로젝트 과정 중에 느끼고 배웠던 내용들을 정리해보고자 합니다.이 글은 그에 대한 첫 번째 글로써, 프로젝트에 대한 개괄적 설명과 프로젝트를 진행하면서 고민했던 점을 글로 남겨보도록 하겠습니다. 파이썬을 사용해서 프로젝트를 진행했기 때문에 다소 미흡한 부분이 있습니다. 앞으로 파이썬 실력을 키우기 위해 더욱 노력해야 하겠습니다.public 순위 : 162등,private 순위 : 81등1. 대회 데이터 설명이 대회는 한국토지주택공사(이하 LH)가 주최한 대회로, 중식과 석식 식수인원을 예측하는 데에 목적이 있습니다. train data set와 test data set의 column은 다음과 같습니다.pd.set_option(&#39;display.max_columns&#39;, 100)pd.set_option(&#39;display.max_rows&#39;, 100)train = pd.read_csv(&quot;/dacon/주차/train.csv&quot;)test = pd.read_csv(&quot;/dacon/주차/test.csv&quot;)train.columns#Index([&#39;일자&#39;, &#39;요일&#39;, &#39;본사정원수&#39;, &#39;본사휴가자수&#39;, &#39;본사출장자수&#39;, &#39;본사시간외근무명령서승인건수&#39;,&#39;현본사소속재택근무자수&#39;, &#39;조식메뉴&#39;, &#39;중식메뉴&#39;, &#39;석식메뉴&#39;, &#39;중식계&#39;, &#39;석식계&#39;],dtype=&#39;object&#39;)test.columns#Index([&#39;일자&#39;, &#39;요일&#39;, &#39;본사정원수&#39;, &#39;본사휴가자수&#39;, &#39;본사출장자수&#39;, &#39;본사시간외근무명령서승인건수&#39;,&#39;현본사소속재택근무자수&#39;, &#39;조식메뉴&#39;, &#39;중식메뉴&#39;, &#39;석식메뉴&#39;],dtype=&#39;object&#39;)train.shape#(1205,12)test.shpae#(50,10)특이한 점은 데이터의 절대적인 개수가 다른 대회에 비해 매우 적은 편이며, column 또한 매우 적습니다. 즉, 1200개의 데이터를 가지고 의미있는 모델을 만들기 위해서는 변수의 개수를 잘 통제해서 ‘차원의 저주’에 빠지지 않도록 해야하며, 딥러닝 모델을 사용하기는 어렵지 않을까 하는 생각을 했습니다.2. 대회 도중의 시행착오와 해결책1. 시계열 데이터를 다루는 방법이번 대회는 시계열 데이터를 다루고 있습니다. 통계학적 측면에서 볼 때 시계열 자료의 특성상 자기 상관성을 가지고 있고 저는 이를 어떻게 처리할 수 있을 지에 대한 고민을 많이 했습니다. K-fold cross validation 같은 경우에도 함부로 데이터를 나누게 되면 미래의 데이터로 과거를 검증하게 되는 문제가 발생합니다. 또한 전통적으로 통계학적 관점에서 시계열 데이터를 다루는 방법인 ARIMA같은 경우에는 오로지 시간만을 가지고 분석을 하기 때문에 그 자체로 한계를 가진다고 생각했습니다. 페이스북에서 만들어낸 prophet 같은 알고리즘 또한 시간을 제외한 다양한 변수를 고려하기에는 한계가 있었고, 신경망 알고리즘에서 시간이라는 변수를 추가할 수 있는 RNN이나 LSTM 같은 딥러닝 알고리즘 또한 대회에서 제공하는 데이터의 row가 너무 작기 때문에 한계가 있었습니다.결과적으로 시간을 나타내는 데이터를 년,월,일,요일로 모두 쪼개어서 데이터를 새롭게 인코딩했고 꽤나 괜찮은 성능을 만들어내었습니다. 이는 제가 생각한 방법이 아니라 캐글이나 데이콘에서 ranking이 높은 사람들 또한 시계열 데이터를 위와 같이 접근하는 것을 보고 따라서 적용해 본 것입니다. 그럼에도 불구하고 이러한 방식을 통해 데이터가 가지고 있는 계절성과 자기상관성을 충분히 모델에 반영한 것인지는 의문이 듭니다. 또한 년/월/일/주/요일을 모두 one-hot encoding으로 변환하면 차원이 매우 커진다는 문제가 발생해서 일부의 columns은 사용하지 않았습니다. 이러한 부분은 ‘‘시간’‘에 대한 충분한 고려가 되었는지 의문이 들게 하는 부분입니다. 그럼에도 불구하고 기존 이론에 얽매이지 않고 한정된 데이터에서 어떻게 하면 좋은 결과를 찾아낼 수 있을지, 기존 상황을 극복하기 위해서 어떤 방법으로 문제를 해결해 나가야 할 지에 대해 생각을 많이 해본 경험이었습니다.2 . feature engineering의 중요성뛰어난 성능을 가지기 위해서는 어떠한 모델을 사용할 것인가 보다 핵심 변수/ 영향력 있는 변수가 무엇인지 찾아내는 것이 훨씬 중요하다는 것을 깨달았습니다. 흔히 우리는 머신러닝에서 최대한 많은 정보를 집어 넣으면 기계가 알아서 유의미한 정보를 뽑아내줄 것이라는 착각에 빠지게 됩니다. 저 또한 통계학을 배우면서 ‘차원의 저주’라는 말을 수없이 들었음에도 처음 모델을 짤 때에는 적당히 유의미하다고 여겨지는 변수를 모두 넣어보려는 시도를 했습니다. 만약 얻을 수 있는 데이터의 개수가 매우 많다면 상관없겠지만, 현실에서 이는 사실상 불가능 합니다. 따라서 한정된 데이터를 가지고 분류나 회귀의 모델을 만들 때에는 데이터를 잘 설명해주는 feature를 잘 뽑아내는 것이 중요했습니다.저는 데이터 전처리를 끝내자마자 모든 변수를 넣고 최선의 모델이 무엇일지, 최적의 하이퍼파라미터는 무엇일지에 찾는 데에만 많은 시간을 보냈습니다. xgboost나 LGBM과 같이 자주 들어오던 트리 기반의 모델들이 알아서 데이터 속에 내재된 숨겨진 패턴들을 찾아줄 것이라고 착각했던 것 같습니다. 그러나 차원이 너무 큰 데에 반해 데이터 수는 상대적으로 작아 원하는 성능을 얻기는 어려웠습니다. 이때 저는 외부데이터를 가지고 와서 ‘확진자수’, ‘현재 기온’, ‘강수량’ 같은 영향력 있는 feature를 찾아내었고 보다 성능을 향상시킬 수 있었습니다. 대회 이후 순위권에 올라가신 다른 분들의 코드를 보니 다른 참여자분들은 불쾌지수, 그리고 메뉴데이터 임베딩을 통해 새로운 feature들을 잡아내셨습니다.이를 통해 추후 데이터 분석에서는 모델에 집중하기 보다는 데이터 전처리와 feature 추출에 보다 많은 시간을 투자해서 데이터 자체에 대해 깊은 이해를 해 나가야 한다고 생각했습니다. 그리고 또한 다중공선성을 고려할 때 재귀적 방식으로 가장 성능이 높은 변수를 추출해주는 코드 또한 존재한다는 것을 알게되었습니다. 이를 활용한다면 feature engineering을 하는 데 큰 도움이 될 것이라 생각합니다.3. Domain 지식의 중요성feature engineering의 중요성에 대한 연장선상에서 domain 지식 또한 중요함을 몸소 체험했습니다. 머신러닝을 위해 데이터를 전처리하고 중요한 특징(feature)를 찾아내야만 알고리즘의 성능이 좋아지는데 이를 위해서는 분석하고자 하는 정보에 대한 지식이 매우 중요함을 깨달았습니다. 이번 대회에서도 예측하고자 하는 식수인원이 야근신청인원과 큰 상관관계를 가지고 있었는데, 이 야근신청인원이 9월에서 11월 사이에 주기적으로 상승하는 부분이 왜 발생하는지, 우연에 의해서 발생한 것인지 궁금했었습니다. 제가 그 회사 직원이 아니기 때문에 이를 명확하게 알기는 어려웠으나 만약 한국주택토지공사 본사 직원이 이에 대해 설명해준다면 이상치 처리나 특징 추출 단계에서 이를 잘 반영할 수 있었을 것입니다.저는 통계적 분석 능력을 가지고 머신러닝 구현능력과 알고리즘에 남들보다 특화된 인재가 되고 싶기 때문에 분석 대상에 대한 도메인 지식이 부족할 수 밖에 없습니다. 따라서 머신러닝을 통해 문제를 해결할 때에는 도메인 지식을 가진 분과의 협업이 매우 중요하며, 협업의 과정에서 생기는 마찰들을 잘 조율하는 것 또한 성능을 결정짓는데 중요할 것이라 생각됩니다.4. data set 자체에 대한 이해 (train / test)모델을 만들때에는 현재 가지고 있는 데이터를 최적화하는 모델을 만들지만, 실제로 이 모델을 사용하고자 할 때는 완전히 새로운 데이터를 사용하게 됩니다. 이는 모델의 일반성과도 연결되는 부분인데, 테스트 하고자 하는 데이터가 기존의 데이터와 다른 분포를 가지고 있거나, 어떤 외부적인 일로 새로운 경향을 나타내게 될 때는 이를 고려해서 모델을 보다 일반화시키는 것이 중요하다는 생각이 들었습니다. 대회에서 테스트하고 싶은 데이터는 21년 2,3,4월 데이터로 이 당시 LH 땅 투기 사태로 인해 전반적으로 야근인원이 늘었고 식수 인원 또한 직전 분기에 비해 다른 추세를 보일 것이라 생각했었습니다. k-fold 교차 검증에서 상대적으로 모델의 성능이 좋지 않았음에도 불구하고, 모델의 일반성에 초점을 맞춘 결과 테스트 하고자 하는 데이터를 보다 잘 맞출 수 있었습니다. 추후 분석에도 데이터의 분포와 외부적인 상황을 복합적으로 고려할 줄 아는 분석가가 되어야겠다고 생각했습니다." } ]
