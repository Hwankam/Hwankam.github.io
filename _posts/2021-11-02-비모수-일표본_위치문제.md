---
layout : post
title : Nonparametric - one sample location
subtitle : permutation test
date : 2021-11-02
#categories:
tags : [Nonparametric, permutation test]
toc_sticky : True
use_math : true
comments: true
---

범주형 자료분석의 보조자료를 정리한 글이다. 비모수통계학의 일표본 위치문제와 permutation test에 관한 내용들을 정리해보겠다.

## 1. Two-sample location problem

### 1.1 Independent sample


Test

* Parmetric test : independent two sample t-test
* Permutation test(resampling method의 일종으로 permutation test는 p-value를 찾는데 사용하며 without-replacement를, bootstrap의 경우 SE 추정을 하며 with-replacement를 사용한다)
* Non-parametric test : Wilcoxon rank sum test, Mann-Whitney test

<br>

#### parametric test

Assumtion :
$ N(\theta_x, \sigma^2) , N(\theta_y,\sigma^2)$ (homoscadescity) 
(*Normality*)

Null hypothesis : $\theta_x = \theta_y $  

Test statistic : $T = \frac {\bar Y - \bar X - (\theta_y - \theta_x)} {S_p \sqrt{1/m + 1/n}} \sim t_{m+n-2}$ 


<br>

#### Wilcoxon Rank Sum Test (여기서도 exact test 와 asymtotic test 로 나뉜다)

Two sample t test 와 달리 정규성가정이 필요없다(: 비모수적 검정)
**그러나 윌콕슨 순위검정은 샘플들을 섞기 때문에 등분산에 대한 가정은 존재해야만 샘플을 섞는것이 의미 있을 것이다**

Null hypothesis : $\theta_x = \theta_y $  

Test statistic : $W = \sum_i R_i$

이 때 $R_i$는 두 집단의 샘플을 마구 섞은 뒤, 순위를 매기고 그 중 Y 샘플에 해당하는 순위만을 합한 것.  
X 샘플에 해당하는 순위를 매기고 이를 합한 것을 $W'$라고 하면 
$W +  W' = N(N+1)/2$

예시) X sample 두개, Y sample 두개 인 경우 $W$의 분포는 아래와 같을 것이다.

<img src='{{"/assets/img/cda_non_1.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

* Exact test 

위 상황에서 우리가 얻은 샘플이 $W = 3$ 이라면, 대립가설이 
$\theta_x \neq \theta_y$ 일 때, p-value는
$ W = 3 \ and \  7 $일 때의 확률값을 더해주면 된다. 따라서 p-value = 1/3  

만약 대립가설이 $\theta_x > \theta_y$ 라면 p-value는 
$ W \leq 3 $일 때의 확률값을 더해주면 된다. 따라서 p-value = 1/6  

만약 대립가설이 $\theta_x < \theta_y$ 라면 p-value는 
$ W \geq 3 $일 때의 확률값을 더해주면 된다. 따라서 p-value = 1  




*참고* 

추가적으로 $ W $의 평균과 분산을 구할 수 있다.

$p(R_i = s) = 1/N \ \ , \ S = 1,2,...,N$ 일 때  

$E(W_0) = n(N+1)/2 \ \ , \ \ $
$Var( W_0) = nm(N+1)/12$  

<br>




* Asympototic test -> Normal

CLT 에 의해, $ W \sim N(E(W), Var(W))$ 이므로 이를 활용해서 Z 값을 만들어 준다.

<br>

#### t-statistics-based permutation test 1

permutation test 는 t 통계량(어떠한 통계량이든 상관없음)을 가져다 쓰나, t-분포를 요구하지는 않는다. 그 말인 즉슨 Normality 가정을 요구하지 않고 empirical distribution으로부터 가설검정을 하겠다는 것이다. 

B번의 permutations이 행해진 뒤에 아래와 같은 값으로 p-value를 구한다.(permuation의 최대 횟수는 샘플의 개수에 따라 다르다)

$$
p = \frac {\sum I(|t^{b}| \geq |t_0|)} {B}
$$

*permutation test는 exact p-value를 구한다*

<br>

#### t-statistics-based permutation test 2

Assumtion : $N(\theta_x, \sigma_x^2) , N(\theta_y,\sigma_y^2)$ (homoscadescity) 
(*Normality*)

Null hypothesis : $\theta_x = \theta_y $  

statistic : $T = \frac {\bar Y - \bar X} {\sqrt{S_1^2/m + S_2^2/n}} $

통계량을 사용해서 permutation test 진행


<br>

#### t-statistics-based permutation test 3

프린트 상으로는 여기에 같이 설명되어 있으나, 이것은 one-sample location 문제이다.

$X_i \sim \ iid \ f_{\theta}(x) = f_0(x-\theta)$

Null hypothesis : $\theta = \theta_0 $  

Test statistic : T = $\frac {\bar X - \theta_0} {S/\sqrt{n}} \sim t_{n-1} $

이제 statistic 을 활용해서 permutation test를 진행한다. 

permuation을 하기 위해서는 부호를 사용한다. f 의 평균이 $\theta$이므로 이를 shift 해서 
$x_i - \theta$ 의 샘플을 만들고 난 뒤, 부호를 준다.  
sample 
{ $x_i - \theta $ }를 모아놓은 벡터와 (-1,1)에서 샘플 개수 n개 만큼 복원 추출한 벡터를 서로 element-wise product하고, 
이를 활용해서 통계량 $T^b$ 를 구한다. 이를 B번 반복해서 p-value를 구한다.

$$
p = \frac {\sum I(|T^{b}| \geq |T_0|)} {B}
$$


<br>

##### Comparison of Wilcoxon test with permutation test


|                          | t-test                          | t-permutation                          | Wilcoxon      |
| ---------------------    | ------------------------------- | ----------------------------------     | -------       |
| Distribution             | Normal                          | No                                     | No            |
| Information              | Mean, Variance                  | Mean, Variance                         | Rank          |
| Robustness to skewness   | No                              | Yes                                    | Yes           |
| Robustness to outliers   | No                              | No                                     | Yes           |

<br>



Wilcoxon rank test는 robustness to outlier 이지만 정보를 모두 순위로 바꾸기 때문에 오히려 정보를 잃어버린다는 단점.

<br>

#### parametric test

샘플이 pair 이므로 correlation이 존재한다 $\Longrightarrow T = \frac {\bar Y - \bar X - (\theta_y - \theta_x)} {S_p \sqrt{1/m + 1/n}} $ 를 사용할 수 없고 
$T = \frac {\bar Y - \bar X - (\theta_y - \theta_x)} {SE(\bar D)} \sim T_{n-1} $ 만을 사용해야 한다. 


<br>

#### Non-parametric test

1. 샘플의 부호를 모두 제거한 채로 오름차순 정렬한 뒤, 순위값 $R_i$을 준다
2. $T = \sum sgn(X_i) R_i$ 으로 test statistic을 정한다. 
3. p-value 계산


<br>

## 2. One-way ANOVA probelm

One-way는 factor(treatment) 가 하나인 경우   
ANOVA는 two sample test 를 확장해서 여러개의 샘플(집단)을 비교하는 것.   
one-way ANOVA 가정 : 등분산성이 기본가정!, 만약 두 집단의 분산이 다르다면? $\rightarrow $ log transformation 해준 다음에 ANOVA 해줘야 함.

#### Parmetric method 

<img src='{{"/assets/img/cda_non_2.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

test statistic $F = \frac {SStr/(k-1)} {SSE/(N-k)} \sim F_{k-1, N-k}$


<br>

#### Non-parametric method

Kruskal-Wallis test (wilcoxon rank test 의 확장) - Exact test

test statistic H 는 아래와 같다

$$
H = \frac {12}{N(N+1)} \sum_{i=1} ^k n_i(\bar R_{i.}- \bar R_{..})^2
$$


<br>


#### Permutation

방식은 동일하다. 통계량은 어떠한 것을 사용해도 괜찮기 때문

$$
p = \frac {\sum I(|F^{b}| \geq |F_0|)} {B}
$$



<br>

## 3. Correlation analysis

Test 

* Parmetric test : Pearson's correlation coefficient => t-test
* Permutation test
* Non-parametric test : Spearman rank correlation

#### Parmetric method

bivariate normal distribution으로부터 아래와 같은 변환으로 통해 t 분포를 유도할 수 있다

귀무가설 $H_0 : \rho = 0$ 로부터

$$
T = \sqrt{n-2} \frac {r} {\sqrt{1-r^2}} \ \ \sim t_{n-2}
$$

만약 normality 가정이 만족하지 않는다면 permuation test나 혹은 spearman rank correlation, Kendall rank correlation 을 사용한다.


<br>

#### Permuation test

paired data (X,Y)을 사용해서 새로운 데이터 set (X', Y') 을 만들 것이다.  
귀무가설 $H_0 : \rho = 0$ 이므로 귀무가설하에서는 x와 y가 서로 독립이므로 random하게 섞을 수 있다.


<br>

#### Non-parametric

spearman rank correlation : 두 집단의 샘플 내부에서 각각의 순위를 정해서 $R_i^X , R_i^Y$ 라고 한다. 이 때 Spearman correlation은

$$
R_s = \frac {\sum (R_i^X - \bar R)(R_i^Y - \bar R)} {\sqrt{\sum (R_i^X - \bar R)^2} \sqrt{\sum (R_i^Y - \bar R)^2}}
$$

where $\bar R = (n+1)/2 $

Asymtotic distribution을 구하고 싶다면, $\sqrt{n-1} R_s \sim N(0,1)$

참고 :  pearson sample corr 같은 경우 $ \gamma \approx N(\rho, \frac {(1-\rho^2)^2}{n}) $


<br>

## 4. Regression Analysis

#### Permutation test only
여기서부터는 Permutation tests for univariate or multivariate analysis of variance and regression - Marti J. Anderson 의 글을 참고했다.

permutation test 의 rationale :  

관찰값으로부터의 통계량과 귀무가설하에서 나올 수 있는 모든 경우의 통계량들의 분포를 비교하는 것. 이때 나올 수 있는 모든 경우라는 것은, 실험 디자인이 random하게 변하는 것으로부터 나오는 것이고 샘플자체, 그리고 error term은 바뀌지 않는 것이다. 즉 고정된 샘플에서 permuation이 행해지는 것을 의미한다.

실험 디자인이 random하게 변한다는 것은 test의 validity를 보장할 수 있다는 것이다. 즉 연구자가 정한 type 1 error 의 값을 유지하면서 실험 결과를 얻어낼 수 있다. 이것은 마치 일반적으로 perametric method of test에서 normality를 가정하거나 asymtotic normality를 얻는 것과 일맥상통한다고 할 수 있겠다.

<br>

##### simple linear regression

permutation test를 위해서는 귀무가설 하에서 exchangeable한 것을 찾아내야 한다.  
model $Y = \beta_0 + \beta_1 X + \epsilon $ 일 때, 귀무가설 
$H_0 : \beta_1 = 0$ 하에서는 Y 는 X와는 무관하기 때문에 이를 randomly permute 가능하다. 이후에는 permutation 된 (X,Y)를 사용해서 원하는 통계량을 구한 뒤 p-value를 찾아낸다. 

이러한 논리는 multiple linear regression $Y =  \beta_0 + \beta_1 X + \beta_2 Z + \epsilon $ 에서 귀무가설이 
$H_0 : \beta_1 = \beta_2 = 0$ 일 때에도 동일하게 적용될 것이다.  

<br>

##### multiple linear regression

multiple linear regression 중 partial regression에 대해 알아보면,

model : $Y =  \beta_0 + \beta_1 X + \beta_2 Z + \epsilon $ 

null hypothesis : $H_0 : \beta_2  = 0$ 

인 경우, 검정하고 싶은 대상은 "relationship between Y and Z given X 이다. simple linear regression과 동일한 논리로 접근하면, 귀무가설 하에서 무엇이 exchangeable 한 것인지 찾아야한다. 귀무가설 하에서의 model $ Y = \beta_0 + \beta_1 X + \epsilon $ 에서 
X 혹은 Y를 permute 하게 되면 $\beta_1$의 실제 값이 바뀌기 때문에 exchange에 주의해야 한다. 귀무가설하에서 실제로 exchange 가능한 것은 
$ Y - \beta_0 - \beta_1 X $ 인데 베타 값에 대한 참값을 알 수 없기 때문에 추정치인 
$\hat \beta$를 사용해서 잔차를 구하고 잔차를 permute 한다. 그런 다음 실제로 알고 싶은 관계를 나타내는 변수인 Z와 잔차의 linear 모델을 만들어서 귀무가설을 검정하게 된다. 

이외에도 multiple linear regression에서 몇가지 소개할 방법들이 있다. 

첫번째로 소개할 것은 R- package의 glmperm 작동원리가 되는 방법이다. 가설과 모델이 모두 위와 동일할 때, 귀무가설하에서 얻어낸 잔차값을 Z 를 대신해 모델에서 사용하는 것이다. 즉 잔차 $\gamma$에 대해 모델 
$Y =  \beta_0 + \beta_1 X + \beta_2 \gamma + \epsilon $ 을 가지고 test를 진행할 것이다. 

여기서는 LR statistic을 찾아낸다. 잔차값을 permutation(without replacement) 한 뒤 각각 case 에 대해서 LR statistic을 구해 카이제곱분포로 근사시켜 p-value까지 직접 구한다. 그런 다음 permutation case에 대한 p-value $p_b^*$ 에 대해 최종적인 p-value 로

$$
p = \frac {\sum I(p_b^* \leq f*p)} {B}
$$

로 p-value 를 구한다.(여기서 f의 값은 numerical instability를 고려한 1과 가까운 매우 작은 값이다.)

두번째로 소개할 방법은 만약 잔차를 계산하는 것의 비용이 많이 들 때의 해결방법이다. 이때는 X와 Z를 고정 시키고 Y를 permute 해서 귀무가설을 검정할 수는 있겠으나, 이 경우 X의 outlier가 존재할 때 상응하는 Y의 값이 random allocation에 의해 관계를 잃어버리게 된다는 한계가 있으므로 주의해야 한다 (sample size가 작을 때 좋을 것)

마지막 방법으로는 residual을 이용하되, 대립가설하에서 exchangeablility를 보는 것이다. 즉 full model하에서의 잔차를 구하고 permute 한 뒤, 이를 검증하고 싶은 변수와 적합해서 계수값에 대한 p-value를 구하는 것이다. 이 값은 각 가설하에서 error term의 분포에 기반한 검정이므로 표본이 매우 작을 경우에는 사용하기 어렵다( 표본이 크면 정규근사하기 때문에 error term의 분포가 각 가설하에서 다르더라도 표본이 클 경우 사용가능하다는 말!)