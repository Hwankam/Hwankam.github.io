---
layout : post
title : MCMC
subtitle : Monte Carlo, Markov Chain, M-H samplers, Gibbs sampler
date : 2021-08-05
#categories:
tags : [datascience, datamining, machinelearning, ISLR]
toc_sticky : true
use_math : true
comments: true
---

### Markov Chain Monte Carlo

흔히 줄여서 말하는 MCMC에 대해서 정리해보려고 한다.



우선 정상분포(stationary distribution)와 에르고딕(ergodic)이 무엇인지 알아보자(나무위키를 참조했습니다)

##### stationary란?

stationary distribution은 분포가 가진 통계적 특징, 즉 평균이나 모먼트, 분산 등이 시간에 따라 변하지 않는다는 것을 의미한다. 또한 stationary process란 확률분포가 시간에 따라 항상 동일함을 의미한다. 

##### ergodic란?

ergodic theory는 장시간동안 지속되는 dynamical system 안에서의 행동을 보고자 한다. 이 이론에서는 공간 안에 있는 각 점들이 장기적으로 볼 때 언젠가는 결국 다시 되돌아 온다는 것에 주목한다.(Poincaré recurrence theorem) 즉 ergodic system은 conservative system으로서 매우 안정화 되어있다.

* conservative system : such systems have no friction or other mechanism to dissipate the dynamics. thus their phase space does not shrink over time. precisely speaking, they are those dynamical systems that have a null wandering set.

  즉 쉽게 말해서 시스템이 매우 안정적이며 한번 만난 점은 결국 다시 만나게 된다(not dissipate). 



##### 그럼 irreducible은 무엇일까?

마코프 체인이 irreducible 하다고 말하는 것은 상태 i 에서 상태 j 로의 전이 확률값이 모두 양수인 것을 의미한다. 또한 irreducible Markov Chain에서는 특정 상태에 위치할 확률을 장기적으로 계산해서(극한으로?) 
$$
\pi_j
$$
라고 한다.



##### aperiodic 은?

state i에서 state i로의 전이확률값이 양수인 경우.  즉 모든 상태 i 에 대해 자기 자신으로 되돌아올 확률이 양인 chain.




이제 MCMC 알고리즘에 대해 설명해보겠다.

MCMC를 개략적으로 설명하자면,  target distribution이 stationary 일 때 그 분포로부터 표본을 추출하는 알고리즘의 한 부류이다(즉 목적은 sampling!). markov chain이 stationary 분포로 얼마나 빠르게 수렴할 수 있는지가 중요하다.



###### (1) markov chain 

$$
X_1, X_2, ... , X_N
$$
은 확률과정으로 
$$
P(X_{n+1} | X_1, ...,X_n) = P(X_{n+1}|X_n)
$$

이 때 irreducible 이고 ergodic 이면 n이 무한대일 때 X_n의 분포는 정상분포로 수렴한다. 그리고 이때에는 초기값 X_0와는 무관하다. 따라서 target distribution F로 부터 표본을 생성하기 위해서는 

1. 
   $
   P(X_{n+1} | X_n)
   $
   에서의 표본 생성이 쉬워야 한다. 

2. F가 markov chain의 정상분포여야 한다. 



###### (2) algorithm

1. 초기값 X_0 지정
2. 정상분포에 도달할 때까지 충분히 큰 N에 대해 X_n을 생성
3. 수렴진단 방법을 이용해서 수렴 여부 확인, 수렴 안되면 더 많은 관측값 생성
4. 정상분포에 도달하기 위한 burn-in 관측값(X_i)을 제거하고 이후의 X_n 들을 표본으로 선택.







##### 몬테카를로란?

위키피디아에 따르면 몬테카를로 방법이란 무수히 많은 무작위 추출을 통해 함수의 값을 확률적으로 계산하는 것을 말한다. 

###### 몬테카를로 적분(수치적분이 가능하면 수치적분을 사용한다 ex. 사다리꼴 공식, 심슨공식)

1. hit or miss Monte Carlo Method

<img src='{{"/assets/img/MCMC-1.jpg"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

사각형 중에서 I의 면적 비율이 p일 때 : I = c(b-a)p

사각형 중 함수 아래에 찍히는 점의 개수를 X 라고 하면
$$
X \sim B(N,p)
$$
이고 
$$
\hat p = X/N
$$

따라서 

$
\hat I = c(b-a)X/N
$

이 때 추정량의 분산을 작게 하기 위해서
$$
c = Max_{a\leq x \leq b}g(x)
$$
로 설정한다. 

또한
$$
p(|\hat I - I| < \epsilon) \geq 1 - \frac { Var(\hat I)}{\epsilon^2} \geq 1- \alpha
$$
이므로 I의 추정값이 주어진 오차한계 epsilon 내에서 100(1-a) % 신뢰도를 갖는 표본의 크기를 정하기 위해
$$
N = \frac {c^2(b-a)^2}{4\alpha \epsilon^2}
$$
을 사용



2. sample mean Monte Carlo integration

$
X \sim U(a,b) ==> E[g(x)] = \frac { 1}{b-a}\int g(x)dx
$

이므로 

$
\int g(x)dx = (b-a)E[g(x)]
$

따라서 넓이를 추정하면

$
\hat I = \frac {b-a}{N}\sum g(x_i), \ \ \ \ \ 난수 \ \ x_i \sim U(a,b)
$


###### 몬테카를로 추론

1. 점추정

$
X_1, X_2 \sim ^{iid} N(0,1)
$

에 대해

$
\theta = E|X_1 - X_2|
$

를 추정하기 위해서 표준정규분포에서 난수를 생성해서 

$
\hat \theta ^{(j)} = |x_1^{(j)} - x_2^{(j)}|
$

를 구하고 이를 가지고 평균을 내면 theta 값을 추정할 수 있다. 



2. 구간추정

$
X \sim F_x
$

일 때 모수 theta를 추정한다고 하자.

j 번째 랜덤표본
$$
X_1^{(j)},...,X_n^{(j)} 
$$
을 생성해내고 이를 가지고 j번째 표본에 대한 신뢰구간 C_j를 계산한다.  이후
$$
y_j = I(\theta \in C_j)
$$
에 대해 경험적인 신뢰수준
$$
\bar y = \frac {1} { m} \sum y_j
$$
을 계산.





##### Metropolis - Hastings Sampler

지금까지 몬테카를로 그리고 마코프 체인에 대해 설명했으니 이를 조합한 MCMC를 설명해보자

MCMC는 앞에서 말했듯 샘플링의 한 방법으로서 Metropolis - Hastings Sampler와 Gibbs Sampler가 있다.

기본적인 구조는 다음과 같다

(1) 초기값을 하나 임의로 정함  => (2) **초기값을 모수로 하는** 제안분포로 (g)부터 새로운 샘플 추천 => (3) 새로운 샘플을 accept or reject? => (4) 이런 과정을 반복하면 정상분포로 수렴할 때까지 표본들이 추출됨 => 초기의 burn-in을 제외하고 나면 targeting distribution(f)으로 부터 뽑은 sample들이 등장



여기서 M-H sampler는 새로운 샘플을 accept or reject 하는 과정에서 다음을 반복한다

1.

$
\ Y \sim \ g(* | X_t) \ 생성 (X_t : parameter)
$

2.

$
\ U \sim U(0,1) \ 생성
$

3.

$
\  U \leq \frac {f(Y)/g(Y|X_t)}{f(X_t)/g(X_t|Y)} \ \ 이면 \ \ X_{t+1} = Y \ 채택 \ \ or  \ X_{t+1} = X_t
$

이러한 방법으로 X_n을 쭉 뽑아내면 n 이 충분히 커졌을 때 정상분포로 수렴하게 되고 burn-in을 제외하면 target dist에서 뽑은 표본이 된다.



##### Gibbs Sampler

M-H sampler의 일종이므로 기본적인 과정은 동일하다.


$
X = (X_1, ..., X_d)\ 일 \ 때 \ X_{(-j)} = (X_1,...,X_{j-1}, X_{j+1}, ... , X_d)
$

라고 하면 X_j의 일변량 조건부 밀도함수
$$
f(X_j | X_{(-j)})
$$
가 완전히 알려져있다고 가정한다. 

이러한 일변량 조건부 밀도함수로부터 새로운 후보변수를 추천받고 M-H sampler 와는 다르게 모든 후보점들이 채택된다.



##### 수렴 진단

표본들을 계속 뽑아나가는데, 언제까지 뽑아나가야 하는걸까?

(1) trace plot : 반복에 따라 생성된 표본의 경로를 그려서 주기성이나 경향성이 없는지 체크.

(2) autocorrelation graph : 자기상관이 없어지는 표집시차(sampling lag) 찾기

(3) 몬테칼로 오차 : ''몬테칼로'' 니까 표본들을 통해 오차를 추정해보는 것. 즉 오차가 작으면 정확도가 높다는 것을 활용

=> N개의 표본을 K개의 batch로 분할해서 batch 당 평균과 전체 평균을 구한 뒤 몬테칼로 오차 추정값을 구한다.

$
\hat {se}[\bar{ g(X)}] = \sqrt {\frac {1}{k(k-1)}\sum(\bar{g(X)_b} - \bar {g(x)})^2}
$


#### MCMC simulation with R

~~~R
library(bayesmeta)
set.seed(2020)

#target 분포 f : 레일리 분포
f = function(x, sigma){
    if (any(x<0)) return (0)
    stopifnot(sigma>0)
    return((x/sigma^2)*exp(-x^2/(2*sigma^2)))
}
?rgamma
m=10000
sigma = 4
x = numeric(m) #실수형으로 선언하기 
x[1] = rgamma(1,1) #제안분포는 gamma 분포
k=0
u = runif(m)

for (i in 2:m) {
    xt = x[i-1]
    y = rgamma(1, xt, 1) #rgamma 는 인수로 n, shape, rate
    num = f(y,sigma) * dgamma(xt,y,1) #dgamma는 인수로 x, shape, rate
    den = f(xt,sigma)*dgamma(y,xt,1)
    if (u[i] <= num/den) x[i] = y
    else {
        x[i] = xt
        k = k+1
    }
}
print(k) #2960 왜 2960 인가? 10000개 중에 reject 된게 2960개인 것

#target 분포

y = seq(0,15, length=1000)
plot(y, drayleigh(y,4), col = 'red')

#M-H로 만든 분포
hist(x, prob=T, add=T, breaks=200)

~~~



<img src='{{"/assets/img/mcmcplot.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>









참고

Sheldon M. Ross, in [Introduction to Probability Models ](https://www.sciencedirect.com/book/9780123756862/introduction-to-probability-models) & wikipedia 

서울시립대 박창이 교수님 강의노트

https://datascienceschool.net/03%20machine%20learning/19.01%20%EB%AA%AC%ED%85%8C%EC%B9%B4%EB%A5%BC%EB%A1%9C%20%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88%20%EB%B6%84%EC%84%9D.html

