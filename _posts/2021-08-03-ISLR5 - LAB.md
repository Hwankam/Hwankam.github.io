---
layout : post
title : ISLR - LAB5
subtitle : statistical learning - 5장 - LAB
date : 2021-08-03
#categories:
tags : [datascience, datamining, machinelearning, ISLR]
toc_sticky : true
use_math : true
comments: true
---

5장 실습 코드 입니다.

~~~R
library(ISLR)

## Validation set approach
set.seed(1)
train = sample(392, 196) # 392까지의 숫자 중에서 196개를 뽑음 (여기서 392는 Auto data의 행이 392개 이기 때문)
?sample

lm.fit = lm(mpg ~ horsepower, data=Auto, subset=train)
attach(Auto)
mean((mpg-predict(lm.fit, Auto))[-train]^2) #trian에 사용된 데이터를 제외하고 validation set으로 test mse 추정하기
dim(Auto)

lm.fit2 = lm(mpg ~ poly(horsepower,2), data=Auto, subset = train)
mean((mpg-predict(lm.fit2, Auto))[-train]^2)


##LOOCV
glm.fit = glm(mpg~horsepower,data=Auto) # family="binomial" 없으면 glm 명령어도 lm처럼 쓰임
coef(glm.fit)

#cv.glm

library(boot)
cv.err = cv.glm(Auto, glm.fit)
cv.err$delta #여기서 나오는 값이 LOOCV 값 (LOOCV의 경우 delta의 두가지 값 동일. 단, K-Fold 인 경우 두 값이 서로 다르고 두 번째 나오는 값이 bias corrected version)

#모형마다 LOOCV를 계산하고 싶다면?
cv.error = rep(0,5)
for (i in 1:5){
    glm.fit=glm(mpg~poly(horsepower, i), data=Auto)
    cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
# 24.23151 19.24821 19.33498 19.42443 19.03321 => sharp drop in the estimated test MSE between linear and quadratic



## K-Fold Cross-Validation
#LOOCV와 코드는 비슷한데 단지 cv.glm 안에 K=k 인자를 추가해주기만 하면 된다.

set.seed(7)
cv.error.10 = rep(0,10)
for (i in 1:10){
    glm.fit = glm(mpg~poly(horsepower,i), data=Auto)
    cv.error.10[i] = cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10



##Bootstraping
#bootstraping 코드 만들기

alpha.fn = function(data, index){
    X=data$X[index]
    Y = data$Y[index]
    return ((var(Y)-cov(X,Y))/(var(X)+ var(Y) -2*cov(X,Y)))
}

alpha.fn(Portfolio, 1:100)

set.seed(1)
alpha.fn(Portfolio, sample(100,100, replace=T)) # 샘플을 1~100에서 100개를 복원추출

#위의 과정을 모두 생략하고 boot 명령을 통해 손쉽게 구할 수 있다.
boot(Portfolio, alpha.fn, R = 1000) #여기서 R 은 붓스트랩 추정량의 개수 

~~~

