---
layout : post
title : CDA - ROC/AUC
subtitle : categorical data analysis
date : 2021-10-31
#categories:
tags : [categorical data]
toc_sticky : true
use_math : true
comments: true
---

이 글은 범주형 데이터분석과 관련한 아티클을 읽고 정리한 글이다.

아티클 주소는 (https://towardsdatascience.com/understanding-the-roc-curve-and-auc-dd4f9a192ecb) 이다.


## ROC ( Receiver Operating Characterisitc ) curve

binary classification algorithm에서 주로 사용되는 모델 성능 평가 기준 중 하나이다.

binary 케이스에서 나올 수 있는 4가지 케이스의 결과는 다음과 같다


<img src='{{"/assets/img/roc1.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

true / false는 예측값과 실제값이 맞는지를 표현하며, postive / negative 값은 예측값이 양성인지 아닌지를 표현한다. 

여기서에서 TP 와 FP를 활용해서 여러가지 threshold 값에 따른 ROC curve를 만들어낸다.

이를 통해서 최적의 threshold 값을 선택할 수 있을 것이다. 

이제 ROC curve의 각 축인 sensitivity와 1- specificity에 대해 자세히 알아보겠다.

#### Sensitivity

True Positive Rate = Sensitivity =  P(Diagnosis of Test is Positive $\mid$ person has disease)  = 
$\frac {TP}{TP + FN}$

FN 은 음성으로 예측했는데 실제로는 암이 있는 상황이므로 TP와 합쳐져서 실제로 암이 있는 환자의 전체 개수를 나타낸다


#### 1 - Specificity

False Positive Rate = 1 - Specificity = P(Diagnosis of Test is Negative $\mid$ person doesn't have disease) = 
$\frac {FP}{TN+ FP}$

FPR 은 쉽게 말해서 'false alarm' 이다. 즉 병이 없는데 병이 있다고 잘못 알람하는 것! 

#### Curve

<img src='{{"/assets/img/roc2.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

위 그림에서 보면 회색 점선은 랜덤 추측 (즉 찍기) 에 기반한 curve 이며, 보라색 선은 perfect classifier를, 파란색 선은 연구자가 설정한 threshold하에서의 curve를 나타낸다. 모델의 성능을 높이기 위해서는 같은 FPR이라면 TPR이 높을수록 좋을 것이다. 이를 면적으로 표현해서 설명한 것이 AUC이다. (curve에 대한 single metric)

## AUC (Area Under the Curve)

curve 그림에서 회색선이 auc = 0.5, pefect classifier = 1.0


