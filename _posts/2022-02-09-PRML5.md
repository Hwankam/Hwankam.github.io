---
layout : post
title : PRML-5
subtitle : PRML
date : 2022-02-09
#categories:
tags : [PRML, Machine learning]
toc_sticky : true
use_math : true
comments: true
--- 


## 5. Neural Networks

chap 3과 4에서는 linear combination of fixed bases function에 대해 배웠다. 그러나 high dimension에서는 과적합의 문제가 발생하는 한계가 있었다. 이를 해결하기 위해 데이터에 맞게 basis function을 바꾸는 것은 어떠할까? 

SVM은 데이터에 맞게 hyperplane을 설정하는 것이므로 맥락에 부합한다. 이는 basis function의 후보 가운데 일부를 선택해서 데이터에 적합시키는 것이므로 '차원의 저주'로 부터 좀 더 자유로워질 수 있다. 또한 convex optimization 문제로 풀 수 있기 때문에 solution이 명확하다.

좀 더 다른 방식으로, basis function 개수는 고정하지만 parameter를 통해 data에 맞는 basis function 자체를 바꾸는 것을 생각할 수 있다. 가장 대표적인 방식이, feed forward neural network(multilayer perceptron)이다. 이 모델은 SVM에 비해 compact하며 학습속도가 빠르다. 그러나 convex optimization 문제가 아니므로 해를 찾기 어려울 수 있다. 

multilayer perceptron에서 결정해야할 parameter는 Maximum likelihood를 사용해서 결정한다.(뒤에서 Jacobian 이나 Hessian을 통해서 error backpropagation의 작동원리를 배울 것임)


<br>


### 5.1 Feed-forward Network Functions

chap 3 과 4의 모델은 다음과 같다.

$$
y(\boldsymbol{x}, \boldsymbol{w}) = f (\sum_{i=1}^M w_j \phi_j (\boldsymbol{x}) )
$$

multilayer perceptron 모델에서는 non-linear basis fucntion인 $\phi_j (\boldsymbol{x})$ 가 adjustable parameter에 의존하도록 하겠다.( how? layer를 거치면서 
$\phi$ 는 input과 weight 
$\boldsymbol{w}$의 결합으로 만들어짐 )

[modeling]

input variable : D개 (i)

linear combination of input variable : M개 (j)

superscript : layer

activation : 
$a_j$

differentiable nonlinear **unit** activation function(last layer)  : h (data의 특성에 의해 / target의 분포적 특성에 의해 결정됨) (Regression : identity function // binary classification : sigmoid function // Multiclass classification : softmax)


differentiable nonlinear activation function  : sigmoid, tanh, relu ... 

hidden unit : z

$$
a_j = \sum _{i=1} ^D w_{ji} ^{(1)} x_i + w_{j0} ^{(1)} \\

z_j = h(a_j)
$$

아래 그림은 two layer neural network를 나타내는데, node는 deterministic variable이므로, probabilistic graphical model(chap 8)은 아니다. 

<img src='{{"/assets/img/prml-5-1.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

식과 그림에서도 알 수 있듯, 각 layer는 perceptron 모델과 매우 유사하다. 결국 perceptron 모델 또한 에러를 줄이는 perceptron parameter w를 결정하고자 한다. 그러나 perceptron 모델은 class를 +1 과 -1 로 나누는 데에서 activation function이 step function인 반면, neural network에서는 differentiable 하다는 것이 차이라 할 수 있다. 

만약 hidden unit이 linear라면 결국 식 (5.7) 와 같이 중첩해서 식을 쓸 필요가 없고, input 과 output만이 있는 매우 simple한 모델을 만들 수 있을 것이다. 이러한 형태는 나중에 12장에서 배울 principal component analysis와 매우 유사하다고 할 수 있다.


network architecture에서 자주 사용되는 skip-layer connection은 경사소실을 막아, sparse 모델이 특정 gredient에만 영향을 크게 받는 것을 방지한다.

"모든 input 과 oupter이 hidden layer 에 의해 연결된다면 weight는 어떻게 정할 것인가 => maximum likelihood and Bayesian apporach "

아래 그림은 hidden unit과 network 학습 결과를 보여준다.


<img src='{{"/assets/img/prml-5-2.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>


<img src='{{"/assets/img/prml-5-3.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>


<br>


#### 5.1.1 Weight-space symmetries

feed-forward network의 특징 중 하나는, weight vector에 대한 multiple distinct choice 가 결국 같은 mapping function을 만들어 낸다는 것이다. 

ex1 ) tanh function와 같은 기함수의 특징을 활용할 때 M개의 hidden unit에 대해 $2^M$ 개의 weight vector가 동일한 network를 만들어 낼 것이다. 

ex2 ) hidden unit의 순서를 바꾸면 된다.  


<br>


### 5.2 Network Training


polynomial curve fitting(chap 1) 에서는 sum of square error function을 minimize 하는 parameter 값을 추정하는 것을 배웠다. neural network에서도 마찬가지로 parameter를 추정하는 것이 중요하다. 

우선 network output에 대한 확률적 접근을 할 수 있다.

target $\boldsymbol{t}$ 가 Gaussian distribution을 따른다고 생각해보자. Regression setting에서 unit activation function을 생각하면 parameter에 대한 MLE를 찾을 수 있다. 또한 Gaussian 가정 하에서는 likelihood function을 최대화 하는 것은 sum of square error function을 최소화 하는 것과 같다. 

가우시안의 경우에는 convex 문제를 쉽게 풀 수 있지만, 실제로 많은 경우에는 network function이 non-linearity를 가지고 있고, error function 또한 마찬가지이다. => analytic 하게 구해야 한다.


binary classification의 경우는 maximum likelihood 방식으로 parameter를 추정하는 것이 cross entropy error function을 최소화 하는 것과 동일하다. (sum of square error는 학습의 속도 또한 느리며, ML 방식에서 도출할 수 없는 error 이므로 generalization이 어렵다) 또한 target이 특정 분포를 따르는 것이 아니라, 0 또는 1로 명확하게 labelling 되어 있기 때문에 분산을 정의할 필요가 없다. 


binary classification with multiple target의 경우, linear classification은 각 linear model이 output과 각각 linearly independent 하게 영향을 주지만, neural network에서는 각 input이 각 output에 non-linearly 영향을 준다는 것이다. 

<br>


#### 5.2.1 Parameter optimization

geometric apporach

<img src='{{"/assets/img/prml-5-4.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>



weight space에서 $\delta \boldsymbol{w}$ 만큼 움직였을 때, error function의 변화는 
$\delta E \simeq \delta \boldsymbol{w}^T \nabla E(\boldsymbol{w}$) 이고 이때 gredient는 error를 가장 많이 줄이는 방향이다. 따라서 gredient가 0에 매우 근사할 때 error를 가장 작게 하는 값에 도달했다고 할 수 있다.

"Points at which the gradient vanishes are called stationary points and may be further classified into minima, maxima, and saddle point"

Network 안에는 수많은 inequivalent stationary point 와 inequivalent minima 가 존재한다. 그러나 반드시 global minima를 찾을 필요는 없으며 존재하지 않을 수도 있다. 실제로 할 수 있는 것은 local minima 후보지를 몇개 선정한 다음 이를 비교해서 최적의 값을 찾는 것이다. 

(Newton-Rhapson 방법과 같이 iterative하게 parameter 값을 추정해야할 경우도 있다.)

<br>

<br>


### 5.5 Regularization in Neural Networks

hidden unit의 개수는 모델을 설계할 때 정하는 free parameter이며 모델 자체의 성능을 결정하게 된다. 한 방법으로 maximum likelihood setting을 통해서 최적의 hidden unit 개수를 결정할 수도 있을 것이다. 아래 그림은 hidden unit의 개수에 따른 fitting 결과를 보여준다.

<img src='{{"/assets/img/prml-5-5.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

overfitting을 방지하는 방법으로는 초기에 hidden unit의 개수를 매우 큰 모형을 만든 다음 데이터를 적합해가면서 sparse한 모형을 만들어 내는 방식이 있다. 이를 위해 regularized error를 설정하는 것을 생각해볼 수 있다.(weight decay) 또한, 이전에도 배웠지만 L2 regularization 하에서 최적의 계수를 찾는 것은 gaussian prior에서 MAP를 찾는 것과 동일하다. 

$$
\tilde E(\boldsymbol{w}) =E(\boldsymbol{w}) + \frac{\lambda}{2}\boldsymbol{w}^T\boldsymbol{w}
$$




또다른 방법으로는 validation set을 통해서도 적절한 hidden unit의 개수를 설정할 수 있을 것이다(또한 hidden unit을 만드는 weight를 결정할 수 있을 것이다)


<br>

#### 5.5.1 Consistent Gaussian Priors

weight decay의 한계는 neural network mapping에서 weight에 대한 transformation(scaling)
과 일치하지 않는 부분이 있다는 것이다. 

기존 데이터를 transform한 데이터를 생각해보자. 두 데이터를 모델을 통해 train 했을 때, 일반적으로 weight 는 다르겠지만 두 모델의 동일한 layer의 weight는 linear transform으로 서로 표현될 수 있을 것이다. 이때에 regularization을 생각해보자. linear transform에 의해 변형된 데이터이므로, regularization 또한 동일한 데이터(변수)에 적용되어야 할 것이다.

그러나 위에서 본 regularized error 는 이러한 점을 만족하지 못한다.(layer 별로 activation function이 다르기 때문에 regularization 또한 다르게 적용되어야 한다) 이를 위해 새로운 regularization term을 제시한다. $\mathcal{w}_1$ 은 첫번째 layer, 
$\mathcal{w}_2$ 는 두번째 layer를 의미한다. 

$$
\frac{\lambda_1}{2}\sum_{w \in \mathcal{w}_1}w^2 + \frac{\lambda_2}{2}\sum_{w \in \mathcal{w}_2}w^2
$$

weight의 prior를 고려한다면 prior는 다음과 같다.(regularizer can be interpreted as the negative loarithm of prior)

$$
p(\boldsymbol{w}) \propto exp(- \frac{1}{2} \sum_k \alpha_k ||\boldsymbol{w}||_k^2)
$$



<br>

#### 5.5.2 Early stopping

모델의 복잡성을 control하는 방법으로 regularization의 대안으로 early stopping을 제시한다. network training에서는 error는 비증가(non-increasing) 함수이다. 그러나 validation set을 통해 모델 검증을 해보면 training의 횟수가 늘어날수록, 즉 데이터에 과적합이 되는 경우 오히려 error가 커지는 현상을 발견할 수 있다. 즉, 적절한 training 횟수를 위해 early stopping이 필요하다.  

또한 자유도에 대한 내용이 언급되고 있다. 저자는 모델 학습이 진행될수록 네트워크의 degree of freedom이 증가할 것이라 말하고 있다. 모델 초기에는 모든 weight들이 동일하게 가중치를 가지고 있는 상태이나 training 동안 모델이 데이터에 적합되면서 일부 weight은 커지고 또 일부 weight은 작아지기 때문에 df의 값은 상대적으로 training 을 반복하면서 커진다고 할 수 있다.


<br>

#### 5.5.3 Invariances

pattern recognition에서 input의 tranforming에 대해서 결과가 바뀌어서는 안된다. 예를들어 input data의 position을 바꾼다거나, 혹은 사이즈를 바꾼다거나 하는 등의 transforming은 결과값을 다르게 만들어서는 안될 것이다. 

만약 데이터가 매우 많다면 모델의 invariance는 자연스럽게 학습될 것이다. 많은 데이터 안에서는 자연스럽게 여러가지 transforming에 대한 것을 학습할 수 있기 때문이다. 그러나 데이터가 많지 않다면?? 요구되는 invariant 가 매우 많다면?? 

이에 대한 대안으로 책에서는 4가지를 제시한다

1. data augmentation(replication을 batch 각각에 넣어주면 더 좋을 것)

2. regularization term(transforming을 제한, 뒤에 나오는 tangent propagation)

3. tranformation과 관련없는 변수를 미리 추출

4. network 모델 자체에 invariance properties를 만들어 놓음. (local receptive fields, shared weights)



<br>

#### 5.5.4 Tangent propagation

continuous transformation에 대해서만 고려해보자.(rotation not reflection)

특정 변환에 의해서 D 차원 input space 에서 M차원의 manifold로 변형될 수 있다. 아래 그림을 보자.

<img src='{{"/assets/img/prml-5-6.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

$\xi$에 의해 transformation이 되고 있고 이러한 변형을
$s(x_n, \xi)$ 라고 할 수 있다. 
이때 point $x_n$에서 tangent 값은 아래와 같다.

$$
\tau_n = \frac {\partial s(x_n, \xi)}{\partial \xi} |_{\xi = 0}
$$


output에 대한 derivative 는 아래와 같다.

$$
\frac{\partial y_k}{\partial \xi} | _{\xi=0} = \sum_{i=1}^D \frac{\partial y_k}{\partial x_i} \frac{\partial x_i}{\partial \xi} |_{\xi=0} = \sum_{i=1}^D J_{ki} \tau_i

$$


이를 활용해서 error function을 변형해보자. 

regularization coefficient $\lambda$와 regularization function 
$\Omega$ 에 대해서 

$$
\Omega = \frac{1}{2} \sum_n \sum_k ( \frac{\partial y_k}{\partial \xi} | _{\xi=0} )^2
$$

$$
\tilde E = E + \lambda \Omega
$$

라고 둘 수 있다. 만일 transformation에 대해서 network mapping function이 invariant 하다면 regularization function $\Omega$는 zero가 될 것이다. 
또한 $\lambda$ 값은 데이터에 대한 fitting과 invariant property에 대한 학습을 조절해주는 역할을 한다.  

이를 통해 볼때, regularization function은 결국 Jacobian을 통해 weight 에 영향을 받는다. 그러므로 backpropagation 방식과 동일하게 regularizer의 derivative를 구해 적절한 weight을 업데이트한다. 즉 tangent propagation 방식은 앞에서 학습한 regularization과 그 방식이 거의 유사한 것이다. 

비슷한 테크닉으로, tangent distance는 nearest-neighbour classifier와 같은 distance 기반의 분석법에서 invariance property를 찾아낼 수 있다.

<br>


#### 5.5.6 Convolutional networks

5.5.3에서 나오는 4가지 방법 중 마지막 방법을 설명해보도록 하겠다. 이 단락에서는 network 구조 자체에 invariance properties를 만들고자 한다. 이러한 시도는 이미지 데이터 처리에 사용되는 convolutional neural network의 기반이 되었다. 

미묘한 변화까지도 감지하기 위한 네트워크 구조를 만들기 위해 fully connected network를 만든다고 해도, '이미지' 데이터는 주변 데이터들과 큰 상관관계를 갖는다는 특성이 있다. 그러므로 vision 분야에서는 *local feature* 를 찾아내려는 시도를 많이하고 있다.(cnn의 핵심 = feature extraction)

convolutional neural network는 local feature를 찾기 위해 local receptive field // weight sharing // subsampling 이라는 3가지 개념을 제시한다.

input image는 sharing weight을 통해서 학습이 되고, image의 subregion으로부터 weight와 bias를 통해 unit으로 이뤄진 feature map을 만든다. 여기서 각 unit들은 feature detector의 역할을 한다. 혹여나 이미지가 이동된다고 하더라도, feature map에서의 활성위치(unit) 만 바뀌면 되기 때문에 invariance가 유지된다. 

convolutional unit의 output은 subsampling layer의 input을 만든다. subsampling unit은 feature map의 정보를 보다 압축한다. 따라서 image shift 가 발생하는 경우 이를 보다 민감하게 찾게 된다.(pooling과 유사?)

이를 정리하면 Convolutional neural network를 다음과 같은 구조로 표현할 수 있다.

<img src='{{"/assets/img/prml-5-7.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>


<br>

#### 5.5.7 Soft weight sharing

모델 복잡도를 통제하는 방법 중 하나로 그룹화를 한 뒤 동일한 weight을 주는 것을 들 수 있다. 이 방법은 translation invariance를 위한 방법 중 하나이기도 하다. 이 방법은 weight에 대한 제약이 선행(그룹 간 weight의 평균, 그룹내 weight의 분산)되어야 하며, soft한 제약을 통해 특정 그룹의 weight가 similar value를 갖도록 한다.  

따라서 이 방식은 결국 mixture model을 고려하는 것과 동일시된다. 확률밀도함수는 다음과 같다

$$
\begin{align}
& p(w_i) = \sum _{j=1} ^ M \pi_j \mathcal{N}(w_i | \mu_j, \sigma_j^2) \\

& p(\boldsymbol{w}) = \prod _i p(w_i)
\end{align}
$$

negative loagrithm(ML을 극대화하는 것과 동일)을 통해 regularization function을 다음과 같이 만들 수 있다.

$$
\Omega(\boldsymbol{w}) = - \sum_i ln (\sum_{j=1} ^M \pi_j \mathcal{N}(w_i | \mu_j, \sigma_j^2))
$$

total error function은 아래와 같다.

$$
\tilde E(\boldsymbol{w}) = E(\boldsymbol{w}) + \lambda \Omega(\boldsymbol{w})
$$

이와 같이 정의한 error는 weight w와 파라미터인 $\pi, \mu, \sigma$ 에 의해 minimize된다. 그 방법으로는 conjugate-gradients 혹은 quasi-Newton method 같은 것으로 weight를 업데이트하면서 동시에 EM알고리즘을 통해 mixture distribution의 파라미터 값을 업데이트하는 방식이 있다.(공동 최적화를 통한 수치적 안정성)


total error function에 대한 derivative 를 구하기 위해서 우선 coefficient 인 $\pi$ 에 대한 prior를 먼저 설정한 뒤, posterior를 나타낸다.


$$
\textrm{posterior} \ \ \gamma_j(w) = \frac {\pi_j \mathcal{N}(w|\mu_j, \sigma_j ^2)}{\sum_k \pi_j \mathcal{N}(w|\mu_j, \sigma_j ^2)}
$$


이때 total error function에 대한 derivative를 살펴보자. weight에 대한 derivative 는 다음과 같다.


$$
\frac {\partial \tilde E}{\partial w_i} = \frac {\partial E}{\partial w_i} + \lambda \sum_j \gamma_j(w_i) \frac {(w_i - \mu_j)}{\sigma^2 _j}
$$

식을 자세히 보면 regularization term은 weight을 $j^{th}$  Gaussian의 중심으로 모으는 역할을 하고 있음을 알 수 있다(표준화)

비슷하게 $\mu , \sigma $ 에 대해서도 derivative 를 구할 수 있으며, 의미는 비슷하다.(sharing, grouping)

만일 $\sigma^2 _j = exp(\eta_j)$ 라고 둔다면 분산의 값이 0이 되는 경우를 막을 수 있으므로 유용하다.(9장 mixture model에서 설명)

mixing coefficient에 대한 제약을 위해(합 1) softmax function을 사용할 수 있으며 여기서 또한 의미를 찾아낼 수 있다. 



<br>


### 5.6 Mixture Density Networks

supervised learning의 목적은 조건부분포 
$p(t | x)$
를 구하고자 하는 것이다. 그러나 실제 문제들에서 Gaussian을 가정하는 것은 잘못된 결과를 이르게 할 수도 있다. 

causality를 기반으로 한 forward problem은 many to one의 문제로 인과관계에 의한 정확한 결과를 예측할 수 있다. 반면 inverse problem을 생각해보자. 즉 one to many 의 문제를 푸는 것으로, 어떤 현상들이 발생했을 때 이를 바탕으로 특정사건이 일어날 것이라 예측할 수 있을지 단정짓기 어렵다. (명확한 인과관계가 밝혀지지 않는 이상 어떠한 결과를 가져올지 단정짓기 어렵다) 

아래 그림은 forward problem과 inverse problem을 설명한다.

<img src='{{"/assets/img/prml-5-8.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

그럼 조건부분포를 찾기위한 일반적인 framework는 없을까?

이 책에서는 mixture density network를 제시한다. 즉 mixing coefficients 와 component density 모두를 input vector X에 대한 flexible function으로 생각하는 것이다. 

Gaussian components 를 가정한다면 아래와 같은 모델을 만들 수 있다

$$
p(t|x) = \sum _{k=1} ^K \pi_k(x) \ \mathcal{N}(t|\mu_k(x), \sigma_k ^2 (x))
$$

이 모델은 input vector에 의해 component의 분산이 영향을 받는 heteroscedastic model(이분산성 모델)이다.

mixture 모델에서 $\pi_k(x), \mu_k (x),  \sigma_k ^2 (x)$ 는 neural network 모델의 output에 영향을 받는다. 즉 mixture model의 parameter를 찾는 데에 hidden unit이 모두 공유된다. 그래서 만약 L개의 mixture component와 output t가 K개의 component를 가진다면 network는 L 개의 output unit activation $a_k ^ {\pi}$ 과
K개의 output $a_k ^ {\sigma}$, 
L x K 개의 output  $a_{kj} ^ {\mu}$ 를 갖게 될 것이다. 

즉 network의 output 수는 (K+2)L 이며 mixture를 고려하지 않을 때에는 K 개의 output 만을 가진다는 데에서 비교된다.


이때 coefficeint의 조건과, 분산값이 양이 된다는 조건을 만족시키기 위해 softmax output form이나 exponential을 활용하면 error function은 다음과 같다. 

$$
E(w) = - \sum _{n=1} ^N ln \ \{ \sum_{k=1}^k \pi_k(x_n,\boldsymbol{w}) \mathcal{N}(t_n | \mu_k(x_n, \boldsymbol{w}), \sigma_k^2(x_n, \boldsymbol{w})    \}
$$

derivative 를 구하는 방식은 5.5.7에서와 유사하게 생각할 수 있을 것이며, mixture model이므로 prior를 정의하고 posterior를 도입하도록 한다.

<img src='{{"/assets/img/prml-5-9.png"| relative_url}}'  width="70%" height="70%" title="1" alt='relative'>

교재에서 제시하는 toy example을 볼 때, 찾고싶은 조건부분포
$p(t|x)$
는 그림 (c)에서처럼 multimodal이다. 

mixture model을 통해
$p(t|x)$
를 구하게 되면 이를 활용한 대표값을 구할 수 있다

=> $E(\boldsymbol{t}|x) , E(||\boldsymbol{t} - E(\boldsymbol{t}|x)||^2|x) $

그러나 평균값이 항상 데이터를 잘 나타낸다고 할 수는 없다. 로봇팔 문제를 생각해보면 inverse problem에서 두가지 가능한 해의 평균이 옳은 답이라 말하기는 힘들다. 이를 해결하기 위해서는 가능성이 높은 성분의 평균값을 각각의 x값에 대해 구하는 것이다. 이는 그림 (d)에서 잘 나타난다.


<br>

