<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="PRML-3" /><meta property="og:locale" content="en" /><meta name="description" content="3. Linear Models for Regression" /><meta property="og:description" content="3. Linear Models for Regression" /><link rel="canonical" href="https://hwankam.github.io/posts/PRML3/" /><meta property="og:url" content="https://hwankam.github.io/posts/PRML3/" /><meta property="og:site_name" content="For Statistics" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-11-07T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="PRML-3" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"3. Linear Models for Regression","url":"https://hwankam.github.io/posts/PRML3/","headline":"PRML-3","dateModified":"2022-01-19T09:59:47+09:00","datePublished":"2021-11-07T00:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://hwankam.github.io/posts/PRML3/"},"@type":"BlogPosting","@context":"https://schema.org"}</script><title>PRML-3 | For Statistics</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="For Statistics"><meta name="application-name" content="For Statistics"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> </a></div><div class="site-title mt-3"> <a href="/">For Statistics</a></div><div class="site-subtitle font-italic">kam's world</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/Hwankam" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['example','doamin.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>PRML-3</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>PRML-3</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> your_full_name </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Nov 7, 2021, 12:00 AM +0900" >Nov 7, 2021<i class="unloaded">2021-11-07T00:00:00+09:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Wed, Jan 19, 2022, 9:59 AM +0900" >Jan 19<i class="unloaded">2022-01-19T09:59:47+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4883 words">27 min read</span></div></div><div class="post-content"><h2 id="3-linear-models-for-regression">3. Linear Models for Regression</h2><p>linear model : parameter에 대한 linear function ( input variables의 nonlinear function이 있다하더라도 이들의 결합이 파라미터 관점에서 선형결합이면 linear model이라 칭한다 )</p><p>이 장에서는 선형모형과 이를 통한 학습 및 예측에 대해 설명하게 될 것이다.</p><p>선형모델은 단순하며 모형의 해석적 측면에서 뛰어나지만, high dimension으로 넘어가게 되면 모델 사용의 한계가 있다는 점을 먼저 밝힌다.</p><p><br /></p><h3 id="31-linear-basis-function-models">3.1 Linear Basis Function Models</h3><p>input variables에 대해서도 선형함수라면 모형 자체가 너무 제한될 것이다. 따라서 basis function을 사용해서 조금 더 복잡한 선형모델을 만들어보자.</p><p>Basis function $\phi_j(x)$에 대해 다음과 같은 선형모델을 만들 수 있을 것이다.</p>\[y(\mathbf x,\mathbf w) = \sum_{j=0}^{M-1} w_j \phi_j(x) = \mathbf w^T \mathbf \phi(x)\]<p>여기서 basis fuction의 종류는 여러가지가 있다.</p><ul><li>power를 사용한 $\phi_j(x) = x^j$<li>가우시안 basis $\phi_j(x) = exp{ - \frac{(x-\mu_j)^2}{2s^2}}$<li>sigmoid basis $\phi_j(x) =\sigma (\frac {x-\mu_j} {s})$</ul><p>등이 있다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-11.png" width="70%" height="70%" title="1" alt="relative" /></p><p>그러나 이 챕터에서는 특정 basis에 국한하지 않고, 일반적인 basis function에 적용되는 성질에 대해 말할 것이다.</p><h5 id="wavelets">Wavelets</h5><p>basis function으로 wavelets이 나오는데, wavelets transform을 한다면 함수를 특정 구간으로 localized 혹은 orthogonalized 할 수 있다. Input value들이 주변의 input value와 서로 연결되어있는 temporal sequnece나 image 상의 pixel 일 때 사용될 수 있을 것이다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-12.png" width="70%" height="70%" title="1" alt="relative" /></p><p><br /></p><h4 id="311-maximum-likelihood-and-least-squares">3.1.1 Maximum likelihood and least squares</h4><p>notation이 지금까지 내가 공부하면서 쓰던 것과 조금 다르긴 하지만 내용은 동일함.</p><p>Gaussian noise assumption 하에서 선형모델을 아래와 같이 적을 수 있다</p>\[p(t \mid \mathbf x, \mathbf w, \beta) = N(t \mid y(\mathbf x, \mathbf w),\beta^{-1})\]<p>gaussian assumption이므로 모델은 unimodal일 것이다.</p><p>likelihood function은</p>\[p(\mathbf t \mid \mathbf X, \mathbf w, \beta) = \prod _{n=1} N(t_n \mid y(\mathbf x_n, \mathbf w),\beta^{-1}) = \prod _{n=1} N(t_n \mid \mathbf w ^T \phi(\mathbf x_n),\beta^{-1})\]<p>이를 극대화하는 파라미터 $\mathbf w$ 추정값은 (ML)</p>\[\mathbf w_{ML} = (\Phi^T \Phi)^{-1} \Phi^T \mathbf t\]<p>이를 극대화하는 precision 파라미터 $\beta$ 추정값은 (ML)</p>\[\frac {1} {\beta_{ML}} = \frac {1}{N} \sum \{t_n - \mathbf w_{ML} ^T \phi(\mathbf x_n) \}^2\]<p>이를 극대화하는 bias term인 $w_0$의 추정값은 (ML)</p>\[\sum _{n=1} \{t_n - w_0 - \sum _{j=1}w_j\phi_j(\mathbf x_n) \}^2\]<p>을 $w_0$로 미분한 값을 0으로 만드는 값이므로</p>\[\hat w_0 = \frac{1} {N} \sum _{n=1} t_n - \sum _{j=1} w_j \sum _{n=1} \frac{1} {N} \phi_j(\mathbf x_n)\]<p>이다. 즉 bias term의 추정값은 target value의 평균값과 basis function의 평균값에 대한 weighted sum의 차이를 의미한다.</p><p><br /></p><h4 id="312-geometry-of-least-squares">3.1.2 Geometry of least squares</h4><p>아래 그림이 모든 것을 말해주고 있다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-13.png" width="70%" height="70%" title="1" alt="relative" /></p><p>벡터 $ \mathbf t $ 에 대해 M개의 basis function이 span하는 공간 $S$으로의 사영을 $\mathbf y = \hat {\mathbf w ^T} \phi(X) $ 라고 하자. 즉 $\mathbf y$ 는 공간 $S$의 기저벡터의 선형결합으로 이뤄지며, $\mathbf t$와의 squared Euclidean 거리가 가장 가까운 벡터이다.</p><p>따라서, $\mathbf t$의 추정값을 구할 때는 결국 $\mathbf w_{ML} = (\Phi^T \Phi)^{-1} \Phi^T \mathbf t $ 를 구해야하는데, 실제 데이터 분석에서는 $(\Phi^T \Phi)$ 가 singular 인 경우가 부지기수다(high dimension). 이 때에는 SVD를 사용하거나 Ridge, Lasso와 같이 regularization을 통해 해결할 수 있다.</p><p><br /></p><p>notation의 편의를 위해 $\phi$ 대신에 $\mathbf{X}$ 를 사용하겠다.</p><p><br /></p><ol><li>(thin) Singular Value Decomposition의 경우</ol><p>만약 design matrix X 가 데이터의 개수가 변수에 비해 충분히 많은 (즉 n&gt;p) 경우에는 thin SVD를 사용해서 아래와 같은 결과를 얻을 수 있을 것이다.</p>\[X^TX = (VDU^T)(UDV^T) \Rightarrow \hat \beta = (X^TX)^{-1}X^Ty = VD^{-1}U^Ty\]<p>그러나 design matrix X 가 high dimension이거나 mulicollinear인 경우에는 $ \mathbf X^T \mathbf X$ 가 signular가 될 것이다. 이때는 SVD를 통해 Moore-Penrose pseudoinverse matrix를 구하는 방식으로 문제를 해결할 수 있다.</p><p>$X=UDV^T$ 일 때 X의 무어 펜로즈 역행렬 $X^- = VD^-U^T$ , $D=diag(d_1^{-1},d_2^{-1},…)$ 을 사용해서</p>\[(X^TX)^- = V(D^2)^- V^T \Rightarrow \hat \beta = (X^TX)^{-}X^Ty = X^-y\]<p>참고 : <em>무어 펜로즈 역행렬의 성질</em></p><ul><li>무어펜로즈 역행렬은 SVD를 통해 만들어지므로 유일하다<li>무어펜로즈 역행렬은 $XX^-X = X$를 만족하는 $X^-$이다.<li>$(X^TX)^{-1}X^T = \mathbf K $ 는 $X$의 generalized inverse 이다.</ul><p><br /></p><ol><li>Ridge의 경우</ol>\[\hat \beta^R = argmin_{\beta} \{ loss + \lambda || \beta||_2^2 \} = (X^tX + \lambda I)^{-1}X^Ty = (I + \lambda(X^TX)^{-1})^{-1}\hat\beta\]<p><br /></p><h4 id="313-sequential-learning">3.1.3 Sequential learning</h4><p>online algorithm의 한 종류로, 실시간으로 파라미터의 추정량을 업데이트 할 수 있다. 데이터가 너무 큰 경우 인위적으로 데이터를 batch 별로 나눠 파라미터를 업데이트하는 방식을 사용할 수도 있을 것이다. sequential learning을 위해서는 Stochastic Gradient Descent를 사용한다. 즉</p>\[\mathbf w^{(\tau+1)} = \mathbf w^{(\tau)} - \eta \nabla E_n\]<p>여기서 $E_n$이란 특정 n번째 데이터에 대한 error를 구한 것으로, SGD에서는 이전의 반복에서 추정한 결과값을 따로 기억할 필요가 없고 한번의 적합으로 한번의 업데이트가 일어나기 때문에 계산비용과 메모리 비용이 적다는 장점이 있다. 그러나 업데이트 되는 값의 variability가 클 수 있다는 단점이 있다.(loss function의 형태에 따라 경사하강의 방향이 뒤죽박죽)</p><p>교재 내용과는 별개로, 딥러닝에서 optimizer에 대한 설명을 담은 사진을 첨부한다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-14.png" width="70%" height="70%" title="1" alt="relative" /></p><p><br /></p><h4 id="314-regularized-least-squares">3.1.4 Regularized least squares</h4><p>딥러닝에서 weight decay라는 용어를 자주 볼 수 있다. weight란 통계학 관점에서의 parameter를 의미하는데, 단순히 loss 를 줄이는 것으로 파라미터값을 추정하다보면 특정 가중치(parameter)가 매우 커지면서 모델이 overfitting 하게 되므로 이를 막고자 weight값을 줄이자는 것이다. 통계학에서는 이를 shrinkage라고 하는데, regularization term을 사용해서 overfitting을 방지하고자 한다. 제약식 하에서 loss를 최소화 하는 것은 아래 식을 최소화 하는 것과 동일하다(Lagrange)</p>\[\frac {1}{2} \sum \{t_n - \mathbf w ^T \phi(\mathbf x_n) \}^2 + \frac {\lambda} {2} \sum |w_j|^q\]<p>regularization term을 통해서 파라미터 추정값을 구하면 주어진 제약 하에서의 squared loss를 최소로하는 추정값을 closed form으로 구할 수 있다는 장점이 있다. $\lambda$값을 크게할수록 변수에 대한 규제가 커지고 그 값을 0에 가깝게 만들기 때문에 이 값을 적절히 설정하는 것이 계수를 추정하는 것 만큼이나 중요하다.</p><p>특히 q=1 인 경우를 Lasso라고 하는데 이는 sparse model을 만들어 낼 수 있다. 아래그림에서와 같이 L1 제약하에서 파라미터 추정값이 0이 되는 것을 알 수 있다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-15.png" width="70%" height="70%" title="1" alt="relative" /></p><p><br /></p><h4 id="315-multiple-outputs">3.1.5 Multiple outputs</h4><p>target variable이 multiple 인 경우에는 어떻게 해야할까?</p><p>각 target에 대한 모델을 만들 수도 있겠지만, 동일한 basis function을 사용해서 multiple response와 한번에 적합하는 모델을 생각할 수 있다. (후자가 더 일반적인 접근 방식이다)</p><p>target의 dimemsion이 K라고 하자.</p><p>기존 모델과의 차이는 basis function에 대한 set $\phi(\mathbf x)$는 기존과 동일하나, 회귀계수 벡터였던 $\mathbf w$ 대신 response variable의 개수(dimension K)를 열 개수로 하는 행렬 $\mathbf W$을 사용한다는 것이다. 가우시안 가정하에서 single obs $\mathbf t_1, \mathbf t_2, \cdots \mathbf t_n$에 대한 모델은 다음과 같다.</p><p>K 차원 벡터 $\mathbf y$에 대해</p>\[\mathbf y(\mathbf x, \mathbf w) = \mathbf W^T \phi(\mathbf x)\]<p>이며 target vector $\mathbf t$ 에 대해</p>\[p(\mathbf t \mid \mathbf x, \mathbf W, \beta) = N(\mathbf t \mid \mathbf y(\mathbf x, \mathbf w),\beta^{-1})\]<p>이다. 모델의 구성을 행렬과 벡터의 size를 통해 살펴보면 다음과 같다.</p>\[\mathbf T = \begin{bmatrix} t_{1} \ \ t_{2} \ \ t_{3} \ \ \cdots \ \ t_{K} \end{bmatrix} = \begin{bmatrix} w_1 \ w_{2} \ w_{3} \ \cdots w_{K} \end{bmatrix} \begin{bmatrix} \ 1 \ \ \ \ \ \ 1 \ \ \ \ \ 1 \ \ \ \ \cdots \ \ \ \ 1 \\ \phi_{n1} \ \ \ \phi_{n1} \ \ \ \phi_{n1} \ \cdots \ \ \phi_{n1} \\ \vdots \\ \phi_{nK} \ \ \phi_{nK} \ \ \phi_{nK} \ \cdots \phi_{nK}\end{bmatrix} + \begin{bmatrix} \epsilon_{1} \ \ \epsilon_{2} \ \ \epsilon_{3} \ \ \cdots \ \ \epsilon_{K} \end{bmatrix} = \mathbf W^T \phi(\mathbf x) + \mathbf \epsilon\]<p>로그가능도함수는</p>\[\text{ln} \ p(\mathbf T \mid \mathbf X, \mathbf W, \beta) = \sum_{k=1} \sum _{n=1} \text{ln} \ N(\mathbf t_{nk} \mid y(\mathbf x_n, \mathbf w),\beta^{-1}) = \frac{NK}{2} \text{ln} \ (\frac {\beta}{2\pi}) - \frac{\beta}{2} \sum _{n=1} ||\mathbf t_n - \mathbf W ^T \phi(\mathbf x_n)||^2\]<p>이렇게 보면 multiple response에서의 계수추정값은 기존의 single response variable에 대한 계수추정값과 같은 form으로 나오게 될 것임이 예상가능하며 각 target variable에 대해 각각의 회귀식을 적합시킨 것에 다를 바 없다.</p>\[\mathbf W_{ML} = (\Phi^T \Phi)^{-1} \Phi^T \mathbf T\]<p>회귀계수 $\mathbf w$는 분산에 관계없이 오직 가우시안의 mean 과 연관되어 있으므로 $\mathbf w$에 대한 추정을 할 때 각 target 변수들을 독립적으로 생각할 수 있다는 뜻.</p><p><br /></p><h3 id="32-the-bias-variance-decomposition">3.2 The Bias Variance Decomposition</h3><p>ML or LS 추정은 복잡한 모델에서 데이터셋의 개수가 한계가 있는 경우 overfitting의 문제를 야기할 수 있다. 그러나 무턱대고 모델의 복잡성(complexity / flexibility) 를 줄여 정말한 피팅을 포기할 수 있을까? Regularization term을 사용한다한들, $\lambda$ 값은 또 어떻게 정할 것인가?</p><p>3장의 목적은 over-fitting을 줄이기 위한 Bayesian 관점의 해결전략을 알아보는 데에 있다. 뒤에서도 설명하겠지만, posterior를 극대화하는 추정량(MAP)는 sum of squared error와 regularization을 동시에 고려해서 error를 최소화 하는 추정량이 된다.</p><p>그러나 이 part에서는 좀 더 일반적으로 알려진, frequentist 관점에서 모델 복잡성 문제 이슈를 살피는 bias-variance trade-off 에 관해 설명하도록 하겠다.</p><p>Expected squared loss decompostion을 통해 bias와 variance 간의 관계를 살펴보자.</p><p><br /></p><h5 id="for-your-information">For Your Information</h5><p>어떤 loss 를 사용하는지에 따라, opitmal prediction이 달라짐을 1장에서 확인했다. 예를들어 squared loss f에서는 조건부 기댓값이, absolute loss f에서는 조건부분포의 median이 optimal prediction이 될 것이다. 핵심은 조건부 분포를 찾는 데에 있으므로, regularization 혹은 Baysian approach(Bayes theorem)를 통해 조건부 분포를 구할 수 있을 것이다.</p><p><br /></p><h5 id="step-1">step 1</h5><p>$t=X\beta + \epsilon $는 response variable, $y(x)$는 추정회귀선, $h(x) = X\beta $이라고 할 때 (figure 3.2 참조)</p>\[E[L] = \int \{ y(x)-h(x) \}^2 p(x) dx + \int \{ h(x) - t \}^2 p(x,t)dxdt\]<p>와 같이 분해가 가능하다.</p><p>첫번째 term 은 어떤 추정회귀식 $y(x)$ 를 선택했는가에 따라 달라지는 값이며 이를 최소화하는 y(x)를 찾고자 할 것이다. 이상적으로 데이터가 무수히 많다면 정확히 h(x) 와 일치하는 y(x)를 찾아낼 수 있을 것이므로 첫번째 term은 0이 될 것이다.</p><p>반면, 두번째 term 은 $h(x) - t = \epsilon$ 이므로 intrinsic noise를 의미하며 expected loss 의 minimum이다. 즉 두번째 term은 결코 0이 될 수 없다.</p><p>이로부터 필연적으로 존재할 수밖에 없는 noise는 차치하고, 줄일 수 있는 첫번째 term을 어떻게 다뤄야할지 생각해볼 필요가 있다.</p><p><br /></p><h5 id="step-2">step 2</h5><p>frequentist는 데이터셋을 통해 파라미터를 추정하며, 데이터셋이 바뀌면 당연히 추정값이 바뀌게 된다. 전체 데이터셋을 batch 형태로 나누었다고 할 때, 각 batch 마다의 적합 회귀추정식을 $y(x; D)$, batch 마다 만들어진 추정회귀식의 평균을 $E_D[y(x;D)]$ 라고 하면 다음과 같은 분해가 가능하다.</p>\[\begin{align} \int \{ y(x)-h(x) \}^2 p(x) dx &amp; = \int \{ y_D(x)-E_D[y(x;D)] \}^2 p(x) dx + \int \{ E_D[y(x;D)] - h(x) \}^2 p(x) dx \\ &amp; =\ \ \ \ \ \textrm{Variance of } \ y_D(x) \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ + \ \ \ \ \ \ (bias)^2 \end{align}\]<p>여기서 분산이란 특정 데이터셋이 얼마나 민감한지를 나타내며 bias 란 추정한 회귀식의 평균값이 실제 참값이라고 여겨지는 h(x)와 어느정도 멀리 떨어져있는지를 알려준다.</p><p><br /></p><p>이제 모든 과정을 종합해보면</p>\[\textrm{Expected loss = squared bias + variance + noise}\]<p>임을 알 수 있다.</p><p><br /></p><h5 id="bias-variance-trade-off">bias-variance trade-off</h5><p>결국 expected loss 가 위와 같이 분해되기 때문에 bias 와 variacne 간의 trade - off 는 필연적이다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-16.png" width="70%" height="70%" title="1" alt="relative" /></p><p>위 그림은 regularization term $\lambda$ 값에 따라 bias와 variance가 어떻게 바뀌는지 simulation 한 결과이다. 제약이 강하게 들어갈 때, 분산이 줄어들고 상대적으로 bias 가 커진다.</p><p>decompostion을 통한 관계를 qunatitative하게 나타내면</p>\[\begin{align} &amp; (bias)^2 = \frac {1} {N} \sum_{n=1}^N \{\bar y(x_n) - h(x_n) \}^2 \\ &amp; Variance = \frac {1} {N} \sum_{n=1}^N \frac{1}{L} \sum_{l=1}^L \{y_{(l)}(x_n) - \bar y(x_n) \}^2 \end{align}\]<p><br /></p><h5 id="limitation">limitation</h5><p>식을 통해서도 알 수 있지만, 위의 decompostion은 data set의 평균에 관한 것이다. 그러나 현실에서는 오직 single data set만을 가진 경우가 허다하다. 이런 이유로 모델 complexity와 over-fitting 문제를 동시에 다룰 수 있는 Baysian approach를 공부해볼 필요가 있다.</p><p><br /></p><h3 id="34-bayesian-model-comparison-brief">3.4 Bayesian Model Comparison (brief)</h3><font color="blue"> intro </font><p>Model selection from Bayesian perspective 을 살펴보자. 3.4장에서는 간단한 개념만 살핀 뒤, 3.5장에서는 regularization parameter를 어떻게 결정할지에 대한 아이디어를 제시할 것이다.</p><p>베이지안 관점의 가장 큰 특징은 불확실성을 control할 수 있다는 것이다. 통상적으로 모델을 만들어 검증을 하는 방식으로 모델의 성능, 즉 over-fitting 여부를 확인한다. 반면 베이지안 관점에서는 training에 모든 데이터를 사용하므로 데이터 손실이 없으며, 동시에 모델의 복잡도를 fitting 과정에서 동시에 판단 가능하다. (이러한 내용은 Chap 7. relevance vector machine에 잘 나온다고 한다.)</p><font color="blue"> body </font><p>$\mathcal{M}_i$는 모델의 종류를 의미한다고 하자.</p><p>[notation]</p><p>prior ; $p(\mathcal{M}_i)$ ; uncertainty</p><div class="table-wrapper"><table><tbody><tr><td>model evidence ; $p(\mathcal{D}<td>\mathcal{M}_i)$ ; marginal likelihood</table></div><p>$\quad \because p(\mathcal{D}|\mathcal{M}_i) = \int p(\mathcal{D}|\mathcal{M}_i, \boldsymbol{w})p(\boldsymbol{w}|\mathcal{M}_i) d\boldsymbol{w}$ 이므로 $\boldsymbol{w}$ 가 marginalized out 된다고 보는 것.</p><div class="table-wrapper"><table><tbody><tr><td>posterior ; $p(\mathcal{M}_i<td>\mathcal{D})$</table></div><p>predictive distribution ; $p(t|x, \mathcal{D}) = \sum_{i=1} ^L p(t|x,\mathcal{M}_i, \mathcal{D})p(\mathcal{M}_i|\mathcal{D})$ ; mixture distribution</p><p><br /> [main]</p><p>위에서 기술한 것처럼 predictive dist는 model evidence를 posterior weight로 가중평균낸 것으로 model selection의 관점에서는 가장 그럴듯한 모델을 말하는 model evidence를 찾아야 한다. 즉, flat prior와 shaply peaked posterior를 가정할 때,</p>\[\begin{align} &amp;p(\mathcal{D}) = \int p(\mathcal{D}|w)p(w)\ dw \simeq p(\mathcal{D}|w_{MAP}) \frac {\Delta W_{posterior}}{\Delta W_{prior}} \\ &amp;ln \ P(\mathcal{D}) \simeq ln \ p(\mathcal{D}|w_{MAP}) + ln \ (\frac {\Delta W_{posterior}}{\Delta W_{prior}}) \end{align}\]<p>여기서 첫 번째 term은 각 모델에 데이터가 얼마나 잘 fitting 하는지를 나타내고(complexity가 높을수록 모델이 모든 데이터에 fitting 될 것), 두 번째 term은 모델 복잡도에 대한 penalty term을 나타낸다.(즉 모델이 복잡할수록 posterior는 간격이 좁아진다 =&gt; second term의 값을 줄여버린다) 따라서 최적의 모델 복잡도는 두가지 term의 trade off 를 통해 선택될 것이다.</p><p><br /></p><h3 id="35-the-evidence-appproximation">3.5 The Evidence Appproximation</h3><font color="blue"> intro </font><p>Evidence function에 대해 좀 더 설명하기 앞서, 데이터를 활용해서 predictive distribution을 form 하는 경우를 생각해보자.</p><p>predictive distribution $p(t|\boldsymbol{t})$은 hyperparameter $\alpha, \beta, w$를 marginalizing 한 것이라 생각할 수 있다. 즉,</p>\[p(t|\boldsymbol{t}) = \int \int \int p(t|\boldsymbol{w}, \beta)p(\boldsymbol{w}|\boldsymbol{t}, \alpha, \beta)p(\alpha, \beta|\boldsymbol{t}) \ d\boldsymbol{w} \ d\alpha \ d\beta\]<p>이때, hyperparameter $\alpha, \beta$를 marginal likellihood function을 극대화하는 추정량 $\hat \alpha , \hat \beta$ 로 정했을 때 predictive distribution을 approximation하는 경우를 생각해보자.</p><p>posterior $p(\alpha, \beta | \boldsymbol{t})$ 에 대해 $p(\alpha, \beta|\boldsymbol{t}) \propto p(\boldsymbol{t}|\alpha, \beta)p(\alpha, \beta)$ 이므로 flat prior를 생각하면 likelihood를 극대화하는 것이 곧 $\alpha, \beta$를 극대화 하는 것임을 알 수 있다.</p><p>이와 같이 온전히 데이터에 의존해서(likelihood) hyperparmeter를 결정하게 되면 predictive distribution을 아래와 같은 방식으로 구해낼 수 있다.</p>\[p( t | \boldsymbol{t}) \simeq p( t | \boldsymbol{t}, \hat \alpha , \hat \beta) = \int p(t|\boldsymbol{w}, \hat \beta) p(\boldsymbol{w}|\boldsymbol{t}, \hat \alpha \hat \beta) d \beta\]<p>즉 alpha 와 beta 값을 적절하게 추정하면 predicitve distribution을 보다 쉽게 만들 수 있음을 보였다.</p><p><br /></p><h4 id="351-evaluation-of-the-evidence-function">3.5.1 Evaluation of the evidence function</h4><p>likelihood function을 다시 한번 정의한 뒤, 이를 극대화하는 hyperparameter를 찾아보자.</p><p>marginal likelihood function $p(\boldsymbol{t}|\alpha, \beta)$는 weight parameter $\boldsymbol{w}$ 에 대한 적분을 통해 얻어진다. 즉,</p>\[p(\boldsymbol{t}|\alpha, \beta) = \int p(\boldsymbol{t}|\boldsymbol{w},\beta)p(\boldsymbol{w}|\alpha) d\boldsymbol{w}\]<p>이에 대한 적분 과정은 뒤에 연습문제로 잘 나타나있다. 특히 적분 결과가 Error function의 형태로 나타남에 주목할 만하다.</p><p>이를 전개한뒤, 로그를 씌우면</p>\[ln\ p(\boldsymbol{t}|\alpha, \beta) = \frac{M}{2}ln\ \alpha + \frac{N}{2}ln\ \beta - E(\boldsymbol{m}_N) -\frac{1}{2}ln\ |\boldsymbol{A}| - \frac{N}{2}ln\ (2\pi)\]<p>여기서 M은 parameter 차원을, N은 데이터의 개수를 의미한다.</p><p>3.4에서 likelihood를 data fitting 부분과 penalty 부분으로 나누어 보았는데 이러한 관점에서 볼 때, Figure 3.14는 M=3 이후로는 data fitting 보다 penalty 부분이 더 커지는 상황임을 알 수 있다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-17.png" width="70%" height="70%" title="1" alt="relative" /></p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-18.png" width="70%" height="70%" title="1" alt="relative" /></p><p>또한, Figure 1.5를 보면 베이지안 관점의 장점이 잘 드러난다. M=3,…,8 일 때 error 가 모두 동일해 어떠한 complexity에서 모델 fitting이 가장 잘 되었을지 수치적으로 확인하기 힘들지만 베이지안적 접근을 통해 이를 극복할 수 있다.</p><h4 id="352-maximizing-the-evidence-function">3.5.2 Maximizing the evidence function</h4><p>앞서 구한 $p(\boldsymbol{t}|\alpha, \beta)$ 를 maximizing하는 $\alpha$ 값을 찾아보자. 일차 미분한 뒤 그 식을 0으로 만들어주는 $\alpha$ 값을 구하면 아래와 같다.</p>\[\alpha = \frac{\gamma}{\boldsymbol{m}_n^T\boldsymbol{m}_n} \ \ \textrm{where} \ \ \gamma = \sum \frac{\lambda_i}{a+\lambda_i}\]<p>여기서 $\lambda$는 design matrix로 만든 행렬 $\Phi^T \Phi$의 고유값이고 $\boldsymbol{m}_n$ 또한 design matrix를 활용한 변환값이다. 즉 $\alpha$는 오로지 데이터에만 의존한다.</p><p>$\gamma$와 $\boldsymbol{m}_n$은 모두 $\alpha$에 의존하기 때문에 $\alpha$에 대한 초기값을 설정한 뒤 $\alpha$ 에 대한 iterative estimation 이 가능해진다.</p><p>$\beta$에 관해서도 동일한 방식으로 보일 수 있으며, hyperparameter인 $\alpha, \beta$를 업데이트 하는데 오로지 데이터에만 의존하는 것에 주목해야 한다.</p><h4 id="353-effective-number-of-parameters">3.5.3 Effective number of parameters</h4><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/prml-3-19.png" width="70%" height="70%" title="1" alt="relative" /></p><p>위의 그림을 볼 때, eigenvalue는 curvature를 나타내고, $\lambda_1$ &lt; $\lambda_2$ 이다.</p><p>$\alpha$ = 0이면 prior인 $p(\boldsymbol{w}|\alpha)$의 분산이 무한에 가깝다는 말이 되므로 flat prior를 의미하게 된다.</p><p>따라서 posterior $p(\boldsymbol{w}|\alpha, \boldsymbol{t})$의 mode는 $\boldsymbol{w}_{ML}$로 표현될 수 있다. (flat prior이므로 likelihood를 극대화하는 것이 사후분포를 극대화 하는 것이다)</p><p>반면 $\alpha$ &gt;0 이면 posterior인 $p(\boldsymbol{w} | \boldsymbol{t}) = \mathcal{N}(\boldsymbol{w} | \boldsymbol{m}_N, \boldsymbol{S}_N)$의 mode는 posterior의 평균 $\boldsymbol{m}_N$이다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/prml/" class="post-tag no-text-decoration" >PRML</a> <a href="/tags/machine-learning/" class="post-tag no-text-decoration" >Machine learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=PRML-3 - For Statistics&url=https://hwankam.github.io/posts/PRML3/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=PRML-3 - For Statistics&u=https://hwankam.github.io/posts/PRML3/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=PRML-3 - For Statistics&url=https://hwankam.github.io/posts/PRML3/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/PRML6/">PRML-6</a><li><a href="/posts/PRML5/">PRML-5</a><li><a href="/posts/PRML4/">PRML-4</a><li><a href="/posts/PRML3/">PRML-3</a><li><a href="/posts/CASI9/">Computer Age Statistical Inference - chap 9</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/datascience/">datascience</a> <a class="post-tag" href="/tags/datamining/">datamining</a> <a class="post-tag" href="/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/tags/islr/">ISLR</a> <a class="post-tag" href="/tags/statistical-method/">statistical method</a> <a class="post-tag" href="/tags/efron/">Efron</a> <a class="post-tag" href="/tags/prml/">PRML</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/categorical-data/">categorical data</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/PRML4/"><div class="card-body"> <span class="timeago small" >Jan 19<i class="unloaded">2022-01-19T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PRML-4</h3><div class="text-muted small"><p> 4. Linear Models for Classification 이번 chapter는 “Input space를 K개의 Class로 나누는 것”이 핵심이다. 이때 나눠지는 영역은 decision region, 나누는 boundary를 decision boundary 혹은 decision surface라 한다. 특히 이번 chapter에서 중요한 것은 ...</p></div></div></a></div><div class="card"> <a href="/posts/PRML5/"><div class="card-body"> <span class="timeago small" >Feb 9<i class="unloaded">2022-02-09T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PRML-5</h3><div class="text-muted small"><p> 5. Neural Networks chap 3과 4에서는 linear combination of fixed bases function에 대해 배웠다. 그러나 high dimension에서는 과적합의 문제가 발생하는 한계가 있었다. 이를 해결하기 위해 데이터에 맞게 basis function을 바꾸는 것은 어떠할까? SVM은 데이터에 맞게 hyper...</p></div></div></a></div><div class="card"> <a href="/posts/PRML6/"><div class="card-body"> <span class="timeago small" >Mar 1<i class="unloaded">2022-03-01T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PRML-6</h3><div class="text-muted small"><p> 6. Kernel Methods [서론] there is a class of pattern recognition techniques ==&gt; training data points are kept, memory based method ex ) nearest neighborhood 방법은 training data와 가장 유사한 label을 te...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/CASI9/" class="btn btn-outline-primary" prompt="Older"><p>Computer Age Statistical Inference - chap 9</p></a> <a href="/posts/CASI10/" class="btn btn-outline-primary" prompt="Newer"><p>Computer Age Statistical Inference - chap 10</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/username">your_full_name</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/datascience/">datascience</a> <a class="post-tag" href="/tags/datamining/">datamining</a> <a class="post-tag" href="/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/tags/islr/">ISLR</a> <a class="post-tag" href="/tags/statistical-method/">statistical method</a> <a class="post-tag" href="/tags/efron/">Efron</a> <a class="post-tag" href="/tags/prml/">PRML</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/categorical-data/">categorical data</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}}); </script> MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
