<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="ISLR chap 8" /><meta property="og:locale" content="en" /><meta name="description" content="8. Tree-Based Methods" /><meta property="og:description" content="8. Tree-Based Methods" /><link rel="canonical" href="https://hwankam.github.io/posts/ISLR8/" /><meta property="og:url" content="https://hwankam.github.io/posts/ISLR8/" /><meta property="og:site_name" content="For Statistics" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-08-08T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="ISLR chap 8" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"8. Tree-Based Methods","url":"https://hwankam.github.io/posts/ISLR8/","headline":"ISLR chap 8","dateModified":"2021-10-17T16:22:10+09:00","datePublished":"2021-08-08T00:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://hwankam.github.io/posts/ISLR8/"},"@type":"BlogPosting","@context":"https://schema.org"}</script><title>ISLR chap 8 | For Statistics</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="For Statistics"><meta name="application-name" content="For Statistics"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> </a></div><div class="site-title mt-3"> <a href="/">For Statistics</a></div><div class="site-subtitle font-italic">kam's world</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/Hwankam" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['example','doamin.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>ISLR chap 8</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>ISLR chap 8</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> your_full_name </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Aug 8, 2021, 12:00 AM +0900" >Aug 8, 2021<i class="unloaded">2021-08-08T00:00:00+09:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 17, 2021, 4:22 PM +0900" >Oct 17, 2021<i class="unloaded">2021-10-17T16:22:10+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3412 words">18 min read</span></div></div><div class="post-content"><h3 id="8-tree-based-methods">8. Tree-Based Methods</h3><p>tree-based method는 간단하게 말해서 preditor space(X 공간)를 층화 / 구분 짓고 각 영역의 데이터들에 대한 평균 혹은 중간값으로 예측을 해내는 구조를 말한다.</p><p>트리 기반의 방식들은 simple 하며 interpretation이 뛰어나나, 예측에 있어 다른 방법들에 비해 열등하다. 따라서 이를 보완하고자 bagging,boosting, Random Forest 등이 나왔는데 이 방식들은 트리를 여러개 만들어서 이들을 결합해 예측력을 높이려는 시도들이다. 즉 기존의 트리 기반 방식에 비해 모델의 해석력은 떨어지나, 예측력을 높인 것이다.</p><h4 id="81-the-basis-of-decision-trees">8.1 The Basis of Decision Trees</h4><h5 id="811-regression-trees">8.1.1 Regression Trees</h5><p>upside-down 형식으로 계속해서 가지를 쳐 나가며 분류하는데 각 가지에 의해 구분된 공간들을 terminal nodes 혹은 leave 라고 한다. 또한 predictor space가 나눠지는 점들을 internal nodes 라고 한다. Node를 이어주는 부분들을 branch라고 한다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/islr8-1.png" width="70%" height="70%" title="1" alt="relative" /></p><p>upside down 형식의 tree 구조를 해석해보자</p><p>years 가 target 변수를 해석하는 가장 큰 요인이 됨을 그림에서 알 수 있다. 또한 hits의 경우 years가 낮은 집단에 대해서는 target 변수를 결정하는 큰 요인이 되지는 못하지만, years가 높은 경우에는 hits가 target변수를 결정하는 큰 기준이 된다. 그림에서 나타듯, tree based method는 직관적이고 모델을 해석하기 쉽다.</p><h6 id="building-regression-tree">building regression tree</h6><ol><li>predictor space를 겹치지 않게 나눈다. R_j<li>각 영역 R_j 에 속한 관측치들은 모두 같은 값으로 예측하게 된다</ol><p>어떻게 겹치지 않게 predictor space를 나눌 수 있을까?</p><p>여기서도 결국 RSS를 최소화 하는 방식으로 space를 나누고자 한다. 즉, \(\sum_j \sum _ i (y_i - \hat y_{R_j})^2\) 를 최소화하는 box \(R_1, R_2, ....,R_J\) 로 영역을 나누면 된다.</p><p>그러나 현실적으로 모든 box들을 고려하는 것은 계산상으로 문제가 있기 때문에 top down 방식으로 각 step마다 최고의 성능(가장 rss를 작게하는)의 split을 고른다. 이를 recursive binary splitting이라 한다(변수 선택의 forward selection과 유사). <strong>특이한 점이 있다면, 가지수를 무한대로 늘리는 것이 아니라 각 변수마다 여러가지 branch 중 하나만 선택해서 terminal nodes를 만든다는 것에 있다.</strong></p><h6 id="tree-pruning">tree pruning</h6><p>tree의 split이 너무 많게 되면 복잡해지고 분산이 커져 예측력이 떨어질 수 있다. <strong>(1)</strong> 이를 해결하기 위해, 모델을 결정할 때 모델의 복잡성에도 불구하고 RSS가 더 작아지는 이점이 더 클 때까지 분할을 하는 방법을 생각할 수 있다. 그러나 이는 어쩌면 매우 작은 tree(분할이 몇개 없는)를 만들거나 혹은 직관적으로 의미없는 tree 일 수도 있다(즉 더 많은 분할이 이뤄진 뒤에 RSS의 급격한 감소가 일어날 수도 있는데 이를 고려하지 않기 때문에). 따라서 교재에서 추천하는 방법은 <strong>(2)</strong> 매우 큰 모델을 하나 만든 다음 역으로 이를 줄여나가 subtree를 찾는 것이다.</p><p>이제 모델을 줄여나가는 방법을 알아보자</p><p>pruning 의 방법으로서 test error rate을 확인하는 것이 있다. 그러나 이를 위해서 각 subtree 마다 CV 혹은 validation set approach를 하는 것은 복잡한 계산을 더욱 복잡하게 만드는 것이다. 따라서 subtree를 몇개 선정해서 CV를 진행한다.</p><p>그럼 subtree는 또 어떻게 결정할 것인가?</p><p>==&gt; Cost Complexity prunning(weakest link pruning) : nonnegative tuning parameter alpha 를 가지고 판정. 수식은 아래와 같은데 T는 terminal node를 의미한다.</p>\[\sum _m ^ {|T|} \sum _{x_i \in R_m} (y_i - \hat y_{R_m})^2 + \alpha |T|\]<p>lasso 처럼 alpha값을 가지고 node의 개수를 조절하면서 RSS를 최소화 하는 모델을 결정하는 것이다.</p><p>CV값을 가지고 몇개의 후보군 alpha를 선택</p><p>pruning의 알고리즘은 다음과 같다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/islr8-2.png" width="70%" height="70%" title="1" alt="relative" /></p><p>정리하면 큰 모델을 만들어낸 다음, 적절한 alpha 후보군을 가지고 CV를 해서 test error rate(이에 대한 예측값이 CV)을 최소로 하는 alpha를 정한다. alpha를 정한다는 것은 곧 변수의 개수를 통제하고 정하는 다는 것이므로 CV error 를 최소로 하는 변수의 개수를 선택하게 된다.</p><h5 id="812-classification-trees">8.1.2 Classification Trees</h5><p>어떤 class에 속할지 예측하는 데에 목적. class prediction, class proportion 두 개 다 관심 대상</p><p>tree growing은 여전히 classification tree에서도 주요 사항인데 regression에서는 RSS를 기준으로 삼았던 것과는 달리 여기선 classification error rate을 기준으로 삼는다.</p><p>classification error rate : the fraction of the training observation in that region that do not belong to the most common class (class는 본래 분류, region은 추정 분류)</p><p>책에는 아래와 같은 식을 보여주는데 이는 1-error rate으로 accuracy를 말하는 것 같다.</p><p>$ E = 1 - max_k(\hat p_{mk}) $</p><p>\(\hat p _{mk}\) 는 proportion of the training observation in the m-th region that are from the k-th class.</p><p>방금 전에도 기술했지만 error rate은 prediction accuracy와 관련된 것으로 accuracy를 목적으로 할 때에는 error rate을 주목해서 보겠지만, tree-growing에 대한 판단을 할 때에는 다른 기준을 사용한다.</p><ol><li>Gini index ( a measure of total variance <u>across</u> the K classes)</ol><p>$ G = \sum \hat p_{mk}(1- \hat p _{mk}) $</p><p>이는 각 노드의 purity 를 측정하는 것으로 hat p 값이 0 혹은 1에 가까울 수록 그 값이 낮아진다. 따라서 이 값은 작으면 작을수록 좋은 것이다.</p><ol><li>Cross-entropy</ol><p>$ D = - \sum \hat p _{mk} log (\hat p _{mk}) $</p><p>이 값 역시 hat p 값이 0 혹은 1에 가까울수록 0에 가까운 값을 가진다. 이 또한 purity를 측정하는 값이다.</p><p>질적 변수 또한 분류의 기준이 될 수도 있다. 또한 purity를 기준으로 tree-growing을 실행했을 때, 같은 predicted value를 갖는 terminal node 도 존재한다. 즉 하나의 기준에 따라 나눠진 값이 모두 같은 값을 가질 수도 있다.</p><h5 id="813-trees-versus-linear-methods">8.1.3 Trees Versus Linear Methods</h5><p>본래 데이터 관계가 선형이면 당연히 linear 한 방법이 좋을 것.</p><p>본래 데이터 관계를 차치하고서도 분석의 목적이 interpreability나 visualization에 있다면 tree-based method 가 더 좋을 것.</p><h5 id="814-advantages-and-disadvantages-of-trees">8.1.4 Advantages and Disadvantages of Trees</h5><p>장점</p><ol><li>다른사람들에게 모델에 대해 설명하는 경우 linear regression 보다도 설명하기가 쉽다<li>보다 인간의 사고 방식과 유사하다<li>시각적으로 보여주기 쉽다<li>더미변수 없이도 질적변수를 다룰 수 있다.</ol><p>단점</p><ol><li>예측력이 떨어진다. 이를 극복하기 위해 아래 내용들이 나옴.</ol><h4 id="82-bagging-random-forest-boosting">8.2 Bagging, Random Forest, Boosting</h4><p>위 세가지는 tree를 예측력이 높은 모델을 만들기 위한 하나의 block으로 여긴다.</p><h5 id="821-baggingcreating-fitting-combining">8.2.1 Bagging(creating, fitting, combining)</h5><p>boostrap + aggregation</p><p>목적 : 예측력을 위해 분산을 줄여보자.</p><p>어떻게? 평균으로 예측하면서 ( 표본평균의 분산이 모 분산에 비해 작아지는 것과 동일한 원리)</p><p>그런데 multiple training set을 얻기 힘드니까 boostrap을 사용하는 것.</p><p>B개의 다른 boostrapped training data set을 가지고 학습을 시켜 모델</p><p>\(\hat f ^{*b}(x)\) 을 만들고 이를 평균 내어 추정한다.</p><p>그럼 붓스트랩 data set 개수 B는 어떻게 결정되는 것인가? 딱히 정해진 것은 없으며 개수가 많아도 overfitting의 위험이 없다. 즉 error를 가장 작게 만드는 큰 값이 좋을 것이다.</p><p>bagging은 사실 많은 회귀문제에 사용될 수 있는 방법인데 특히 분산이 큰 decision tree에 유용하다. 또한 boostraping을 사용할 때 block으로 여겨지는 tree들은 deep하고 prune 되지 않은 것이다.</p><p>classification 에서 bagging을 사용하는 방법은 각 트리에서 나온 분류 예측값들을 가지고 voting을 통해 결정한다.</p><h5 id="out---of---bag-error-estimation">Out - of - Bag Error Estimation</h5><p>boostrap 방법의 특징을 이용해서 error를 측정하는데 이는 boostrap data set B가 매우 클 때 leave-one-out cross-validation과 유사하다(즉 데이터가 부족할 때 k-fold 처럼 많은 수의 데이터를 validation set으로 놓기 힘들 때 유용하다). Data set이 너무 큰 경우 CV error를 계산하는데 필요한 계산량이 매우 많은데 이 대신에 OOB error를 사용할 수 있다.</p><p>방법은 다음과 같다. boostraping 을 하는데 사용하는 observation 중에서 2/3 만 사용해서 boostrapping sample을 만든다. 그 뒤 이를 적합시켜 모델을 만들고 남은 1/3의 관측치에 대한 예측값을 구하고 OOB MSE를 구한다. 이 error 값이 bagged model의 test error에 대한 추정값이 된다.</p><h5 id="variable-importance-measures">Variable Importance Measures</h5><p>bagging을 하면 해석력이 떨어지고 visualization이 어렵다. 즉 더이상 statistical learning procedure을 트리 형태로 보이기 어렵다. 이는 어떠한 변수가 더 중요한 것인지 시각화하기 어렵다는 것이다. 단 이러함을 감수하고서도 예측력은 더 좋아질 것이다.</p><p>그럼에도 불구하고 bagging을 통해 알아낼 수 있는 부분은, 각 변수들에 대해서 그 변수를 split 했을 때, RSS 감소량 혹은 Gini-index의 감소량의 총합(각 모델과 bagging에 의한 rss, gini-index)이 크면 그 변수는 상대적으로 더 중요한 것이라고 할 수 있다.</p><h5 id="822-random-forests">8.2.2 Random Forests</h5><p>Random Forest는 bagged tree를 개선시킨 것으로서 boostarping 이전 변수의 일부분만 뽑아서 이들을 가지고 모델에 적합시킨다. 이 방법은 예측값의 correlation을 낮춰줄 수 있다. 만일 특정변수가 매우 영향력이 크다면 bagged tree들은 모두 특정변수를 top split으로 둔 model이 될 것이다. 이러한 경우 결과값이 매우 유사해질 것이고 평균 시 variance의 감소 효과가 미미하다. Random Forest는 predictor 중 일부분만 변수로 넣게 함으로써 uncorrelated quantity들을 평균시킬 수 있다.</p><p>이때 각 split은 m 개의 변수로 이뤄지며 전체 변수 개수가 p 일 때 \(m =\sqrt (p)\) 이다.</p><p>(oob는 행을 떼어내는 것, RF는 열을 떼어내는 것)</p><p>RF는 bagging의 일종이므로 bagging data set B의 크기는 overfitting과 관련이 없다.</p><h5 id="823-boosting">8.2.3 Boosting</h5><p>Boosting 또한 tree-based method 뿐만 아니라 다른 regression 혹은 classification에서도 쓸 수 있다.</p><p>Boosting의 방식 또한 ‘creating + fitting+combining’으로 bagging과 유사하다.</p><p>단 tree가 sequentially 증가한다는 데에 차이가 있다. “<strong>each tree is grwon using information from previously grown trees</strong>” 이 말 뜻은 정해진 모델들에서 나온 값들을 combining하지는 bagging과는 다르게, boosting 은 잔차를 살피고 이에 따라 가중치를 달리주면서 모델을 점점 만들어나간다는 것이다.</p><p>또한 boostrapping을 통해 표본을 만들어 내는 것이 아니라, 각 tree들이 본래 데이터의 변형된 형태에 적합이 된다는 것에 차이가 있다.</p><p>알고리즘은 다음과 같다</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/islr8-3.png" width="70%" height="70%" title="1" alt="relative" /></p><p>알고리즘이 의미하는대로, boosting은 y의 값이 아닌 업데이트 된 잔차를 target 변수처럼 생각하고 적합하는 데에 있다. 적합된 모델은 기존의 적합 모델과 더해지고 lambda에 따라서 여러가지 적합 모델이 잔차를 attack(상쇄시키려 노력, 잔차를 없애려고 노력)한다.</p><p>충분히 예상하겠지만 이러한 과정은 모델의 학습 속도를 늦추게 한다.</p><p>boosting은 세가지 tuning parameter를 갖는다.</p><p>(1) the number of trees B. 여기서 B는 그림의 알고리즘에 나오는 B이다. 즉 업데이트 횟수. boosting은 bagging이나 RF와는 달리 overfitting이 될 수 있기 때문에 CV를 통해 최적의 횟수를 결정해야한다.(앞에서 보았듯, bagging이나 RF는 B의 개수가 overfitting을 결정하진 않았다)</p><p>(2) the shrinkage parameter lambda. 이는 부스팅을 통해 학습을 하는 비율을 조절한다. 일반적으로 0.01 혹은 0.001을 사용한다. 이 값이 작으면 좋은 성능을 위한 학습의 횟수가 많이 요구된다.</p><p>(3) the number of d. 즉 변수의 개수. 이는 앙상블의 복잡성을 통제. 변수의 개수인 만큼 interaction depth를 결정한다고 말할 수 있다. 즉 변수가 많아지면 변수간의 교호작용도 많이 고려해야한다.</p><p>또한 Boosting은 RF와 다르게 tree의 성장이 이전 tree에 영향을 받기 때문에 더 작은 tree 또한 설명력이 좋을 수 있다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/datascience/" class="post-tag no-text-decoration" >datascience</a> <a href="/tags/datamining/" class="post-tag no-text-decoration" >datamining</a> <a href="/tags/machinelearning/" class="post-tag no-text-decoration" >machinelearning</a> <a href="/tags/islr/" class="post-tag no-text-decoration" >ISLR</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=ISLR chap 8 - For Statistics&url=https://hwankam.github.io/posts/ISLR8/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=ISLR chap 8 - For Statistics&u=https://hwankam.github.io/posts/ISLR8/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=ISLR chap 8 - For Statistics&url=https://hwankam.github.io/posts/ISLR8/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/PRML6/">PRML-6</a><li><a href="/posts/PRML5/">PRML-5</a><li><a href="/posts/PRML4/">PRML-4</a><li><a href="/posts/PRML3/">PRML-3</a><li><a href="/posts/CASI9/">Computer Age Statistical Inference - chap 9</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/datascience/">datascience</a> <a class="post-tag" href="/tags/datamining/">datamining</a> <a class="post-tag" href="/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/tags/islr/">ISLR</a> <a class="post-tag" href="/tags/statistical-method/">statistical method</a> <a class="post-tag" href="/tags/efron/">Efron</a> <a class="post-tag" href="/tags/prml/">PRML</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/categorical-data/">categorical data</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/ISLR2/"><div class="card-body"> <span class="timeago small" >Jul 29, 2021<i class="unloaded">2021-07-29T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ISLR chap 2</h3><div class="text-muted small"><p> 2.1 What is statistical learning? 2.1.1 X : predictor, features, independent variable Y : response, dependent variable $ Y = f(X) + \epsilon $ $ \hat Y = \hat f(X) $ reducible error : Y를 ...</p></div></div></a></div><div class="card"> <a href="/posts/ISLR2-LAB/"><div class="card-body"> <span class="timeago small" >Jul 30, 2021<i class="unloaded">2021-07-30T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ISLR - LAB2</h3><div class="text-muted small"><p> R 코드 정리 #할당, c는 백터를 의미 x &lt;- c(1,2,3,4) # 백터의 원소 개수 length(x) #저장되어 있는 변수 모두 호출 ls() #remove rm(x) rm(list=ls()) #행렬 x = matrix(data=c(1,2,3,4), nrow=2, ncol=2) x y = matrix(data=c(1,2,3,4), nr...</p></div></div></a></div><div class="card"> <a href="/posts/ISLR3-LAB/"><div class="card-body"> <span class="timeago small" >Jul 30, 2021<i class="unloaded">2021-07-30T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ISLR - LAB3</h3><div class="text-muted small"><p> R 코드 정리 library(MASS) fix(Boston) #table 형태로 보여주기 names(Boston) # 열 이름 보여주기 attach(Boston) lm.fit = lm( medv ~ lstat) summary(lm.fit) """ Call: lm(formula = medv ~ lstat) Residuals: Min ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/ISLR8-LAB/" class="btn btn-outline-primary" prompt="Older"><p>ISLR - LAB8</p></a> <a href="/posts/ISLR9/" class="btn btn-outline-primary" prompt="Newer"><p>ISLR chap 9</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/username">your_full_name</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/datascience/">datascience</a> <a class="post-tag" href="/tags/datamining/">datamining</a> <a class="post-tag" href="/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/tags/islr/">ISLR</a> <a class="post-tag" href="/tags/statistical-method/">statistical method</a> <a class="post-tag" href="/tags/efron/">Efron</a> <a class="post-tag" href="/tags/prml/">PRML</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/categorical-data/">categorical data</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}}); </script> MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
