<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="ISLR chap 7" /><meta property="og:locale" content="en" /><meta name="description" content="7. Moving Beyond Linearity" /><meta property="og:description" content="7. Moving Beyond Linearity" /><link rel="canonical" href="https://hwankam.github.io/posts/ISLR7/" /><meta property="og:url" content="https://hwankam.github.io/posts/ISLR7/" /><meta property="og:site_name" content="For Statistics" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-08-05T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="ISLR chap 7" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"7. Moving Beyond Linearity","url":"https://hwankam.github.io/posts/ISLR7/","headline":"ISLR chap 7","dateModified":"2021-10-17T16:22:10+09:00","datePublished":"2021-08-05T00:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://hwankam.github.io/posts/ISLR7/"},"@type":"BlogPosting","@context":"https://schema.org"}</script><title>ISLR chap 7 | For Statistics</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="For Statistics"><meta name="application-name" content="For Statistics"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> </a></div><div class="site-title mt-3"> <a href="/">For Statistics</a></div><div class="site-subtitle font-italic">kam's world</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/Hwankam" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['example','doamin.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>ISLR chap 7</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>ISLR chap 7</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> your_full_name </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Thu, Aug 5, 2021, 12:00 AM +0900" >Aug 5, 2021<i class="unloaded">2021-08-05T00:00:00+09:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 17, 2021, 4:22 PM +0900" >Oct 17, 2021<i class="unloaded">2021-10-17T16:22:10+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2537 words">14 min read</span></div></div><div class="post-content"><h3 id="7-moving-beyond-linearity">7. Moving Beyond Linearity</h3><p>relax the linearity assumption while still attempting to maintain as much interpretability as possible</p><h4 id="71-polynomial-regression">7.1 Polynomial Regression</h4><p>변수들의 제곱항이나 세제곱항을 추가한 뒤에 기존의 linear regression이나 logistic regression을 똑같이 적합시키면 된다. 차원이 높아질수록 매우 비선형적인 그래프가 만들어질것이고 이 경우 심각한 오버피팅의 위험이 있기 때문에 보통은 3차원 혹은 4차원 정도에서 적합한다.</p><h4 id="72-step-functions--piecewise-constant-regression-">7.2 Step Functions ( piecewise constant regression )</h4><p>global structure을 피하고 step function을 사용해서 X 변수를 quantitative =&gt; qualitative로 바꾼다.</p><p>cutting 방법은 그림과 같이 cutpoint를 설정 후 categorical 변수로 바꾸는 것이다. dummy화 시키는 것</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/islr7-1.png" width="70%" height="70%" title="1" alt="relative" /></p><p>각 bin을 predictor로 사용해서 회귀식에 적합</p><p>$ y_i = \beta_0 + \beta_1C_1(x_i) + \beta_2C_2(x_i) + …+\beta_kC_k(x_i) + \epsilon_i $</p><p>단, breakpoint를 잘못 설정하면 변수간의 증감이 드러나지 않을 수도 있다.</p><h4 id="73-basis-functions">7.3 Basis Functions</h4><p>polynomial regression 혹은 piecewise-constant regression 은 basis function approach의 일종이다. basis function을 b는 연구자에 의해 사전에 정해진 것으로 이를 활용해서 predictor를 변화시켜 적합</p><p>$ y_i = \beta_0 + \beta_1b_1(x_i) + \beta_2b_2(x_i) + …+\beta_kb_k(x_i) + \epsilon_i $</p><p>polynomial function, step function, wavelets, Fourier series 등이 basis function으로 사용 가능 regression spline 또한 basis function을 사용한 회귀이다.</p><h4 id="74-regression-splines">7.4 Regression Splines</h4><p>flexible class of basis functions</p><h5 id="741-piecewise-polynomials">7.4.1 Piecewise Polynomials</h5><p>X 변수의 각 영역(piecewise)에 낮은 차수의 각기 다른 polynomial을 적합시키는 것.</p><p>회귀 계수가 변하는 부분, 즉 cutpoint를 knot라고 부른다.</p><p>만약 single knot를 가진 piecewise cubic polynomial을 적합시키고자 한다면 \(y_i = \begin{cases} \beta_{01} + \beta_{11}x_i + \beta_{21}x_i^2 &amp; if \ \ x_i &lt; c \\ \beta_{02} + \beta_{12}x_i + \beta_{22}x_i^2 &amp; if\ \ x_i \geq c \end{cases}\)</p><p>결국 앞에서 나온 step function은 knot를 통해 나눠진 구간에, 적합시키는 polynomial의 차수가 0인 것이고 simple 한 polynomial은 knot가 0개인 Piecewise Polynomials를 의미하는 것이다.</p><p>단점? 이라면 piecewise polynomial들이 불연속일 수 있고, knots의 개수가 늘어나면 모델 전체의 계수도 많아지는 것이므로 자유도가 늘어난다.</p><h5 id="742-constraints-and-splines">7.4.2 Constraints and Splines</h5><p>Constraints가 필요한 이유? knot에 의해 나눠진 각 section 별 함수가 불연속일 수 있다. 이는 데이터 자체가 가진 본연의 이유가 아니라면 매우 어색한 것.</p><p>continuity와 smoothness를 주기 위해 constraints가 필요하다. 단 이러한 제약을 위해서 어느정도의 자유도는 감소된다.</p><p>예를들어 cubic spline은 third ordered piecewise polynomial에 3개의 제약(continuity, continuity of the first derivative, continuity of the second derivate)을 주면서 continuity와 smoothness를 달성</p><p>linear spline은 각 적합 함수가 선형이며 knot에서 연속성을 갖는 spline을 말한다.(smoothness는 달성하지 못함)</p><h5 id="743-the-spline-basis-representation">7.4.3 The Spline Basis Representation</h5><p>basis model을 활용해서 복잡한 spline을 표현해보자</p><p>cubic spline의 경우(knots는 K개) \(y_i = \beta_0 + \beta_1 b_1(x_i) + \beta_2b_2(x_i) + ... + \beta _{K+3}b_{K+3}(x_i) + \epsilon_i\)</p><p>((cubic spline의 경우 자유도가 (knot 개수 K + 4)이다. 그 이유는 제약이 없을 때 자유도는 4K 인데 knot 하나당 제약으로 인해 자유도가 3씩 줄어 4(K+1) - 3K 가 최종 자유도가 되기 때문이다.))</p><p>basis model을 cubic polynomial와 truncated power basis function으로 표현해보자.</p><p>truncated power basis function이 다음과 같이 정의될 때</p><p>$ h(x,\xi) = (x-\xi)_+^3 = \begin{cases} (x-\xi)^3 &amp; \ \ if \ \ x &gt; \xi \ 0 &amp; \ \ otherwise \end{cases} $</p><p>basis function을 \(X, X^2, X^3, h(X,\xi_1), h(X,\xi_2), ...,h(X,\xi_K)\) 로 잡으면 cubic spline을 basis function을 사용해서 표현하게 되는 것이다.</p><p>그러나 이 경우에 predictor 값의 양 극단 부분에서는 분산이 매우 커지게 되는 경우가 발생한다. 이를 방지하기 위해서 ‘natural spline’이 등장하는데 양 극단 데이터에 대한 추가적인 가정을 부여하는 것이다. 단, 조건은 함수가 양 극단에서 linear 해야한다는 것. natural spline으로 인해 자유도는 기존의 cubic spline에 비해 4만큼 빠짐</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/islr7-2.png" width="70%" height="70%" title="1" alt="relative" /></p><h5 id="744-choosing-the-number-and-locations-of-the-knots">7.4.4 Choosing the Number and Locations of the Knots</h5><p>(1) location</p><p>함수가 급격하게 변할것 같은 부분을 연구자가 선택?</p><p>자유도를 연구자가 정한 뒤에 소프트웨어에 의해 uniform 하게 선택?</p><p>(2) number</p><p>가장 좋아보이는 curve를 그리는 knot의 개수를 선택?</p><p>CV의 결과 RSS가 가장 낮은 K를 선택</p><h5 id="745-comparison-to-polynomial-regression">7.4.5 Comparison to Polynomial Regression</h5><p>polynomial은 flexible fit을 위해 degree(자유도, 차수)를 높여야 하는데 spline은 차수를 정해놓고, knot를 바꿔가면서 flexibility를 달성할 수 있다. 또한 함수 전체가 아닌 일부의 필요한 부분에 flexibility를 높이니까 훨씬 적합이 잘 된다. 추정량도 안정적이다. 특히 flexibility를 과하게 주면 데이터의 양 극단 부분에서 적합이 잘 안되고 분산이 매우 커지는데, natural spline의 경우 이 또한 방지 가능하다.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/islr7-3.png" width="70%" height="70%" title="1" alt="relative" /></p><h4 id="75-smoothing-splines">7.5 Smoothing Splines</h4><h5 id="751-an-overview-of-smoothing-splines">7.5.1 An Overview of Smoothing Splines</h5><p>spline regression은 knot와 basis function을 결정해서 LSE로 계수를 추정하는 것이었다면 smoothing spline은 좋은 fitting을 위해 RSS를 줄이는 것에 기반한다. 단지 RSS만을 줄이는 것이 아니라 smoothness를 고려한다. 즉 아래의 식을 최소로 하는 g function을 찾고자 한다.</p><p>$ \sum (y_i - g(x_i))^2 + \lambda\int g’‘(t)^2dt $</p><p>이는 smoothness를 주기 위해서 penalty 항을 부여하는 것이다. 이를 좀 더 자세히 설명하면 \(g''(x)\) 함수는 roughness에 대한 measure로 기울기의 변화율이다. 이를 적분해서 \(g'(x)\) 에 대한 total change를 평가한 것이 \(\int g''(t)^2\) 이 되는 것이다.</p><p>또한,</p><p>Ridge, Lasso와 비슷하게 tuning parameter lambda를 가지고 bias - variance trade-off 를 조절할 수 있다. 즉 natural cubic spline의 shrunken version이 smoothing spline 이라 할 수 있다.</p><h5 id="752-choosing-the-smoothing-parameter-lambda">7.5.2 Choosing the Smoothing Parameter lambda</h5><p>모든 unique 값인 x_i에 대해 knot를 잡고 natural cubic spline을 하면 그것이 smoothing spline이 된다.(왜냐면 rss를 줄이고자 하는것이니까 모든 x_i에 대해 knot를 주는 것과 같다!) 그러나 모든 데이터에 대해 knot을 주면 자유도가 커진다. 여기서 lambda값을 통해 자유도를 control 하는 것이다.</p><p>smoothing spline에서는 knot의 개수나 위치를 따로 구할 필요가 없다. 계산에 의해 알아서 해주니까. 단, 여기서는 tuninig parameter인 lambda 값을 정해야 한다. lambda값은 커지면 모델의 flexibility가 줄어드는데 이 값과 반대의 역할을 가지는 parameter로 effective degree of freedom \(df_\lambda\) 가 있다. smoothing spline에서는 모든 데이터에 대해 knot를 주고 lambda로 variance를 조절하기 때문에 effective degree of freedom으로 자유도(분산과 관련있는 것)를 판단한다.</p><p>이 값을 구하는 공식은 아래와 같다. smoothing spline을 적합한 fitted value를 벡터로 표현한 것이 \(\hat g_\lambda = S_\lambda y\) 라고 할 때 \(df_\lambda = trace(S_\lambda)\)</p><p>적당한 lambda 값은 어떻게 구할 것인가? CV를 이용.</p><p>특히 LOOCV 같은 경우 계산이 쉽다.</p><p>==&gt; \(RSS_{cv}(\lambda) = \sum(y_i - \hat g_\lambda^{(-i)}(x_i))^2 = \sum [\frac {y_i - \hat g_\lambda(x_i)}{1-\{ \ S_\lambda \}_{ii}}]^2\)</p><h4 id="76-local-regression">7.6 Local Regression</h4><p>알고리즘은 다음과 같다</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 70% 70%'%3E%3C/svg%3E" data-proofer-ignore data-src="/assets/img/islr7-4.png" width="70%" height="70%" title="1" alt="relative" /></p><p>각 값에 대한 예측치를 주변 값을 이용해 하나하나 찾아가는 게 특징이다. (KNN과 유사)</p><p>KNN에서 K 값을 어떻게 정할지가 중요한 것 처럼 여기서도 s 값을 어떻게 정할지 결정해야 하는데 일반적으로는 CV를 통해서 정한다. s의 값이 작으면 fitting이 보다 local에 맞춰질 것이다(wiggly)</p><p>거리에 따라 weight를 주고 난 뒤에는 weighted least square를 통해 예측값을 정한다.</p><p>또한 여러가지 변수를 종합적으로 보고 거리에 포함시킬지 말지 정할 수도 있는데 변수 개수가 너무 많은 경우, training에 필요한 변수가 적어 오버피팅 발생 가능.</p><h4 id="77-generalized-additive-models">7.7 Generalized Additive Models</h4><p>가법성(additivity)을 유지하면서 선형 모델을 비선형 모델으로 확장. 반응변수가 양적 혹은 질적 변수인 경우 모두 사용 가능.</p><h5 id="771-gams-for-regression-problems">7.7.1 GAMs for Regression Problems</h5><p>7.1-7.6에서는 하나의 변수에 대해 fitting function을 다르게 주는 법을 공부했다.</p><p>GAMs 의 특징은 “we can use these(7.1-7.6) methods as building blocks for fitting an additive model”</p><p>$ y_i = \beta_0 + \sum_j f_j(x_{ij}) + \epsilon_i $</p><p>즉 각 변수마다 spline, local regression, polynomial 등등을 사용한 뒤 이를 가법모형으로 만들어 합치는 방식으로 모형을 fitting 하는 것.</p><h6 id="pros-and-cons">pros and cons</h6><p>장점 :</p><p>(1) 모델을 쌓을 때 비선형 모델을 추가할 수 있기 때문에 선형모델이라는 제약에서 쉽게 벗어날 수 있고, 따로 변수를 변환해주는 등의 노력이 필요 없다.</p><p>(2) 비선형 모델이 들어가기 때문에 fitting이 더 잘될 것</p><p>(3) 가법 모형이기 때문에 나머지 변수를 고정한 채로 하나의 변수의 영향력을 알 수 있다. 그러니까 모델의 해석력이 좋을 것.</p><p>(4) smoothness도 포함 가능</p><p>단점:</p><p>(1) 이름에서도 알 수 있듯, ‘가법’이라는 것에 모형을 한정시킨다. 따라서 변수간의 interaction이 포함되지 못한다. 그러나 애초에 변수 자체에 interaction을 포함시키고 이를 가법으로 쌓으면 앞의 문제를 상쇄 할 수 있다.</p><p>GAMs는 linear 모형과 더 flexible한 모형인 RF, Boosting의 compromise</p><h5 id="772-gams-for-classification-problems">7.7.2 GAMs for Classification Problems</h5><p>로지스틱 회귀를 예로 들면</p><p>$ log(\frac {p(X)}{1-p(X)}) = \beta_0 + \sum_j f_j(x_{j}) $</p><p>와 같이 적합된 모델을 쌓아서 분류한다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/datascience/" class="post-tag no-text-decoration" >datascience</a> <a href="/tags/datamining/" class="post-tag no-text-decoration" >datamining</a> <a href="/tags/machinelearning/" class="post-tag no-text-decoration" >machinelearning</a> <a href="/tags/islr/" class="post-tag no-text-decoration" >ISLR</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=ISLR chap 7 - For Statistics&url=https://hwankam.github.io/posts/ISLR7/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=ISLR chap 7 - For Statistics&u=https://hwankam.github.io/posts/ISLR7/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=ISLR chap 7 - For Statistics&url=https://hwankam.github.io/posts/ISLR7/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/PRML6/">PRML-6</a><li><a href="/posts/PRML5/">PRML-5</a><li><a href="/posts/PRML4/">PRML-4</a><li><a href="/posts/PRML3/">PRML-3</a><li><a href="/posts/CASI9/">Computer Age Statistical Inference - chap 9</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/datascience/">datascience</a> <a class="post-tag" href="/tags/datamining/">datamining</a> <a class="post-tag" href="/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/tags/islr/">ISLR</a> <a class="post-tag" href="/tags/statistical-method/">statistical method</a> <a class="post-tag" href="/tags/efron/">Efron</a> <a class="post-tag" href="/tags/prml/">PRML</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/categorical-data/">categorical data</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/ISLR2/"><div class="card-body"> <span class="timeago small" >Jul 29, 2021<i class="unloaded">2021-07-29T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ISLR chap 2</h3><div class="text-muted small"><p> 2.1 What is statistical learning? 2.1.1 X : predictor, features, independent variable Y : response, dependent variable $ Y = f(X) + \epsilon $ $ \hat Y = \hat f(X) $ reducible error : Y를 ...</p></div></div></a></div><div class="card"> <a href="/posts/ISLR2-LAB/"><div class="card-body"> <span class="timeago small" >Jul 30, 2021<i class="unloaded">2021-07-30T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ISLR - LAB2</h3><div class="text-muted small"><p> R 코드 정리 #할당, c는 백터를 의미 x &lt;- c(1,2,3,4) # 백터의 원소 개수 length(x) #저장되어 있는 변수 모두 호출 ls() #remove rm(x) rm(list=ls()) #행렬 x = matrix(data=c(1,2,3,4), nrow=2, ncol=2) x y = matrix(data=c(1,2,3,4), nr...</p></div></div></a></div><div class="card"> <a href="/posts/ISLR3-LAB/"><div class="card-body"> <span class="timeago small" >Jul 30, 2021<i class="unloaded">2021-07-30T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ISLR - LAB3</h3><div class="text-muted small"><p> R 코드 정리 library(MASS) fix(Boston) #table 형태로 보여주기 names(Boston) # 열 이름 보여주기 attach(Boston) lm.fit = lm( medv ~ lstat) summary(lm.fit) """ Call: lm(formula = medv ~ lstat) Residuals: Min ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/ISLR6-LAB/" class="btn btn-outline-primary" prompt="Older"><p>ISLR - LAB6</p></a> <a href="/posts/MCMC/" class="btn btn-outline-primary" prompt="Newer"><p>MCMC</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://twitter.com/username">your_full_name</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/datascience/">datascience</a> <a class="post-tag" href="/tags/datamining/">datamining</a> <a class="post-tag" href="/tags/machinelearning/">machinelearning</a> <a class="post-tag" href="/tags/islr/">ISLR</a> <a class="post-tag" href="/tags/statistical-method/">statistical method</a> <a class="post-tag" href="/tags/efron/">Efron</a> <a class="post-tag" href="/tags/prml/">PRML</a> <a class="post-tag" href="/tags/machine-learning/">machine learning</a> <a class="post-tag" href="/tags/machine-learning/">Machine learning</a> <a class="post-tag" href="/tags/categorical-data/">categorical data</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}}); </script> MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
